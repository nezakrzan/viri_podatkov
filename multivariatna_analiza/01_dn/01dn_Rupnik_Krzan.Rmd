---
title: "Domača naloga 1"
author: "Neza Krzan, Tom Rupnik"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
header-includes:
- \usepackage[slovene]{babel}
- \usepackage{float}
- \usepackage[T1]{fontenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'H', fig.align="center", echo=FALSE, results = F)
library(cluster)
library(mclust)
library(foreign)
library(psych)

set.seed(2020)
```

\tableofcontents
\listoffigures
\listoftables
\newpage

# Cilji naloge

V nalogi vova poskušala razvrstiti enote v skupine tako, da si bodo enote znotraj skupin čim bolj podobne in enote v različnih skupinah čim bolj različne glede na več spremenljivk. 

# Podatki

<!--
NEZA: a misls da je treba te podatke tko pregledat kokr na prvih vajah k ste delal?-->

<!--
Ime raziskave oziroma podatkov. Leto in kraj/država, če je to za podatke
smiselno. Enota analize. Velikost vzorca. Uporabljene spremenljivke (ime v datoteki in
vsebinski pomen). Ostale posebnosti, za katere menite, da so vredne omembe (obravnava
manjkajočih vrednosti, rekodirane spremenljivke ...). Zapišite, katere spremenljivke boste
uporabili za razvrščanje in ali jih boste za ta namen standardizirali.
-->

Uporabila bova podatke _Swiss banknotes data_, ki vsebujejo šest meritev, opravljenih na 100 pravih in 100 ponarejenih starih švicarskih bankovcih za 1000 frankov. 

```{r message=FALSE, warning=FALSE, include=FALSE}
data = read.table("data.txt", header = T, sep = "", dec = ".")
str(data)
nrow(data)
colnames(data)
```

Podatki vsebujejo 7 spremenljivk - 6 številskih in eno opisno. Vsebujejo različne izmerjene dolžine in širine bankovca v milimetrih:

- `length`: dolžina bankovca(na sliki $x_1$), 
- `left`: dolžina levega roba(na sliki $x_2$), 
- `right`: dolžina desnega roba(na sliki $x_3$), 
- `bottom`: dolžina spodnjega roba(na sliki $x_4$) in 
- `top`: dolžina zornjega roba(na sliki $x_5$) ter 
- `diag`: dolžina diagonale bankovca(na sliki $x_6$). 

```{r echo=FALSE, fig.align='center', fig.cap="Označene mere na bankovcu.", fig.show='hold', out.width="70%"}
knitr::include_graphics("ban.png")
```

Opisna spremenlivka `status` pa določa ali je bankovec pravi(`genuine`) ali ponarejen(`counterfeit`). V tabeli imamo torej meritve za 200 različnih bankovcev.

## Urejanje podatkov

Imena spremenljivk in vrednosti kategorične spremenljivke sva preimenovala v slovenska imena ter, kot sva že napisala zgoraj, sva podatke skalirala.

Preimenovane spremenljivke:

- `length`: `dolžina`, 
- `left`: `levi.rob`, 
- `right`: `desni.rob`, 
- `bottom`: `spodnji.rob`,
- `top`: `zgornji.rob`, 
- `diag`: `diagonala` in
- `status` : `tip`, kjer je potem `counterfeit`:`ponarejen bankovec` in `genuine`:`pravi bankovec`. 

```{r message=FALSE, warning=FALSE, include=FALSE}
# preimenovanje stolpcev
colnames(data) <- c('dolzina','levi.rob','desni.rob', 'spodnji.rob', 'zgornji.rob', 'diagonala', 'tip')

# nastavim stolpec kot faktor
data$tip <- as.factor(data$tip)
levels(data$tip)
# prevedem v slovenščino
levels(data$tip) <- c("ponarejen bankovec", "pravi bankovec")
levels(data$tip)
```

Za lažjo predstavo si poglejmo opisne statistike številskih spremenljivk, da bomo vedeli s kakšnimi podatki imamo opravka.

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(vtable)
#napovedne spremenljivke
pred <- c('dolzina','levi.rob','desni.rob', 'spodnji.rob', 'zgornji.rob', 'diagonala')
sumtable(data[,pred], add.median = T, digits = 1, 
         title = "Opisne statistike za števillske spremenljivke v podatkovnem okviru \\texttt{Swiss banknotes data}.")
```

Spremenljivke imajo različen razpon vrednosti, zato jih bova, skalirala. Tako bodo imele spremenljivke povprečje 0 in standardni odklon 1. S tem doseževa enakovreden vpliv spremenljivk na razvrstitev. Vidimo pa tudi, da nimamo mankajočih vrednosti v podatkih.

Poglejmo si še porazdelitve spremenljivk.

<!-- 
tuki nevem al so bols boxploti al tko k sva mela na zacetku?
TOM: teli boxploti so mi kr vsec k se takoj vid da je razlika 
Neza: okej pustim pol boxplote
-->

```{r echo=FALSE, fig.cap="Porazdelitve spremenljivk v podatkovnem okviru \\texttt{Swiss banknotes data}.", fig.height=8, message=FALSE, warning=FALSE, fig.show='hold', out.width="50%"}
library(reshape2)
library(ggplot2)
library(gridExtra)

g1 = ggplot(data, aes(x = tip, y= dolzina, fill=tip)) +
  geom_boxplot() +
  theme_bw() + 
  ylab("dolzina(mm)")
g2 = ggplot(data, aes(x = tip, y= levi.rob, fill=tip)) +
  geom_boxplot() +
  theme_bw() + 
  ylab("levi rob(mm)")
g3 = ggplot(data, aes(x = tip, y= desni.rob, fill=tip)) +
  geom_boxplot() +
  theme_bw() + 
  ylab("desni rob(mm)")
g4 = ggplot(data, aes(x = tip, y= spodnji.rob, fill=tip)) +
  geom_boxplot() +
  theme_bw() + 
  ylab("spodnji rob(mm)")
g5 = ggplot(data, aes(x = tip, y= zgornji.rob, fill=tip)) +
  geom_boxplot() +
  theme_bw() + 
  ylab("zgornji rob(mm)")
g6 = ggplot(data, aes(x = tip, y= diagonala, fill=tip)) +
  geom_boxplot() +
  theme_bw() + 
  ylab("diagonala(mm)")

library(patchwork)
library(ggpubr)

combined <- g1 + g2 + g3 + g4 + g5 + g6 & theme(legend.position = "bottom")
combined + plot_layout(guides = "collect", nrow = 3)
```

Opazna je razlika med pravimi bankovci in ponarejenimi pri vseh spremenljivkah.

Za razvrščanje bova uporabljala samo številske spremenljivke, in sicer `dolzina`, `levi.rob`, `desni.rob`, `spodnji.rob`, `zgornji.rob`; za analizo pa spremenljivki `tip` in `diagonala`. Ker je `diagonala` edina številska spremenljivka pri analizi, le ta ne bo skalirana.

## Analiza povezanosti med spremenljivkami

<!-- ker nimava tolk spremenljivk kokr jih mamo na vajah niti ne vem kako nej to sploh nardim
Tematska: samo tip bankovca?
povezanost med tipom bankovca in ostalimi stevilskimi spremenljivkami?
okej jst kle nevem cist tocno kaj hoce....
-->

<!-- 
TOM: tole tvoje spodnje vrjetno spada pod analiza Likertovih spremenljivk
oziroma je tko vsaj v 1. vajah
Neza: da spada to pod likertove spremenljivke, sam nevem zakaj ni tam, je prestavljeno tja dol...

Pa teoreticno je naceloma taka razporeditve kokr si jo ti naredila ampak glede na korelacijsko matriko ("lowerMat(Rlik)") se mi zdi pa moja bolja...
Neza: jst sm to razvrstitev nardila tko po kmecki logiki, tko da ni teoreticno utemeljena...
-->

<!-- TOM: bom se jst tle neki probal pa bova potem vidla kaj je uporabnega -->

```{r fig.cap = "Korelacija med spremenljivkami.", fig.height=4, fig.height=4, out.width="40%", out.height="50%", echo=FALSE, results=F}

ime = c('dolzina','levi.rob','desni.rob', 'spodnji.rob', 'zgornji.rob')

Rlik <- cor(data[ime])
lowerMat(Rlik)

heatmap(x=Rlik, Rowv=NA, symm=T, revC=T, 
        col=hcl.colors(n=100, palette="Blue-Red 3", rev=T),
        breaks=seq(-1, 1, 0.02))
```

Iz grafa vidimo, da sta levi in desni rob med seboj mocno povezana. Prav tako imata zgornji in spodnji rob z njima srednje mocno korelacijo. Dolzina ima z vsemi zelo sibko korelacijo iz cesar bi lahko zakljucili, da tvori svojo skupino. 

To je še bolje razvidno iz spodnjega grafa.

```{r fig.cap="Korelacija med spremenljivkami in možna povezava med spremenljivkami.", fig.height=4, fig.height=4, out.width="50%", out.height="50%", echo=FALSE, results=F}
heatmap(x=Rlik, symm=T, revC=T,
        col=hcl.colors(n=100, palette="Blue-Red 3", rev=T),
        breaks=seq(-1, 1, 0.02))
```

Poglejmo si povezanost med kategorično spremenljivko tip bankovca in številskimi spremenljivkami za razvršanje. 

```{r fig.cap="Povezanost med kategorično spremenljivko(tip bankovca) in številskimi spremenljivkami.", fig.height=4, fig.height=4, out.width="50%", out.height="50%", echo=FALSE, results=F}
t(aggregate(x=data[ime], by=list(data$tip), FUN=mean))

agr <- aggregate(x=data[ime], by=list(data$tip), FUN=mean)
matplot(x=seq_along(ime), y=t(agr[, -1]), type="o", pch=16, col=agr[, 1], main="", xlab="", xaxt="n", ylab="")
axis(side=1, at=seq_along(ime), labels=ime, las=2)
#abline(v=1.5)
legend("topright", legend=agr[, 1], col=agr[, 1], pch=16)
```

<!-- 
Neza: okej tega ne znam komentirat
mislm men je isto glede na tip bankovca?
-->

<!--TOM: to spodnje nevem kok je OK -->

```{r}
tabela.diagonala <- cor(x=data[ime], y=data$diagonala, method="pearson")
round(tabela.diagonala, digits=2)
```
Torej sklepava lahko, da spremenljivka `dolzina` tvori svoj sklop, ostale spremenljivke pa svojega iz zgornje analize in grafov.

## Konstrukcija in analiza Likertovih spremenljivk

Sedaj bomo za spremenljivke izdelali dve Likertovi lestvici, torej razdelila sva jih v dve skupini, tako da znotraj skupine spremenljivke merijo približno enako stvar. Za vsako skupino sva ustvarili eno Likertovo lestvico, tako da za vsako opazovano enoto izračunamo povprečje izbranih spremenljivk.

* Prvi sklop predstavlja dolžino bankovca in vsebuje `dolzina`.
* Druga sklop predstavlja mere in vsebuje `levi.rob`,`desni.rob`, `spodnji.rob`, `zgornji.rob`.

```{r include=FALSE}
# sestavljene spremenljivke
#	sklop "istih" indikatorjev zdruzimo v eno sestavljeno spremenljivko (Likertova lestvica)
#	sklop tvorimo glede na teorijo
#	sklop se vidi iz korelacijske matrike
v1 <- c("dolzina")
v2 <- c('levi.rob','desni.rob', 'spodnji.rob', 'zgornji.rob')

# sestavljena spremenljivka je povprecje indikatorjev iz sklopa
# shranimo kot novi spremenljivki v podatkih (dodamo dva stolpca)
data$v1 <- rowMeans(x=data[v1])
data$v2 <- rowMeans(x=data[v2])
```

<!--
```{r}
# opisne statistike
opisne <- as.data.frame(describe(data[c("v1", "v2")]))
rownames(opisne) <- c("dolzina", "mere")
round(t(opisne), 2)

# graficni prikaz
oldpar <- par(las=1, mfrow=c(1, 2))
hist(data$v1 , main="Porazdelitev za sklop dolzina", xlab="strinjanje", ylab="frekvenca")
hist(data$v2 , main="Porazdelitev za sklop mere", xlab="strinjanje", ylab="frekvenca")
par(oldpar)
```
-->
Poglejmo si porazdelitvi novo ustvarjenih spremenljivk Likertove lestivce tj. dolzina in mere.

```{r, results=TRUE, fig.width=9, fig.height=5, fig.cap="Deskriptivne statistike Likertovih spremenljivk.", include=FALSE}
# Poglejmo porazdelitvi teh dveh spremenljivk.
OpisLikert <- as.data.frame(psych::describe(data[, c("v1","v2")]))
kable(round(OpisLikert[, c(2, 3, 4, 5, 8, 9, 10, 11, 12)], 2), caption=" ") %>% 
  kable_styling(full_width=F, latex_options="hold_position")
```

```{r, results=F, fig.width=9, fig.height=4, fig.cap="Porazdelitvi Likertovih spremenljivk.", echo=FALSE}
par(mfrow = c(1, 2))
hist(data$v1, main = "Porazdelitev dolzine", xlab = "Strinjanje", ylab = "Frekvenca", prob = T)
x <- seq(min(data$v1), max(data$v1), length = 1000)
f <- dnorm(x, mean = mean(data$v1), sd = sd(data$v1))
lines(x, f, col = "red", lwd = 2)

hist(data$v2, main = "Porazdelitev mere", xlab = "Strinjanje", ylab = "Frekvenca", prob = T)

# Preverimo domnevo o enakosti povprečij.
t <- t.test(x = data$v2, y = data$v1, paired = TRUE)
```

Porazdelitvi dolzine in mer si nista podobni. Povprečna nagnjenost k dolzini je 214.9 s standarndim odklonom 0.38 in je dokaj simetrična. Povprečna nagnjenost k meri je 70.04, medtem ko je standardni odklon enak 0.56 in njena porazdelitev je precej nedefinirana.

<!--
Neza: a je to okej, da sta sklopa tok razlicno porazdeljena? Se mi zdi da je blo na vajah dokaj lepo...
-->

Da preverimo domnevo o enakosti povprečij dolzine in mer uporabimo t-test za odvisna vzorca z ničelno domnevo, da je razlika povprečij enaka 0. Ta vrne vrednost $p < 0.001$, torej lahko ničelno domnevo pri stopnji značilnosti 0.05 zavrnemo. 95% interval zaupanja za razliko povprečij med dolzino in mero je [-144.96,-144.76].

Pogledala bova še ali sta ustvarjeni spremenljivki Likertove lestvice povezani med seboj in ali sta povezani z ostalimi spremenljivkami.

\newpage

## Povezanost Likertovih spremenljivk

Grafično si oglejmo razsevni diagram dolzine in mer. 

```{r, fig.align="center", fig.width=5, fig.height=5, fig.cap="Razsevni diagram dolzine in mer.", echo=FALSE, results = F, out.width="50%"}
tmp <- apply(data[, c("v1", "v2")], 2, jitter, amount = 0.07)

plot(tmp[,1], tmp[,2], xlab = "dolzina", ylab = "mere")

cor.test(x=data$v1, y=data$v2)
```

Da sva preverila ničelno povezanost, sva uporabila korelacijski test za odvisna vzorca na osnovi Pearsonovega koeficienta korelacije, ki vrne kot oceno za Pearsonov korelacijski koeficient vrednost -0.0795, ampak vrednost 0 pa pade v 95% IZ ter vrednost $p = 0.26 > 0.05$, torej ne moreva pri stopnji značilnosti 5% trditi, da povezanost obstaja na populaciji.

## Likertovi spremenljivki in `tip`

```{r echo=FALSE, fig.cap="Povprečja dolzina (levo) in mere (desno) po skupinah spremenljivke tip.", fig.height=6, fig.width=10, message=FALSE, warning=FALSE, results=F, out.width="70%"}
library(gplots)
par(mfrow = c(1,2))
plotmeans(v1 ~ tip, 
          data = data, 
          ylab = "povprečje", 
          xlab = "")

plotmeans(v2 ~ tip, 
          data = data, 
          ylab = "povprečje", 
          xlab = "")

t.test(data$v1 ~ data$tip)
t.test(data$v2 ~ data$tip)
```

Tukaj sva uporabljala Welchev test za primerjavo povprečij, ki pokaže, da se skupini tipa bankovcev pri stopnji značilnosti 5% v povprečju statistično značilno razlikujeta pri obeh Likertovi spremenljivki, ker je $p<0.05$. 

Ocena za povprečje pri dolzini za ponarejen tip bankovca je 214.82 in za pravi bankovec 214.97 pri 95% intervalu zaupanja [-0.25, -0.043]. Ocena za povprečje pri mere pa je za ponarejen tip bankovca 70.54 in za pravi bankovec 69.53 pri 95% intervalu zaupanja [0.94, 1.07].

Nariševa še razsevni diagram spremenljivke `tip`, kjer za osi vzameva Likertovi lestvici, točke pa predstavljajo posamezne enote. Dodamo tudi dve večji točki, ki predstavljata povprečji po skupinah obeh Likertovih spremenljivk.

```{r, fig.height=5, fig.width=5, fig.cap="Razsevni diagram dolzina in mere po spremenljivki tip.", out.width="70%"}
# Izberemo spremenljivko
var <- "tip"
sprem <- c("v1", "v2")

# Izračunamo centroide po nadzoru
agg <- aggregate(data[, sprem], by=list(data[, var]), FUN=mean, na.rm = TRUE)

tmp <- apply(data[, sprem], 2, jitter, amount=0.07)

joint <- rbind(tmp, agg[, -1])

plot(joint,
     xlab = "dolzina",
     ylab = "mere",
     pch = 16,
     cex = c(rep(0.5, nrow(tmp)), rep(2, nrow(agg))),
     col=c(data[, var], agg[,1]))
# dodamo legendo
par(xpd=TRUE)
legend("bottomright", legend = agg[,1], pch = 16, col = 1:nrow(agg))
```

Iz grafa opazimo razlike med tipom bankovca, ampak obstajajo enote, ki se malenkost pomešajo. 

<!-- Neza: kaj nej zdej sploh za zakljucek napisem?-->

Torej spremenljivke sva razdelila v dva sklopa glede na povezanost in tako ustvarila dve Likertovi spremenljivki. Prva spremenljivka predstavlja dolžino, druga pa ostale mere. S 95% zaupanjem lahko trdimo, da dolžina in mere nista statistično značilno povezani. Glede na tip bankovca se skupini statistično razlikujeta pri obeh Likertovi spremenljivki.


```{r message=FALSE, warning=FALSE, include=FALSE}
# skaliranje podatkov
# vprasanje: misls da skalirava tud diagonalo k jo uporabva za analizo?, zdej ni skalirana
# odgovor: sva skalirala samo spremenljivke za razvrscanje
dfz <- scale(x=data[1:5])
```

\newpage

# Hierarhično razvršanje

<!-- Primerjajte tri različne metode (pri vsaki zapišite ime metode in
uporabljeno razdaljo). Uporabite Wardovo metodo s kvadrirano Evklidsko razdaljo in še dve
drugi metodi. Izberite najbolj primerno razvrstitev (metoda in število skupin). Vašo izbiro
utemeljite.
-->

Pri hierarhičnem razvrščanju začnemo s tem, da je vsaka enota v svoji skupini. Potem pa se na vsakem koraku, glede na izračunane matrike različnosti, v kateri so razdalje med pari skupin, združujejo skupine, ki so si najbližje. Nato se izračunajo različnosti novih združenih skupin od ostalih, kar se nadaljuje dokler niso vse enote v eni skupini. Dobra lastnost hierarhičnega razvrščanja je, da uporabniku ni potrebno vnaprej določiti števila skupin.

Kot mero različnosti bova uporabila evklidsko razdaljo.

Torej za razvrščanje uporabljava spremenljivke `dolzina`, `levi.rob`, `desni.rob`, `spodnji.rob` in `zgornji.rob` ter primerjala bova tri različne metode in sicer, Wardovo metodo, minimalno metoda (single linkage) in maksimalno metoda (complete linkage).

Število skupin lahko določimo na podlagi dendograma, ki grafično prikazuje potek združevanja v skupine. Število skupin pa določimo tako na podlagi vidnejšega zmanjšanja razdalj skupinami.

## Wardowa metoda

Wardova metoda je primera za eliptične skupine.

```{r echo=FALSE, fig.cap="Dendogrami Wardowe metode razvrščanja v skupine.", fig.height=5, fig.width=11}
# matrika razliznosti na standardiziranih podatkih (Evklidska razdalja)
dz <- dist(x=dfz, method="euclidean")

hc.ward <- hclust(d=dz, method="ward.D2")
oldpar <- par(las=1, mfrow=c(1, 3))
barplot(hc.ward$height)
barplot(tail(x=hc.ward$height, n=10), names.arg=rev(seq_len(10)))
plot(hc.ward, labels=F, hang=-1, main="Ward", sub="", xlab="", ylab="")
par(oldpar)
```

## Minimalna metoda 

Minimalna metoda (enojna povezanost - single linkage) je primerna za dolge in neeliptične skupine, ki so jasno ločene med seboj. Kadar skupine med seboj niso jasno ločene pri minimalni metodi pride do problema veriženja. Na takem dendogramu ne moremo določiti števila skupin in zato rečemo, da je skupina zgolj ena.

```{r echo=FALSE, fig.cap="Dendogrami minimalne metode razvrščanja v skupine.", fig.height=5, fig.width=11}
# uporabili smo Evklidsko razdaljo
hc.sin <- hclust(d=dz, method="single")
oldpar <- par(las=1, mfrow=c(1, 3))
barplot(hc.sin$height) 
barplot(tail(x=hc.sin$height, n=10), names.arg=rev(seq_len(10)))
plot(hc.sin, labels=F, hang=-1, main="Single", sub="", xlab="", ylab="")
par(oldpar)
```

## Maksimalna metoda

Maksimalna metoda (polna povezanost - complete linkage) pa je primerna za okrogle skupine.

```{r echo=FALSE, fig.cap="Dendogrami maksimalne metode razvrščanja v skupine.", fig.height=5, fig.width=11}
# uporabili smo Evklidsko razdaljo
hc.com <- hclust(d=dz, method="complete")
oldpar <- par(las=1, mfrow=c(1, 3))
barplot(hc.com$height)
barplot(tail(x=hc.com$height, n=10), names.arg=rev(seq_len(10)))
plot(hc.com, labels=F, hang=-1, main="Complete", sub="", xlab="", ylab="")
par(oldpar)
```

## Analiza

Glede na izgled grafov (razvrstitve) sva se odločila, da je najbolj primerna razvrstitev po Wardowi metodi. Pri ostalih dveh metodah so različnosti dokaj majhne (ni tako izrazitih skokov v višini). Grafe bomo narisali za _2_, _3_ in _4_ skupine, saj so tu razlike <!--med različnostmi--> bolj izrazite.

```{r echo=FALSE, fig.cap="Povprečja po skupinah za Wardowo metodo.", fig.height=5, fig.width=12}
# Ward skupine
hc.ward1 <- cutree(tree=hc.ward, k=1)
hc.ward2 <- cutree(tree=hc.ward, k=2)
hc.ward3 <- cutree(tree=hc.ward, k=3)
hc.ward4 <- cutree(tree=hc.ward, k=4)

ime = c('dolzina','levi.rob','desni.rob', 'spodnji.rob', 'zgornji.rob')

oldpar <- par(las=1, mfrow=c(1, 3))
nsk <- 2
sk <- hc.ward2
sk.ime <- paste("sk", 1:nsk, sep="")
agr <- aggregate(x=dfz, by=list(sk), FUN=mean)
y <- t(agr[, -1])
matplot(x=seq_along(ime), y=y, type="o", pch=16, ylim=c(-2, 2), xlab="",
        ylab="Povprecje (standardizirane spremenljivke)")
axis(side=1, at=seq_along(ime), labels=ime, las=2)
legend("bottomleft", legend=sk.ime, col=1:nsk, pch=16)
abline(h=0, v=6.5)
nsk <- 3
sk <- hc.ward3
sk.ime <- paste("sk", 1:nsk, sep="")
agr <- aggregate(x=dfz, by=list(sk), FUN=mean)
y <- t(agr[, -1])
matplot(x=seq_along(ime), y=y, type="o", pch=16, ylim=c(-2, 2), xlab="",
        ylab="Povprecje (standardizirane spremenljivke)")
axis(side=1, at=seq_along(ime), labels=ime, las=2)
legend("bottomleft", legend=sk.ime, col=1:nsk, pch=16)
abline(h=0, v=6.5)
nsk <- 4
sk <- hc.ward4
sk.ime <- paste("sk", 1:nsk, sep="")
agr <- aggregate(x=dfz, by=list(sk), FUN=mean)
y <- t(agr[, -1])
matplot(x=seq_along(ime), y=y, type="o", pch=16, ylim=c(-2, 2), xlab="",
        ylab="Povprecje (standardizirane spremenljivke)")
axis(side=1, at=seq_along(ime), labels=ime, las=2)
legend("bottomleft", legend=sk.ime, col=1:nsk, pch=16)
abline(h=0, v=6.5)
par(oldpar)
```

<!-- Tukej je vrjetno potreben se komentar 
Neza: to pomojem zdej nc ni prov ker nevem ce je ta razvrstitev spremenljivk sploh prava....-->

Če si pogledamo skupino 2 na vseh treh grafih, vidimo, da zavzema podpovprečne vrednosti. Ravno obratno vidimo pri skupini 1, ki na prvem grafu zavzema nadpovprečne vrednosti, na drugih dveh pa zavzema podpovprečne vrednosti samo pri dolžini bankovca. Skupina 3 pa je v nekaterih primerih nadpovprečna v nekaterih pa podpovprečna(`spodnji.rob`, `zgornji.rob`). Pri zadnjem garfu se skupina 4 pri spremenljivki `dolzina` pribliza povprecju zelo dobro, pri vseh ostalih spremenljivkah je nadpovprecna in pri zadnji mocno podpovprecna.

\newpage

# Nehierarhično razvrščanje

<!--
Izberite/določite najbolj primerno število skupin. Pomagajte si z
rezultati hierarhičnega razvrščanja in dodatno za metodo K-means narišite grafe:
koleno, pseudo F, gap statistika. Vašo izbiro utemeljite. 
-->

## Razvrščanje K-means

K-means je metoda voditeljev oz. nehierarhičnega razvrščanja. Voditelji so "predstavniki skupin", vsaka enota pa pripada skupini, kateremu voditelju je najbližje(razdalja je evklidska) oz. mu je najbolj podobna; voditelj predstavlja povprečje skupine. Spremenljivke pri metodi _k-means_ morajo biti vsaj intervalne. 

Tukaj pri tej metodi mora biti število skupin podanoi vnaprej, kar je morda slaba lastnost in se glede tega razlikuje od npr. Wardove metode. Na začetku določimo voditelje, potem pa na vsakem koraku vsako enoto priredimo voditelju oz. skupini, kateremu je najbljižja glede na evklidsko razdaljo. Na vsakem koraku se izračunajo novi voditelji kot povprečja skupin. Postopek se zaključi, ko so novi voditelji enaki starim. 

Izberemo tisto razvrstitev, ki ima najmanjšo vrednost Wardove kriterijske funkcije, za katero vemo, da pada z naraščanjem števila skupin. Torej za optimalno število skupin ponavadi vzamemo tisto vrednost, kjer se zgori t.i. "koleno" funkcije. Če to "koleno" ni jasno razvidno, lahko sklepamo, da skupine niso jasno ločene. Postopek običajno večkrat ponovimo, saj za različne začetne voditelje lahko dobimo različne rešitve, torej razvrstitve v skupine.

```{r echo=FALSE, fig.cap="Vrednost Wardove kriterijske funkcije.", fig.height=4, fig.width=6, out.width="70%"}
# WSS
kmax <- 10
wss <- NULL
for (k in 1:kmax) {
  withinss <- kmeans(x=dfz, # podatki
                     centers=k, # st. skupin
                     nstart=100)$tot.withinss # st. ponovitev
  wss <- c(wss, withinss)
}

plot(x=1:kmax, y=wss, type="b", main="", xlab="stevilo skupin(k)",
     ylab="vrednost Wardowe kriterijske funkcije")
```

Sprememba naklona funkcije izgleda največja pri **2** ali **4** skupinah oziroma je tam "koleno" najbolj razvidno.

## GAP statistika


Pri določevanju števila skupin si lahko pomagamo tudi z GAP statistiko, kjer iščemo skupine, ki so podatki bolj homogeni, kot kjer ni skupin. Gre za primerjavo razdalj znotraj skupin z razdaljami na podatkih brez skupin. Izberemo pa tisto najmanjše število skupin k , kjer je vrednost $GAP(k)$ statistike vsaj tolikšna kot $GAP(k+1) - SE(GAP(k+1))$; $SE$ je standardna napaka GAP statistike.

```{r echo=FALSE, fig.cap="Vrednost GAP statistike.", fig.height=4, fig.width=6, out.width="70%"}
# gap statistika
gap_stat <- clusGap(x=dfz, FUNcluster=kmeans, K.max=kmax)
plot(gap_stat, xlab="stevilo skupin", main="")
```

Na podlagi grafičnega prikaza vrednosti GAP statistike pri različnem številu skupin se odločimo za **4** skupine, saj tam doseže najvišjo točko.

## Pseudo F (Calinski - Harabasz indeks)

Uporabimo pa lahko tudi indeks Calinski-Harabasz, ki ocenjuje razmerje med razpršenostjo znotraj skupin in razpršenostjo med skupinami. Uporabljamo ga za oceno primernosti števila skupin v metodi gručenja (angl. _clustering_). Višje vrednosti indeksa Calinski-Harabasz označujejo boljše gručenje, pri čemer optimalno število skupin običajno doseže maksimum tega indeksa.

```{r echo=FALSE, fig.cap="Vrednost Pseudo F oz. Calinski - Harabasz indeksa.", fig.height=4, fig.width=6, out.width="70%"}
# Pseudo F (Calinski and Harabasz index)
pseudoF <- 0
bss <- wss[1] - wss
for (k in 2:kmax) pseudoF <- c(pseudoF, (bss[k]/(k-1)) / (wss[k]/(nrow(dfz)-k)))

plot(x=1:kmax, y=pseudoF, type="b", xlab="stevilo skupin",
     ylab="Pseudo F", main="")

km1 <- kmeans(x=dfz, centers=1, nstart=1)
km2 <- kmeans(x=dfz, centers=2, nstart=100)
km3 <- kmeans(x=dfz, centers=3, nstart=100)
km4 <- kmeans(x=dfz, centers=4, nstart=100)
```

Tukaj je maksimum dosežen pri **2** skupinah.

Torej, če povzameva celotno analizo, bi, glede na posamezen graf, izbrala

* WSS: sprememba naklona izgleda največja pri **4** skupinah,
* Pseudo F: maksimum doseze pri **2** skupinah,
* gap statistika: najvišjo točko preden začne padati doseže pri **4** skupinah.

Na podlagi zgornjih analiz in ugotovitev pri hierarhičnem razvrščanju, kjer smo e odločali med 2, 3 ali 4 skupinami, bi se tu določili raje za **4** skupine, kot za 2, saj težimo k večjemu številu skupin kot je 2.

<!--
Primerjajte vrednost kriterijske funkcije pri različnem številu skupin za Wardovo
metodo in K-means. Katera metoda je boljša? Pri izbranem številu skupin primerjajte
obe razvrstitvi. Izpišite kontingenčno tabelo in izračunajte popravljen Randov indeks.
-->

\newpage

## Primerjava vrednosti kriterijske funkcije za Wardowo metodo in K-means

Primerjala sva tudi vrednosti kriterijskih funkcij za Wardowo metodo in metodo K-means, ker sta podobno oziroma delujeta na isti princip. Je pa metoda K-means boljša, ker išče lokalne minimume, za razliko do Wardove, ki deluje hierarhično in vedno poda enak rezultat. Ocenjujeva sva pa po principu, da ima boljša razvrtitev manjšo vrednost karaketristične funkcije. Pomembno pa je tudi to, da so podatki standardizirani, saj drugače med seboj ne bi bilo primerljivo.

```{r echo=FALSE}
# Wardova kriterijska funkcija
WardKF <- function(data, cluster){
  # vsota kvadratov
  # x = ena spremenljivka
  ss <- function(x) sum((x-mean(x))^2)
  # vsota kvadratov znotraj ene skupine po vseh spremenljivkah
  # X = matrika, stolpci so spremenljivke
  withinss <- function(X) sum(apply(X=X, MARGIN=2, FUN=ss))
  # vsota kvadratov vseh skupin
  sum(by(data=data, INDICES=cluster, FUN=withinss))
}

wkf <- NULL
wkf <- rbind(wkf, c(WardKF(dfz, hc.ward1), WardKF(dfz, hc.ward2), WardKF(dfz, hc.ward3), WardKF(dfz, hc.ward4)))
wkf <- rbind(wkf, c(WardKF(dfz, km1$cluster), WardKF(dfz, km2$cluster), WardKF(dfz, km3$cluster), WardKF(dfz, km4$cluster)))
rownames(wkf) <- c("Ward", "Kmeans")
colnames(wkf) <- c("k=1", "k=2", "k=3", "k=4")

# NEZA: to tabelo ne znam med besedilo spravt, vedno jo vrze na vrh strani, mogoce ves zakaj, vse sm ze poskusla?
kable(wkf, caption = "Primerjava vrednosti kriterijske funkcije za Wardowo metodo in K-means.")
```

Vidimo da ima v vseh primerih (z izjemo prvega kjer sta enaka) K-means manjšo vrednost, kar si tudi želimo. Primerjavo razvrtitev bomo naredili na številu skupin **k = 4**. 

```{r echo=FALSE}
# kontingenčna tabela
table(km4$cluster, c(3, 2, 4, 1)[hc.ward4])

# popravljen Randov indeks
adjustedRandIndex(x=km4$cluster, y=hc.ward4)
```

<!-- Tukej nevem kaj bi komentiral 
Neza: sm neki napisala-->

Največje elemente imamo na diagonali kontingenčne tabele, tudi te vrednosti niso ekstremno velike(npr. 400). Za izvendiagonalne elemente si želimo, da bi bili čim manjši oziroma zelo blizu 0, kar pa po večini so, ali pa so celo kar enaki 0(iztopa le ena vrednost - 17).

Poglejmo si še Randow indeks, ki predstavlja delež parov enot, ki so si v obeh razbitjih usklajeni -  v obeh razbitjih v isti skupini ali pa v obeh razbitjih v različnih skupinah. Pogledala sva si popravljen Randow indeks, zaradi boljše primerljivosti. Enak je `r round(adjustedRandIndex(x=km4$cluster, y=hc.ward4), 3)`, kar je blizu 0,5, torej gre skoraj za neko srednjo podobnost, sicer pa večji kot je, boljše je -  vrednost 1 pomeni identični razbitji, vrednost 0 pa, da sta si razbitji tako podobni po slučaju.

\newpage

#  Razvrščanje na podlagi modelov

Tukaj predpostavimo, da so podatki generirani iz multivariatnih normalnih porazdelitev z različnimi parametri oziroma komponentami; vsaka skupina ima svojo multivariatno normalno porazdelitev. Skupina je večja po volumnu, če ima večjo variabilnost, omejimo pa se z domnevami oziroma predhodnim znanjem, kakšne naj bi ti skupine bile. Zato si poglejmo porazdelitve spremenljivk ne glede na tip bankovca.

<!-- Ali je porazdelitev spremenljivk primerna za uporabo te metode? Ne glede na
primernost uporabite metodo za razvrščanje na vaših podatkih. Izberite najbolj
primeren model in število skupin. Izbiro utemeljite.
-->

```{r echo=FALSE, fig.cap="Porazdelitve spremenljivk."}
oldpar <- par(las=1, mfrow=c(2, 3))
for (i in seq_along(ime)) {
  hist(data[, ime[i]],
       main=ime[i],
       xlab="",
       ylab="Frekvenca")
}
par(oldpar)
```

Spremenljivka `spodnji.rob`  in tudi `desni.rob` nista porazdeljeni po normalni porazdelitvi, zato ne moremo trditi, da je zadoščen ta pogoj. Ostale so porazdeljene po normalni, nekatere asimetrične v denso(npr. spremenljivka `dolzina`) in nekatere v levo(npr. spremenljivka `levi.rob`).

<!--
Nekatere spremenljivke niso porazdeljene po normalni porazdelitvi, zato ne moremo trditi da je zadoščen pogoj. 
-->

Tukaj ocenimo število skupin in parametre za vsako skupino ter kateri skupini posamezna enota pripada. V najinem primeru, kjer je predpostavka o multivariatni normalni porazdelitvi kršena, se simulacija ne izkaže za optimalno. Razvrstitev se dela na originalnih podatkih oz. nestandardiziranih podatkih, ker s tem omogočimo različno velikost skupin.

## BIC(Bayes Information Criterion) kriterij

Naredimo torej razvrstitev na originalnih, nestandardiziranih podatkih, kjer funkcija sama izbere naprimernejši model.

```{r echo=FALSE, fig.height=5, fig.width=8, fig.cap="BIC kriterij za originalne podatke.", results=F, out.width="70%"}
df = data[1:5]
mc <- Mclust(data=df, G=1:5)
summary(mc)
plot(x=mc, what="BIC")
```
Na podlagi BIC kriterija (Bayesian Information Criterion), ki zavzame vrednost -592.64 izberemo model VEE s tremi skupinami, kar pomeni, da gre za elipsoidne(angl. _ellipsoidal_) skupine, ki so različno velike, različnih oblik in enako usmerjene.

<!--
Najbolj primeren model je VEE (vsi elipticne oblike, razlicnih velikosti in enake orientacije) in 3 skupine. 
-->

Kriterij temelji na "Bayesovski" statistiki, zato lahko določimo tudi apriorne verjetnosti(torej neko naše predhodno znanje oziroma prepričanja). 

```{r, fig.height=4, fig.cap="BIC kriterij (priorControl) za originalne podatke.", fig.height=5, fig.width=8, results=F, out.width="70%"}
# priorControl
mcP <- Mclust(data=df, G=1:5, prior = priorControl())
summary(mcP)
plot(mcP, what = "BIC")
```

Na podlagi BIC kriterija z uporabljenim argumentom o apriornih verjetnostih se odločimo za model EEE s tremi skupinami, kar pomeni, da gre za različno velike skupine, različnih oblik in enake usmerjenosti.

## BIC kriterij na standariziranih podatkih

Poglejmo si še, iz radovednosti, kako je z oceno modela na standariziranih podatkih, ampak vrednosti BIC kriterija niso primerljive med standariziranimi in nestandariziranimi podatki. 

```{r echo=FALSE, fig.height=6, fig.width=8, fig.cap="BIC kriterij za standardizirane podatke.", results=F, out.width="70%"}
mc <- Mclust(data=dfz, G=1:5)
summary(mc)
plot(x=mc, what="BIC")
```

Na podlagi BIC kriterija (Bayesian Information Criterion), ki zavzame vrednost -1143.31	ponovno izberemo model VVE s tremi skupinami.

Tudi tukaj lahko primerjamo z vključitvijo apriornih verjetnosti.

```{r, fig.height=4, fig.cap="BIC kriterij (priorControl) za standardizirane podatke.", fig.height=5, fig.width=8, results=F, out.width="70%"}
# priorControl
mcP <- Mclust(data=dfz, G=1:5, prior = priorControl())
summary(mcP)
plot(mcP, what = "BIC")
```

Tudi tukaj se na podlagi BIC kriterija z uporabljenim argumentom o apriornih verjetnostih se odločimo za model EEE s tremi skupinami, kar pomeni, da gre za različno velike skupine, različnih oblik in enake usmerjenosti.

<!-- tole nevem ce je okej-->

Na podlagi vseh štirih kriterijev se zaradi enostavnosti odločimo za model VEE s tremi skupinami - torej različno velike skupine, različnih oblik in enakih umserjenosti.

# Najboljša razvrstitev in predstavitev skupin

<!--5. Predstavitev skupin. Izberite najboljšo razvrstitev po vašem mnenju in predstavite skupine.
a) Izračunajte povprečja standardiziranih spremenljivk po skupinah. Rezultat grafično
prikažite. Skupine opišite po najbolj izstopajočih lastnostih.
b) Skupine analizirajte bolj podrobno po nekaterih izbranih spremenljivkah. Preverite,
ali obstaja povezanost med skupino in temi spremenljivkami. Povezanost analizirajte na podlagi grafičnih prikazov in z ustreznimi izračuni. Interpretirajte moč in smer povezanosti. Preverite, ali je povezanost statistično značilna pri 5 % stopnji značilnosti. Pred analizo navedite, kateri test ste uporabili in zakaj ste izbrali ta test.
-->

Tukaj naju pa zanima kako podobne so si naše razvrstitve, ki sva jih v prejšnjih poglavjih izbrala na podlagi različnih modelov.

<!-- tuki pa rabva te sklope, k bi jih pomojem mogla nardit glede na likartovo lestvico v prvem delu...-->





