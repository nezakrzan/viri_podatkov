---
title: "Domača naloga 1"
author: "Neza Krzan, Tom Rupnik"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
header-includes:
- \usepackage[slovene]{babel}
- \usepackage{float}
- \usepackage[T1]{fontenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'H', fig.align="center", echo=FALSE, results = F)
library(cluster)
library(mclust)
library(foreign)
library(psych)

set.seed(2020)
```

\tableofcontents
\newpage
\listoffigures
\listoftables
\newpage

# Cilji naloge

V nalogi bova poskušala razvrstiti enote v skupine tako, da si bodo enote znotraj skupin čim bolj podobne in enote v različnih skupinah čim bolj različne glede na več spremenljivk. 

# Podatki
<!--
Ime raziskave oziroma podatkov. Leto in kraj/država, če je to za podatke
smiselno. Enota analize. Velikost vzorca. Uporabljene spremenljivke (ime v datoteki in
vsebinski pomen). Ostale posebnosti, za katere menite, da so vredne omembe (obravnava
manjkajočih vrednosti, rekodirane spremenljivke ...). Zapišite, katere spremenljivke boste
uporabili za razvrščanje in ali jih boste za ta namen standardizirali.
-->

Uporabila bova podatke _Swiss banknotes data_, ki vsebujejo šest meritev, opravljenih na 100 pravih in 100 ponarejenih starih švicarskih bankovcih za 1000 frankov. 

```{r message=FALSE, warning=FALSE, include=FALSE}
data = read.table("data.txt", header = T, sep = "", dec = ".")
str(data)
nrow(data)
colnames(data)
```

Podatki vsebujejo 7 spremenljivk - 6 številskih in eno opisno. Vsebujejo različne izmerjene dolžine in širine bankovca v milimetrih:

- `length`: dolžina bankovca(na sliki $x_1$), 
- `left`: dolžina levega roba(na sliki $x_2$), 
- `right`: dolžina desnega roba(na sliki $x_3$), 
- `bottom`: dolžina spodnjega roba(na sliki $x_4$) in 
- `top`: dolžina zornjega roba(na sliki $x_5$) ter 
- `diag`: dolžina diagonale bankovca(na sliki $x_6$). 

```{r echo=FALSE, fig.align='center', fig.cap="Označene mere na bankovcu.", fig.show='hold', out.width="70%"}
knitr::include_graphics("ban.png")
```

Opisna spremenljivka `status` pa določa ali je bankovec pravi(`genuine`) ali ponarejen(`counterfeit`). V tabeli imamo torej meritve za 200 različnih bankovcev.

## Urejanje podatkov

Imena spremenljivk in vrednosti kategorične spremenljivke sva preimenovala v slovenska imena in podatke sva standardizirala.

Preimenovane spremenljivke:

- `length`: `dolžina`, 
- `left`: `levi.rob`, 
- `right`: `desni.rob`, 
- `bottom`: `spodnji.rob`,
- `top`: `zgornji.rob`, 
- `diag`: `diagonala` in
- `status` : `tip`, kjer je potem `counterfeit`:`ponarejen bankovec` in `genuine`:`pravi bankovec`. 

```{r message=FALSE, warning=FALSE, include=FALSE}
# preimenovanje stolpcev
colnames(data) <- c('dolzina','levi.rob','desni.rob', 'spodnji.rob', 'zgornji.rob', 'diagonala', 'tip')

# nastavim stolpec kot faktor
data$tip <- as.factor(data$tip)
levels(data$tip)
# prevedem v slovenščino
levels(data$tip) <- c("ponarejen bankovec", "pravi bankovec")
levels(data$tip)
```

Za lažjo predstavo si poglejmo opisne statistike številskih spremenljivk, da bomo vedeli s kakšnimi podatki imamo opravka.

```{r echo=FALSE, message=FALSE, warning=FALSE, results=T, fig.pos = 'H'}
library(vtable)
#napovedne spremenljivke
pred <- c('dolzina','levi.rob','desni.rob', 'spodnji.rob', 'zgornji.rob', 'diagonala')
#sumtable(data[,pred], add.median = T, digits = 1, 
#         title = "Opisne statistike za števillske spremenljivke v podatkovnem okviru Swiss banknotes data.", #simple.kable = T, out = 'kable', fit.page = "\textwidth") 

stat = data.frame(spremenljivke = c("dolzina", "levi.rob", "desni.rob", "spodnji.rob", "zgornji.rob", "diagonala"),
           N = c(rep(200,6)),
           mean = c(215, 130, 130, 9, 11, 140),
           Std.Dev. = c(0.4, 0.4, 0.4, 1, 0.8, 1),
           Min = c(214, 129, 129, 7, 8, 138), 
           Pctl.25 = c(215, 130, 130, 8, 10, 140),
           Pctl.50 = c(215, 130, 130, 9, 11, 140),
           Pctl.75 = c(215, 130, 130, 11, 11, 142),
           Max = c(216,131,131,13,12,142))

kable(stat, 
      caption="Opisne statistike za števillske spremenljivke v podatkovnem okviru Swiss banknotes data.") %>% 
  kable_styling(full_width=F, latex_options="hold_position")
```

Spremenljivke imajo različen razpon vrednosti, zato sva vse standardizirala, razen spremenljivko `diagonala`, ker jo bova uporabila za analizo, ampak več o tej razvrstitvi spremenljivk, katere so za razvršanje in analizo kasneje. Tako bodo imele spremenljivke povprečje 0 in standardni odklon 1. S tem doseževa enakovreden vpliv spremenljivk na razvrstitev. Vidimo pa tudi, da nimamo mankajočih vrednosti v podatkih.

Torej za razvrščanje bova uporabljala samo številske spremenljivke, in sicer `dolzina`, `levi.rob`, `desni.rob`, `spodnji.rob`, `zgornji.rob`; za analizo pa spremenljivki `tip` in `diagonala`. Ker je `diagonala` edina številska spremenljivka pri analizi, le ta ne bo skalirana.

```{r message=FALSE, warning=FALSE, include=FALSE}
# skaliranje podatkov
# vprasanje: misls da skalirava tud diagonalo k jo uporabva za analizo?, zdej ni skalirana
# odgovor: sva skalirala samo spremenljivke za razvrscanje
dfz <- scale(x=data[1:5])
```

\newpage

# Hierarhično razvršanje

<!-- Primerjajte tri različne metode (pri vsaki zapišite ime metode in
uporabljeno razdaljo). Uporabite Wardovo metodo s kvadrirano Evklidsko razdaljo in še dve
drugi metodi. Izberite najbolj primerno razvrstitev (metoda in število skupin). Vašo izbiro
utemeljite.
-->

Pri hierarhičnem razvrščanju začnemo s tem, da je vsaka enota v svoji skupini. Potem pa se na vsakem koraku, glede na izračunane matrike različnosti, v kateri so razdalje med pari skupin, združujejo skupine, ki so si najbližje. Nato se izračunajo različnosti novih združenih skupin od ostalih, kar se nadaljuje dokler niso vse enote v eni skupini. Dobra lastnost hierarhičnega razvrščanja je, da uporabniku ni potrebno vnaprej določiti števila skupin.

Kot mero različnosti bova uporabila evklidsko razdaljo.

Torej za razvrščanje uporabljava spremenljivke `dolzina`, `levi.rob`, `desni.rob`, `spodnji.rob` in `zgornji.rob` ter primerjala bova tri različne metode in sicer, Wardovo metodo, minimalno metoda (single linkage) in maksimalno metoda (complete linkage).

Število skupin lahko določimo na podlagi dendograma, ki grafično prikazuje potek združevanja v skupine. Število skupin pa določimo tako na podlagi vidnejšega zmanjšanja razdalj skupinami.

## Wardowa metoda

Wardova metoda je primera za eliptične skupine.

```{r echo=FALSE, fig.cap="Dendogrami Wardowe metode razvrščanja v skupine.", fig.height=5, fig.width=11}
# matrika razliznosti na standardiziranih podatkih (Evklidska razdalja)
dz <- dist(x=dfz, method="euclidean")

hc.ward <- hclust(d=dz, method="ward.D2")
oldpar <- par(las=1, mfrow=c(1, 3))
barplot(hc.ward$height)
barplot(tail(x=hc.ward$height, n=10), names.arg=rev(seq_len(10)))
plot(hc.ward, labels=F, hang=-1, main="Ward", sub="", xlab="", ylab="")
par(oldpar)
```

## Minimalna metoda 

Minimalna metoda (enojna povezanost - single linkage) je primerna za dolge in neeliptične skupine, ki so jasno ločene med seboj. Kadar skupine med seboj niso jasno ločene pri minimalni metodi pride do problema veriženja. Na takem dendogramu ne moremo določiti števila skupin in zato rečemo, da je skupina zgolj ena.

```{r echo=FALSE, fig.cap="Dendogrami minimalne metode razvrščanja v skupine.", fig.height=5, fig.width=11}
# uporabili smo Evklidsko razdaljo
hc.sin <- hclust(d=dz, method="single")
oldpar <- par(las=1, mfrow=c(1, 3))
barplot(hc.sin$height) 
barplot(tail(x=hc.sin$height, n=10), names.arg=rev(seq_len(10)))
plot(hc.sin, labels=F, hang=-1, main="Single", sub="", xlab="", ylab="")
par(oldpar)
```

## Maksimalna metoda

Maksimalna metoda (polna povezanost - complete linkage) pa je primerna za okrogle skupine.

```{r echo=FALSE, fig.cap="Dendogrami maksimalne metode razvrščanja v skupine.", fig.height=5, fig.width=11}
# uporabili smo Evklidsko razdaljo
hc.com <- hclust(d=dz, method="complete")
oldpar <- par(las=1, mfrow=c(1, 3))
barplot(hc.com$height)
barplot(tail(x=hc.com$height, n=10), names.arg=rev(seq_len(10)))
plot(hc.com, labels=F, hang=-1, main="Complete", sub="", xlab="", ylab="")
par(oldpar)
```

## Analiza

Glede na izgled grafov (razvrstitve) sva se odločila, da je najbolj primerna razvrstitev po Wardowi metodi. Pri ostalih dveh metodah so različnosti dokaj majhne (ni tako izrazitih skokov v višini). Grafe bomo narisali za _2_, _3_ in _4_ skupine, saj so tu razlike <!--med različnostmi--> bolj izrazite.

```{r echo=FALSE, fig.cap="Povprečja po skupinah za Wardowo metodo.", fig.height=5, fig.width=12}
# Ward skupine
hc.ward1 <- cutree(tree=hc.ward, k=1)
hc.ward2 <- cutree(tree=hc.ward, k=2)
hc.ward3 <- cutree(tree=hc.ward, k=3)
hc.ward4 <- cutree(tree=hc.ward, k=4)

ime = c('dolzina','levi.rob','desni.rob', 'spodnji.rob', 'zgornji.rob')

oldpar <- par(las=1, mfrow=c(1, 3))
nsk <- 2
sk <- hc.ward2
sk.ime <- paste("sk", 1:nsk, sep="")
agr <- aggregate(x=dfz, by=list(sk), FUN=mean)
y <- t(agr[, -1])
matplot(x=seq_along(ime), y=y, type="o", pch=16, ylim=c(-2, 2), xlab="",
        ylab="ovprecje (standardizirane spremenljivke)")
axis(side=1, at=seq_along(ime), labels=ime, las=2)
legend("bottomleft", legend=sk.ime, col=1:nsk, pch=16)
abline(h=0, v=6.5)
nsk <- 3
sk <- hc.ward3
sk.ime <- paste("sk", 1:nsk, sep="")
agr <- aggregate(x=dfz, by=list(sk), FUN=mean)
y <- t(agr[, -1])
matplot(x=seq_along(ime), y=y, type="o", pch=16, ylim=c(-2, 2), xlab="",
        ylab="")
axis(side=1, at=seq_along(ime), labels=ime, las=2)
legend("bottomleft", legend=sk.ime, col=1:nsk, pch=16)
abline(h=0, v=6.5)
nsk <- 4
sk <- hc.ward4
sk.ime <- paste("sk", 1:nsk, sep="")
agr <- aggregate(x=dfz, by=list(sk), FUN=mean)
y <- t(agr[, -1])
matplot(x=seq_along(ime), y=y, type="o", pch=16, ylim=c(-2, 2), xlab="",
        ylab="")
axis(side=1, at=seq_along(ime), labels=ime, las=2)
legend("bottomleft", legend=sk.ime, col=1:nsk, pch=16)
abline(h=0, v=6.5)
par(oldpar)
```

<!-- Tukej je vrjetno potreben se komentar 
Neza: to pomojem zdej nc ni prov ker nevem ce je ta razvrstitev spremenljivk sploh prava....-->

Če si pogledamo skupino 2, ki je enaka na vseh treh grafih(pri vseh treh razvrstitvah) in zavzema podpovprečne vrednosti. 

Ravno obratno vidimo pri skupini 1, ki na prvem grafu zavzema nadpovprečne vrednosti, na drugih dveh pa zavzema podpovprečne vrednosti samo pri dolžini bankovca. Skupina 1 se na drugem in tretjem grafu torej razdeli na podskupine, ker smo tam povečali število skupin.

Skupina 3 pa je v nekaterih primerih nadpovprečna v nekaterih pa podpovprečna(`spodnji.rob`, `zgornji.rob`). Pri zadnjem garfu se skupina 4 pri spremenljivki `dolzina` pribliza povprecju zelo dobro, pri vseh ostalih spremenljivkah je nadpovprecna in pri zadnji mocno podpovprecna.

\newpage

# Nehierarhično razvrščanje

<!--
Izberite/določite najbolj primerno število skupin. Pomagajte si z
rezultati hierarhičnega razvrščanja in dodatno za metodo K-means narišite grafe:
koleno, pseudo F, gap statistika. Vašo izbiro utemeljite. 
-->

## Razvrščanje K-means

K-means je metoda voditeljev oz. nehierarhičnega razvrščanja. Voditelji so "predstavniki skupin", vsaka enota pa pripada skupini, kateremu voditelju je najbližje(razdalja je evklidska) oz. mu je najbolj podobna; voditelj predstavlja povprečje skupine. Spremenljivke pri metodi _k-means_ morajo biti vsaj intervalne. 

Tukaj pri tej metodi mora biti število skupin podamo v naprej, kar je morda slaba lastnost in se glede tega razlikuje od npr. Wardove metode. Na začetku določimo voditelje, potem pa na vsakem koraku vsako enoto priredimo voditelju oz. skupini, kateremu je najbljižja glede na evklidsko razdaljo. Na vsakem koraku se izračunajo novi voditelji kot povprečja skupin. Postopek se zaključi, ko so novi voditelji enaki starim. 

Izberemo tisto razvrstitev, ki ima najmanjšo vrednost Wardove kriterijske funkcije, za katero vemo, da pada z naraščanjem števila skupin. Torej za optimalno število skupin ponavadi vzamemo tisto vrednost, kjer se zgodi t.i. "koleno" funkcije. Če to "koleno" ni jasno razvidno, lahko sklepamo, da skupine niso jasno ločene. Postopek običajno večkrat ponovimo, saj za različne začetne voditelje lahko dobimo različne rešitve, torej razvrstitve v skupine.

```{r echo=FALSE, fig.cap="Vrednost Wardove kriterijske funkcije.", fig.height=4, fig.width=6, out.width="70%"}
# WSS
kmax <- 10
wss <- NULL
for (k in 1:kmax) {
  withinss <- kmeans(x=dfz, # podatki
                     centers=k, # st. skupin
                     nstart=100)$tot.withinss # st. ponovitev
  wss <- c(wss, withinss)
}

plot(x=1:kmax, y=wss, type="b", main="", xlab="stevilo skupin(k)",
     ylab="vrednost Wardowe kriterijske funkcije")
```

<!--TOM: tukej men mogoce izgleda najvecja sprememba pri 2 in 3 -->
Sprememba naklona funkcije izgleda največja pri **2** ali **3** skupinah oziroma je tam "koleno" najbolj razvidno.

## GAP statistika

Pri določevanju števila skupin si lahko pomagamo tudi z GAP statistiko, kjer iščemo skupine, ki so podatki bolj homogeni, kot kjer ni skupin. Gre za primerjavo razdalj znotraj skupin z razdaljami na podatkih brez skupin. Izberemo pa tisto najmanjše število skupin k , kjer je vrednost $GAP(k)$ statistike vsaj tolikšna kot $GAP(k+1) - SE(GAP(k+1))$; $SE$ je standardna napaka GAP statistike.

```{r echo=FALSE, fig.cap="Vrednost GAP statistike.", fig.height=4, fig.width=6, out.width="70%"}
# gap statistika
gap_stat <- clusGap(x=dfz, FUNcluster=kmeans, K.max=kmax)
plot(gap_stat, xlab="stevilo skupin", main="")
```
<!-- 
TOM: tukej se mi zdi da je 3 skuoine ker se gleda kje je najvisja predn zacne padat -->
Na podlagi grafičnega prikaza vrednosti GAP statistike pri različnem številu skupin se odločimo za **3** skupine, saj tam doseže najvišjo točko in začne padati.

## Pseudo F (Calinski - Harabasz indeks)

Uporabimo pa lahko tudi indeks Calinski-Harabasz, ki ocenjuje razmerje med razpršenostjo znotraj skupin in razpršenostjo med skupinami. Uporabljamo ga za oceno primernosti števila skupin v metodi gručenja (angl. _clustering_). Višje vrednosti indeksa Calinski-Harabasz označujejo boljše gručenje, pri čemer optimalno število skupin običajno doseže maksimum tega indeksa.

```{r echo=FALSE, fig.cap="Vrednost Pseudo F oz. Calinski - Harabasz indeksa.", fig.height=4, fig.width=6, out.width="70%"}
# Pseudo F (Calinski and Harabasz index)
pseudoF <- 0
bss <- wss[1] - wss
for (k in 2:kmax) pseudoF <- c(pseudoF, (bss[k]/(k-1)) / (wss[k]/(nrow(dfz)-k)))

plot(x=1:kmax, y=pseudoF, type="b", xlab="stevilo skupin",
     ylab="Pseudo F", main="")
```

Tukaj je maksimum dosežen pri **2** skupinah.

Torej, če povzameva celotno analizo, bi, glede na posamezen graf, izbrala

* WSS: sprememba naklona izgleda največja pri **2** skupinah,
* Pseudo F: maksimum doseze pri **2** skupinah,
* gap statistika: najvišjo točko preden začne padati doseže pri **3** skupinah.

Na podlagi zgornjih analiz in ugotovitev pri hierarhičnem razvrščanju, kjer smo se odločali med 2 ali 3 skupinami, bi se tu določili raje za **3** skupine, kot za 2, saj težimo k večjemu številu skupin kot je 2.

<!--Neza: kaj nej tuki napiseva, zakaj rajs 3 skupine, okej ker si zelimo vec skupin ampak, jst nikjer v zapiskih nimam napisan zakaj točno hočmo več kt 2 skupini, v predavanjih pa tud nekega smiselnega razloga ne najdem, razn to da nočmo premal skupin pa da nočmo preveč skupin...

<!--
Primerjajte vrednost kriterijske funkcije pri različnem številu skupin za Wardovo
metodo in K-means. Katera metoda je boljša? Pri izbranem številu skupin primerjajte
obe razvrstitvi. Izpišite kontingenčno tabelo in izračunajte popravljen Randov indeks.
-->

\newpage

## Primerjava vrednosti kriterijske funkcije za Wardowo metodo in K-means

Primerjala sva tudi vrednosti kriterijskih funkcij za Wardowo metodo in metodo K-means, ker sta podobno oziroma delujeta na isti princip. Je pa metoda K-means boljša, ker išče lokalne minimume, za razliko do Wardove, ki deluje hierarhično in vedno poda enak rezultat. Ocenjujeva sva pa po principu, da ima boljša razvrtitev manjšo vrednost karakteristične funkcije. Pomembno pa je tudi to, da so podatki standardizirani, saj drugače med seboj ne bi bilo primerljivo.

```{r echo=FALSE, results=T}
km1 <- kmeans(x=dfz, centers=1, nstart=1)
km2 <- kmeans(x=dfz, centers=2, nstart=100)
km3 <- kmeans(x=dfz, centers=3, nstart=100)
km4 <- kmeans(x=dfz, centers=4, nstart=100)

# Wardova kriterijska funkcija
WardKF <- function(data, cluster){
  # vsota kvadratov
  # x = ena spremenljivka
  ss <- function(x) sum((x-mean(x))^2)
  # vsota kvadratov znotraj ene skupine po vseh spremenljivkah
  # X = matrika, stolpci so spremenljivke
  withinss <- function(X) sum(apply(X=X, MARGIN=2, FUN=ss))
  # vsota kvadratov vseh skupin
  sum(by(data=data, INDICES=cluster, FUN=withinss))
}

wkf <- NULL
wkf <- rbind(wkf, c(WardKF(dfz, hc.ward1), WardKF(dfz, hc.ward2), WardKF(dfz, hc.ward3), WardKF(dfz, hc.ward4)))
wkf <- rbind(wkf, c(WardKF(dfz, km1$cluster), WardKF(dfz, km2$cluster), WardKF(dfz, km3$cluster), WardKF(dfz, km4$cluster)))
rownames(wkf) <- c("Ward", "Kmeans")
colnames(wkf) <- c("k=1", "k=2", "k=3", "k=4")

kable(wkf, caption = "Primerjava vrednosti kriterijske funkcije za Wardowo metodo in K-means.") %>% 
  kable_styling(full_width=F, latex_options="hold_position")
```

Vidimo da ima v vseh primerih (z izjemo prvega kjer sta enaka) K-means manjšo vrednost, kar si tudi želimo. Primerjavo razvrtitev bomo naredili na številu skupin **k = 3**. 

```{r echo=FALSE, results=T}
# kontingenčna tabela
#table(km4$cluster, c(3, 2, 4, 1)[hc.ward4])

kable(table(km3$cluster, c(1,3,2)[hc.ward3]), caption = "Kontingenčna tabela.") %>% 
  kable_styling(full_width=F, latex_options="hold_position")

# popravljen Randov indeks
r = adjustedRandIndex(x=km3$cluster, y=hc.ward3)
```

Največje elemente imamo na diagonali kontingenčne tabele, tudi te vrednosti niso ekstremno velike(npr. 100). Za izvendiagonalne elemente si želimo, da bi bili čim manjši oziroma zelo blizu 0, kar pa po večini so, ali pa so celo kar enaki 0(izstopa le ena vrednost - 16).

Poglejmo si še Randov indeks, ki predstavlja delež parov enot, ki so si v obeh razbitjih usklajeni -  v obeh razbitjih v isti skupini ali pa v obeh razbitjih v različnih skupinah. Pogledala sva si popravljen Randov indeks, zaradi boljše primerljivosti. Enak je `r round(r, 3)`, kar je nad 0,5, torej gre za neko več kot srednjo podobnost, ampak ne popolno identičnost razbitji, sicer pa večji kot je, boljše je -  vrednost 1 pomeni identični razbitji, vrednost 0 pa, da sta si razbitji tako podobni po slučaju, vrednost 0.5 pa pomeni, da gre za neko srednjo podobnost med razbitji.

\newpage

#  Razvrščanje na podlagi modelov

Tukaj predpostavimo, da so podatki generirani iz multivariatnih normalnih porazdelitev z različnimi parametri oziroma komponentami; vsaka skupina ima svojo multivariatno normalno porazdelitev. Skupina je večja po volumnu, če ima večjo variabilnost, omejimo pa se z domnevami oziroma predhodnim znanjem, kakšne naj bi te skupine bile. Zato si poglejmo porazdelitve spremenljivk ne glede na tip bankovca.

<!-- Ali je porazdelitev spremenljivk primerna za uporabo te metode? Ne glede na
primernost uporabite metodo za razvrščanje na vaših podatkih. Izberite najbolj
primeren model in število skupin. Izbiro utemeljite.
-->

```{r echo=FALSE, fig.cap="Porazdelitve spremenljivk."}
oldpar <- par(las=1, mfrow=c(2, 3))
for (i in seq_along(ime)) {
  hist(data[, ime[i]],
       main=ime[i],
       xlab="",
       ylab="Frekvenca")
}
par(oldpar)
```

Spremenljivka `spodnji.rob`  in tudi `desni.rob` nista porazdeljeni po normalni porazdelitvi, zato ne moremo trditi, da je zadoščen ta pogoj. Ostale so porazdeljene po normalni, nekatere asimetrične v desno(npr. spremenljivka `dolzina`) in nekatere v levo(npr. spremenljivka `levi.rob`).

Tukaj ocenimo število skupin in parametre za vsako skupino ter kateri skupini posamezna enota pripada. V najinem primeru, kjer je predpostavka o multivariatni normalni porazdelitvi kršena, se simulacija ne izkaže za optimalno. Razvrstitev se dela na originalnih podatkih oz. nestandardiziranih podatkih, ker s tem omogočimo različno velikost skupin.

## BIC(Bayes Information Criterion) kriterij

Naredimo torej razvrstitev na originalnih, nestandardiziranih podatkih, kjer funkcija sama izbere naprimernejši model.

```{r echo=FALSE, fig.height=5, fig.width=8, fig.cap="BIC kriterij za originalne podatke.", results=F, out.width="70%"}
df = data[1:5]
mc <- Mclust(data=df, G=1:5)
summary(mc)
plot(x=mc, what="BIC", xlab="stevilo skupin")
```
Na podlagi BIC kriterija (Bayesian Information Criterion), ki zavzame vrednost -1365.42 izberemo model VEE s tremi skupinami, kar pomeni, da gre za elipsoidne(angl. _ellipsoidal_) skupine, ki so različno velike, različnih oblik in enako usmerjene.

Kriterij temelji na "Bayesovski" statistiki, zato lahko določimo tudi apriorne verjetnosti(torej neko naše predhodno znanje oziroma prepričanja). 

```{r, fig.height=4, fig.cap="BIC kriterij (priorControl) za originalne podatke.", fig.height=5, fig.width=8, results=F, out.width="70%"}
# priorControl
mcP <- Mclust(data=df, G=1:5, prior = priorControl())
summary(mcP)
plot(mcP, what = "BIC", xlab="stevilo skupin")
```

Na podlagi BIC kriterija z uporabljenim argumentom o apriornih verjetnostih se odločimo za model EEE s tremi skupinami, kar pomeni, da gre za različno velike skupine, različnih oblik in enake usmerjenosti.

## BIC kriterij na standariziranih podatkih

Poglejmo si še, iz radovednosti, kako je z oceno modela na standariziranih podatkih, ampak vrednosti BIC kriterija niso primerljive med standariziranimi in nestandariziranimi podatki. 

```{r echo=FALSE, fig.height=6, fig.width=8, fig.cap="BIC kriterij za standardizirane podatke.", results=F, out.width="70%"}
mc <- Mclust(data=dfz, G=1:5)
summary(mc)
plot(x=mc, what="BIC", xlab="stevilo skupin")
```

Na podlagi BIC kriterija (Bayesian Information Criterion), ki zavzame vrednost -2466.76	ponovno izberemo model VVE s tremi skupinami.

Tudi tukaj lahko primerjamo z vključitvijo apriornih verjetnosti.

```{r, fig.height=4, fig.cap="BIC kriterij (priorControl) za standardizirane podatke.", fig.height=6, fig.width=8, results=F, out.width="70%"}
# priorControl
mcP <- Mclust(data=dfz, G=1:5, prior = priorControl())
summary(mcP)
plot(mcP, what = "BIC", xlab="stevilo skupin")
```

Tudi tukaj se na podlagi BIC kriterija z uporabljenim argumentom o apriornih verjetnostih se odločimo za model EEE s tremi skupinami, kar pomeni, da gre za različno velike skupine, različnih oblik in enake usmerjenosti.

## Primerjava modelov

Na pogladi BIC kriterja, kjer lahko na spodnjem grafu vidimo primerjavo VEE modela in EEE modela za nestandardizirane in standardizirane podatke, se, v obeh primerih, odločimo za model VEE. Bi pa se pri obeh modelih odločila za **3** skupine, saj vrednost BIC kriterija od tam naprej počasi narašča.

```{r, fig.height=7, fig.width=12, fig.align="center", fig.cap="Primerjava VEE in EEE modela(levo: nestandardizirani podatki, desno: standardizirani podatki)."}
# nestandardizirani
mcSEL <- Mclust(data=df, G=1:5, modelNames = c("VEE", "EEE"))
# modela na treh skupinah
mcVEE <- Mclust(data=df, G = 3, modelNames = "VEE")
mcEEE <- Mclust(data=df, G = 3, modelNames = "EEE")

# standardizirani
mcSEL.s <- Mclust(data=dfz, G=1:5, modelNames = c("VEE", "EEE"))
# modela na treh skupinah
mcVEE.s <- Mclust(data=dfz, G = 3, modelNames = "VEE")
mcEEE.s <- Mclust(data=dfz, G = 3, modelNames = "EEE")

oldpar <- par(las=1, mfrow=c(1, 2))
plot(mcSEL, what="BIC", legendArgs = list(x = "bottomright"), xlab="stevilo skupin", main="Nestandardizirani podatki")
plot(mcSEL.s, what="BIC", legendArgs = list(x = "bottomright"), xlab="stevilo skupin", main="Standardizirani podatki")
par(oldpar)
```

Na podlagi vseh kriterijev se zaradi enostavnosti odločimo za model VEE s tremi skupinami - torej različno velike skupine, različnih oblik in enakih umserjenosti.

\newpage

# Najboljša razvrstitev in predstavitev skupin

<!--5. Predstavitev skupin. Izberite najboljšo razvrstitev po vašem mnenju in predstavite skupine.
a) Izračunajte povprečja standardiziranih spremenljivk po skupinah. Rezultat grafično
prikažite. Skupine opišite po najbolj izstopajočih lastnostih.
b) Skupine analizirajte bolj podrobno po nekaterih izbranih spremenljivkah. Preverite,
ali obstaja povezanost med skupino in temi spremenljivkami. Povezanost analizirajte na podlagi grafičnih prikazov in z ustreznimi izračuni. Interpretirajte moč in smer povezanosti. Preverite, ali je povezanost statistično značilna pri 5 % stopnji značilnosti. Pred analizo navedite, kateri test ste uporabili in zakaj ste izbrali ta test.
-->

Tukaj naju pa zanima kako podobne so si naše razvrstitve, ki sva jih v prejšnjih poglavjih izbrala na podlagi različnih modelov. V prejšnjih poglavjih sva izbirala najboljše razvrstitve in sedaj jih bova med seboj primerjala.

## Primerjava povprečij

Na spodnjem grafu si poglejmo povprečja po skupinah in primerjamo razvrstitve na standardiziranih podatkih.

```{r echo=FALSE, fig.cap="Primerjava razvrstitev na standariziranih podatkih.", fig.height=5, fig.width=12}
# tukej sm dal stevilo skupin na n=3 k so tud boljsi rezultati
oldpar <- par(las=1, mfrow=c(1, 3))
nsk <- 3
sk <- km3$cluster
sk.ime <- paste("sk", 1:nsk, sep="")
agr <- aggregate(x=dfz, by=list(sk), FUN=mean)
y <- t(agr[, -1])
matplot(x=seq_along(ime), y=y, type="o", pch=16, ylim=c(-2, 2), xlab="",
        xaxt="n", ylab="povprecje (standardizirane spremenljivke)", main = "k-means")
axis(side=1, at=seq_along(ime), labels=ime, las=2)
legend("bottomleft", legend=sk.ime, col=1:nsk, pch=16)
abline(h=0, v=6.5)

nsk <- 3
sk <- hc.ward3
sk.ime <- paste("sk", 1:nsk, sep="")
agr <- aggregate(x=dfz, by=list(sk), FUN=mean)
y <- t(agr[, -1])
matplot(x=seq_along(ime), y=y, type="o", pch=16, ylim=c(-2, 2), xlab="",
        xaxt="n", ylab="", main = "Ward")
axis(side=1, at=seq_along(ime), labels=ime, las=2)
legend("bottomleft", legend=sk.ime, col=1:nsk, pch=16)
abline(h=0, v=6.5)

nsk <- 3
sk <- mcVEE.s$classification
sk.ime <- paste("sk", 1:nsk, sep="")
agr <- aggregate(x=dfz, by=list(sk), FUN=mean)
y <- t(agr[, -1])
matplot(x=seq_along(ime), y=y, type="o", pch=16, ylim=c(-2, 2), xlab="",
        xaxt="n", ylab="", main = "VEE(BIC)")
axis(side=1, at=seq_along(ime), labels=ime, las=2)
legend("bottomleft", legend=sk.ime, col=1:nsk, pch=16)
abline(h=0, v=6.5)
par(oldpar)
```


Vrstni red skupin se razlikuje v modelih, ampak če pogledamo sta si Wardov model in k-means model nekoliko bolj podobna. Skupina 1 si je pri modelu na podlagi k-means podobna skupini 1 v modelu na podlagi Ward-a. Podobne so si tudi skupina 3 pri modelu na podlagi k-means in skupina 2 pri Wardu in VEE ter skupina 2 pri k-means je podobna skupini 3 pri Wardu. Do odstopanj prihaja le pri posameznih točkah(npr. pri k-means za skupino 2 je nadpovprečno pri spremenljivki `zgornji.rob`, s tem ko je pri modelu Ward za skupino 3 podpovprečno, pri ostalih spremenljivkah pa sta si skupini dokaj podobni). Pri k-means in Wardu- sta si torek skupini 1 podobni, obe sta nadpovprečni pri vseh spremenljivkah, razen pri spremenljivki `dolzina`, kjer sta podpovprečni. Vidimo lahko tudi, da so si skupina 1 pri k-means in Ward-u in skupina 3 pri VEE(BIC) zelo podobne. Skupina 3 pri k-means in skupina 2 pri Ward-u sta edini, ki sta vedno podpovprečni, vedno nadpovprečne skupine pa ni.

<!--
Skupina 1 ima podpovprečno vrednost dolžine, vse ostale mere robov pa so nadpovprečne. \
Skupina 2 je edina od skupin, ki ima nadpovprečno dolžino in ima skoraj vse mere robov prav tako nadpovprečne z izjemo spodnjega roba.\
Skupina 3 je edina, ki ima povprečja vseh spremenljivk podpovprečne.
-->

## Wardova kriterijska funkcija

Poglejmo si še primerjavo razvrstitev na podlagi Wardove kriterijske funkcije.

```{r echo=FALSE, message=FALSE, warning=FALSE, results=T}
wkf <- NULL
wkf <- rbind(wkf, c(WardKF(dfz, km3$cluster), WardKF(dfz, hc.ward3)))
colnames(wkf) <- c("k-means", "Ward")

kable(wkf, caption = "Primerjava vrednosti Wardove kriterijske funkcije za vse metodi k-means in Ward.") %>% 
  kable_styling(full_width=F, latex_options="hold_position")
```

Glede na vrednost Wardove kriterijske funkcije je najboljša metoda k-means razvrstitev s tremi skupinami, nato ji sledi Wardova. Zato se odločimo za k-means metodo.

## Popravljen Randov indeks
Poglejmo si še kako podobne so razvrstitve glede na popravljen Randov indeks. 

```{r echo=FALSE, results=T}
# kako podobni sta si razvrstitvi; popravljen randov indeks
r = data.frame( wk = round(adjustedRandIndex(hc.ward3, km3$cluster),3), # ward in k-means
                wv = round(adjustedRandIndex(hc.ward3, mcVEE.s$classification),3), #ward in VEE
                kv = round(adjustedRandIndex(km3$cluster, mcVEE.s$classification),3)) # k-means in Vee
colnames(r) <- c("Ward in k-means", "Ward in VEE(BIC)", "k-means in VEE(BIC)")

kable(r, caption = "Primerjava popravljenega Randovega indeksa.") %>% 
  kable_styling(full_width=F, latex_options="hold_position")
```

Pri vseh treh primerjavah je vrednost indeksa večja od $0.5$, kar pomeni da gre za dokaj podobna razbitja na skupine. Indeks pri Ward in k-means je najvišji, torej gre za najbolj podobno razbitje na skupinah.

## Število enot v skupinah

Na spodnjem izpisu si oglejmo število enot v posamezni skupini in povprečja na nestandardiziranih podatkih za vse modele.

```{r echo=FALSE, message=FALSE, warning=FALSE, results=T}
# dodamo skupine v podatke
nsk = 3
sk.k = km3$cluster
sk.w = hc.ward3
sk.v = mcVEE.s$classification
sk.k.ime = paste("sk", 1:nsk, sep="")
sk.w.ime = paste("sk", 1:nsk, sep="")
sk.v.ime = paste("sk", 1:nsk, sep="")

data$cluster.k = sk.k
data$cluster.w = sk.w
data$cluster.v = sk.v
data$skupina.k = factor(x=sk.k, labels=sk.k.ime)
data$skupina.w = factor(x=sk.w, labels=sk.w.ime)
data$skupina.v = factor(x=sk.v, labels=sk.v.ime)

# velikost skupin
kable(table(data$skupina.k), caption = "Velikost skupin pri metodi k -means.", 
      col.names= c("skupina", "velikost")) %>% 
  kable_styling(full_width=F, latex_options="hold_position")
```


```{r echo=FALSE, message=FALSE, warning=FALSE, results=T}
kable(table(data$skupina.w), caption = "Velikost skupin pri Ward metodi.", 
      col.names= c("skupina", "velikost")) %>% 
  kable_styling(full_width=F, latex_options="hold_position")
```


```{r echo=FALSE, message=FALSE, warning=FALSE, results=T}
kable(table(data$skupina.v), caption = "Velikost skupin pri VEE(BIC).", 
      col.names= c("skupina", "velikost")) %>% 
  kable_styling(full_width=F, latex_options="hold_position")
```

Vidimo, da se število enot glede na skupine pri metodah razlikuje, s tem ko povprečja nestandardiziranih vrednosti Likartovih spremenljivk `dolzina` in `mere` niso tako zelo različne po skupinah.

## Povezanost skupin s tipom bankovca

```{r fig.dim=c(5,5), echo=FALSE, fig.cap="Povezanost skupin pri k-means.", out.width="70%"}
### OPIS LASTNOSTI SKUPIN
# povezanost skupin z ostalimi spremenljivkami
# graficni prikaz
( tabela <- 100*proportions(x=table(data$tip, data$skupina.k), margin=2) )
barplot(height=tabela, legend.text=T, ylim=c(0, 130), args.legend=list(x="top"), las=1)
abline(h=(100*table(data$tip)/nrow(df))[1], col="red")
```

Skoraj vse enote v skupini 1 predstavljajo ponarejene bankovce. Torej skupina 1 je povezana s tipom bankovca (pravimi bankovci). \
Skupina 2 ima skoraj enakomerno zastopanost med pravimi in ponarejenimi bankovci. \
V skupini 3 pa so skoraj vsi bankovci pravi, torej je tudi povezana s tipom bankovca.

<!-- Neza: kle sm dala sam pozitivno pa negativno vn ker pac nevem kako nej drugac popravim...-->

```{r echo=FALSE}
# hi kvadrat test
# kontingenzna tabela
tabela <- table(data$tip, data$skupina.k)
chisq.test(x=tabela, correct=F)
```
Hi-kvadrat test, pri dveh stopinjah prostosti in pri stopnji značilnosti 0.05 je z p-vrednostjo $p<0.001$ pokazal, da je statistično značilna povezanost med skupino in tipom bankovca. 

Preverimo še moč povezanosti s Cramerjevim V koeficientom.

```{r}
# moc povezanosti (Cramerjev V)
tabela <- table(data$tip, data$skupina.k)
hi2 <- chisq.test(x=tabela, correct=F)$statistic
n <- sum(tabela)
dim <- min(nrow(tabela), ncol(tabela)) - 1
sqrt(hi2/(n*dim))
```

Kramarjev V ima vrednosti 0.85, kar pomeni, da je povezanost med skupinama in tipom bankovcev zelo močna.

## Povezanost skupin z spremenljivko `diagonala`

```{r fig.dim=c(5,5), echo=FALSE, fig.cap="Povezanost skupin s spremenljivko diagonala pri k-means.", out.width="70%"}
boxplot(diagonala~skupina.k,data=data, xlab = "skupine", ylab="diagonala")
mx <- aggregate(diagonala ~ skupina.k, data=data, FUN=mean)[, -1]
abline(h=mean(data$diagonala), col="red")
points(x=mx, col="blue", pch="X")

```

<!-- te komentarje je treba se za Warda in VEE-->

Skupina 1 vsebuje (z izjemo enega) bankovce, ki imajo podpovprečno vrednost diagonale in povezanost skupine 1 in diagonale je negativna. Glede na to, da skupina 1 vsebuje same ponarejene bankovce, ki imajo v povprečju manjšo diagonalo, je to povsem smislno, zato nas tudi nadpovprečne vrednosti diagonale ne presenetijo v tretji skupini.\
Povprečje vrednosti diagonal bankovcev v skupine 2 se ujema s povprecjem celotnega vzorca, vendar pa so v njej vsebovani bankovci, ki imajo dosti podpovprečno ali nadpovprečno vrednost diagonale, kar je smiselno, saj vsebuje ponarejene in prave bankovce.\
Bankovci v skupini 3 imajo torej vsi nadpovprečno vrednost diagonale saj so vsi pravi. Povezanost te skupine in vrednosti diagonale je pozitivna.

```{r}
# test povezanosti (vec kategoriji = anova)
# predpostavljamo neenake variance na populaciji
oneway.test(diagonala ~ skupina.k, data=data, var.equal=F)
```

Naredili smo enostranski ANOVA test povezanosti, pri predpostavki različnih varianc. Test je bil statistično značilen ($p<0.001$), s čimer smo zavrnili ničelno hipotezo, ki pravi, da so povprečja (v našem primeru povprečje vrednosti diagonal) v vseh skupinah enaka.

\newpage

# Vsebinski povzetek

V nalogi sva obravnavali različne metode razvrščanja v skupine. Iskala sva najbolj primerno število skupin, da se le-te med seboj čimbolj razlikujejo glede na lastnosti. 

Pri hierarhičnemu razvrščanju je bila izbrana Wardova metoda, pri nehierarhičnemu smo se odločili za metodo voditeljev in pri razvrščanju na podlagi modelov pa za model VEE. Povsod smo imeli tri skupine. Po primerjanju teh treh metod, na podlagi Wardove kriterijske funkcije, se odločimo za metodo voditeljev(k-means). 

V nadaljevanju pa sva ugotovila, da obstaja povezanost med skupinami in tipom bankovcev, glede na Kramarjev V pa je tudi zelo močna. Ugotovila sva tudi in s testom potrdila, da povprečja diagonal niso enaka v najinih treh skupinah, kar je logično glede na razporeditev bankovcev po skupinah.

\newpage

# Viri

Flury, B., Riedwyl, H. (1988). _Multivariate Statistics: A practical approach._ London: Chapman & Hall, Tables 1.1 and 1.2, pp. 5-8.

Pohar P., M.(2024). _Osnove teoretične statistike._

Polajnar, E.(2024). _Multivariatna analiza._ 

Smrekar, J.(2024). _Bayesova statistika._

Žiberna, A.(2024). _Multivariatna analiza._ 

