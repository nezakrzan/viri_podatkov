---
title: "Domaca naloga 4"
author: "Neža Kržan, Tom Rupnik Medjedovič"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
header-includes:
- \usepackage[slovene]{babel}
- \usepackage{float}
- \usepackage[T1]{fontenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", fig.pos = "H", message = FALSE, warning = FALSE, results = F, fig.height =3, fig.width = 5)

# potrebne knjižnice
library(ggplot2)
library(tidyr)
library(dplyr)
library(knitr)
library(kableExtra)
library(gridExtra)
library(psych) #describe
library(corrplot)
library(VIM)
library(multiUS)
library(mice)
library(arm)
library(randomForest)

# seme
set.seed(2024)
```

<!--
Navodila:
Analizirajte realne podatke (lahko izberete katerikoli podatki), ki vsebujejo zadostno število manjkajočih vrednosti, in uporabite katerokoli metodo (v osnovi multivariatno), ki jo želite uporabiti. Zadostno število manjkajočih enot pomeni, da bi pri uporabi izbrane metode na popolnih enotah (seznamno brisanje) iz podatkov odstranili vsaj 30 % enot. Tukaj manjkajočih vrednosti ne smete ustvariti sami; manjkajoče vrednosti morajo že obstajati v izvirnih podatkih. Pri podatkih s področja družboslovja je velik delež pogosto nepopoln zaradi "občutljivih" spremenljivk, npr. "dohodka". 

- Ocenite (na podlagi katere analize, testa in poznavanja področja/podatkov), kakšen je mehanizem manjkajočih vrednosti (po Rubinu). 

- Ocenite, katera metoda za obravnavo manjkajočih vrednosti je najprimernejša. Uporabiti morate vsaj:
      - metodo, ki se vam zdi najprimernejša,
      - vsaj eno metodo ignoriranja manjkajočih vrednosti (analiza na podlagi razpoložljivih ali popolnih enot),
      - in vsaj eno drugo metodo za obravnavo manjkajočih vrednosti (morda metodo, ki se vam zdi druga najprimernejša).
      
Ne glede na to, katera metoda se vam zdi najprimernejša, morate uporabiti vsaj eno metodo, ki sem jo v predavanjih/slajdih označil kot priporočeno - Slajd 19. Interpretirajte rezultate. Prav tako komentirajte, kaj vam podobnosti ali razlike v rezultatih različnih metod povedo o mehanizmu manjkajočih vrednosti. Na koncu morate obvezno navesti, katera metoda se vam zdi v danem primeru najprimernejša.
-->

```{r}
# uvoz podatkov
data = read.csv("pima_indians_diabetes_dataset.csv", header = TRUE, sep = ",", na.strings = c(""))
```


# Cilj naloge

Analizirali bomo podatke o diabetesu Nacionalnega inštituta za diabetes, prebavne in ledvične bolezni, kateri vsebujejo več medicinskih napovednih spremenljivk in eno ciljno spremenljivko. Podatki imajo veliko mankajočih enot(več kot 30\%), zato bova v nalogi definirala oz. ocenila, kakšen je mehanizem mankajočih vrednosti(po Rubinu) in obravnavala mankajoče vrednosti po treh različnih metodah. \
Zanima naju torej mehanizem mankajočih vrednosti(zakaj in kako manjkajo podatki v podatkovnem nizu), da bova potem ustrezno izbrala metodo imputacije in jo primerjala še z drugima dvema metodama, ki se nama bosta zdeli primerni.


# Podatki
Izbrala sva si zdravstvene podatke žensk indijanskega plemena Pima, ki so starejše od 21 let. Glavni cilj tega niza je napovedati, ali ima posameznica diabetes, na podlagi različnih medicinskih spremenljivk:

- `Pregnancy` (število nosečnosti): Število nosečnosti, ki jih je imela ženska.
- `Glucose` (glukoza v krvi): Raven glukoze v krvi po 2 urah oralnega glukoznega testa.
- `BloodPressure` (krvni tlak): Krvni tlak (v mmHg).
- `SkinThickness` (debelo tkivo): Debelina kožnega gubca (v mm) na tricepsu, merjeno za testiranje telesne maščobe.
- `Insulin` (inzulin): Raven inzulina (v $\mu$U/ml) v krvi.
- `BMI` (Body Mass Index): Indeks telesne mase (BMI).
- `DiabetesPedigree` (genetska nagnjenost): Indikator, ki kaže, koliko je posameznica nagnjena k razvoju diabetesa na podlagi dednosti. 
- `Age` (starost): Starost posameznice v letih.
- `Class` (diabetes diagnoza): Ciljna spremenljivka, ki označuje, ali ima posameznica diabetes (1) ali ne (0). To je binarna spremenljivka, ki jo želimo napovedati na podlagi drugih spremenljivk.

Poglejmo si osnovne statistike podatkov, iz katerih vidimo nekatere izjemne vrednosti, kot so npr. število nosečnosti 17, vrednost inzulina 846, debelost kože 99, ... Ker naju zanima analiza mankajočih vrednosti, podatkov podrobneje ne bova analizirala.

```{r, results="hold"}
selected_stats_org = describe(data) %>% 
  dplyr::select(-vars, -kurtosis, -skew, -trimmed, -mad, -range)
kable(selected_stats_org,
      align = "c", digits = 2,
      caption = "Opisne statistike podatkov.") %>%
kable_styling( full_width = F, 
                position = "center", latex_options = "H")
```

Podatkovni niz vsebuje `r nrow(data)` primerov in torej vsak primer vključuje 8 merjenih spremenljivk in diagnozo(`Class`) - oseba ima diabetes(vrednost 1), oseba nima diabetesa(vrednost 0). Podatki vsebujejo veliko količino mankajočih vrednosti, kar lahko vidimo na spodnjem grafu glede na posamezno spremenljivko. Vidimo, da spremenljivke, kot so starost(`Age`), število nosečnosti(`Pregnant`), diagnoza(`Class`) in genetska nagnjenost(`DiabetesPedigree`) nimajo mankajočih vrednosti, torej imamo mankajoče vrednosti samo pri spremenljivkah, ki so bile verjetno izmerjene s strani medicinskega osebja.

```{r, results=T, fig.cap="Odstotek mankajočih vrednosti pri posamezni spremenljivki in vizualizacija.", fig.height =5}
library(naniar)
vis_miss(data)
```

Za lažjo predstavo si poglejmo grafe spremenljivk v naših podatkih, iz katerih vidimo, da je večina spremenljivk asimetričnih v desno.

```{r include=FALSE, results=FALSE}
data$Class = as.factor(data$Class)
g1 <- ggplot(data, aes(x=Pregnant)) + 
    geom_density() + 
    theme_bw()+
    labs(y = "gostota") 
g2 <- ggplot(data, aes(x=Pregnant, fill=Class)) + 
    geom_density(alpha=0.4) + 
    theme_bw()+
    labs(y = "gostota") 
g_1 = grid.arrange(g1, g2, ncol=2, top = paste("spremenljivka Pregnant"))
  
g1 <- ggplot(data, aes(x=Glucose)) + 
    geom_density() + 
    theme_bw()+
    labs(y = "gostota") 
g2 <- ggplot(data, aes(x=Glucose, fill=Class)) + 
    geom_density(alpha=0.4) + 
    theme_bw()+
    labs(y = "gostota") 
g_2 = grid.arrange(g1, g2, ncol=2, top = paste("spremenljivka Glucose"))

g1 <- ggplot(data, aes(x=BloodPressure)) + 
    geom_density() + 
    theme_bw()+
    labs(y = "gostota") 
g2 <- ggplot(data, aes(x=BloodPressure, fill=Class)) + 
    geom_density(alpha=0.4) + 
    theme_bw()+
    labs(y = "gostota") 
g_3 = grid.arrange(g1, g2, ncol=2, top = paste("spremenljivka BloodPressure"))

g1 <- ggplot(data, aes(x=SkinThickness)) + 
    geom_density() + 
    theme_bw()+
    labs(y = "gostota") 
g2 <- ggplot(data, aes(x=SkinThickness, fill=Class)) + 
    geom_density(alpha=0.4) + 
    theme_bw()+
    labs(y = "gostota") 
g_4 = grid.arrange(g1, g2, ncol=2, top = paste("spremenljivka SkinThickness"))

g1 <- ggplot(data, aes(x=Insulin)) + 
    geom_density() + 
    theme_bw()+
    labs(y = "gostota") 
g2 <- ggplot(data, aes(x=Insulin, fill=Class)) + 
    geom_density(alpha=0.4) + 
    theme_bw()+
    labs(y = "gostota") 
g_5 = grid.arrange(g1, g2, ncol=2, top = paste("spremenljivka Insulin"))

g1 <- ggplot(data, aes(x=BMI)) + 
    geom_density() + 
    theme_bw()+
    labs(y = "gostota") 
g2 <- ggplot(data, aes(x=BMI, fill=Class)) + 
    geom_density(alpha=0.4) + 
    theme_bw()+
    labs(y = "gostota") 
g_6 = grid.arrange(g1, g2, ncol=2, top = paste("spremenljivka BMI"))

g1 <- ggplot(data, aes(x=DiabetesPedigree)) + 
    geom_density() + 
    theme_bw()+
    labs(y = "gostota") 
g2 <- ggplot(data, aes(x=DiabetesPedigree, fill=Class)) + 
    geom_density(alpha=0.4) + 
    theme_bw()+
    labs(y = "gostota") 
g_7 = grid.arrange(g1, g2, ncol=2, top = paste("spremenljivka DiabetesPedigree"))

g1 <- ggplot(data, aes(x=Age)) + 
    geom_density() + 
    theme_bw()+
    labs(y = "gostota") 
g2 <- ggplot(data, aes(x=Age, fill=Class)) + 
    geom_density(alpha=0.4) + 
    theme_bw()+
    labs(y = "gostota") 
g_8 = grid.arrange(g1, g2, ncol=2, top = paste("spremenljivka Age"))
```

```{r, fig.cap="Porazdelitev spremenljivke v podatkovnem nizu, kjer je  Class ciljna spremenljivka, ki označuje, ali ima posameznica diabetes (1) ali ne (0).", results=T, fig.height = 15, fig.width = 8}
grid.arrange(g_1, g_2, g_3, g_4, g_5, g_6, g_7, g_8, nrow=8, ncol = 2)
```

# Mehanizem mankajočih vrednosti

Za začetek si poglejmo korelacije med mankajočimi vrednostmi na spodnji korelacijski matriki. Opazimo nekaj pozitivnih korelacij, kar pomeni, da če imamo mankajočo vrednost pri eni spremenljivki, obstaja večja verjetnost, da bo tudi pri drugi. \
Torej če imamo mankajočo vrednost pri spremenljivki `Insulin`, potem obstaja večja verjetnost, da bomo imeli mankajočo vrednost tudi pri spremenljivki `SkinThickness`(tudi pri `BloodPressure`).  Če imamo mankajočo vrednost pri spremenljivki `SkinThickness`, obstaja večja verjetnost, da bomo imeli mankajočo vrednost še pri `BloodPressure`. Če pa bomo imeli mankajočo vrednost pr spremenljivki `BMI`, potem obstaja večja verjetnost, da bomo imeli mankajočo vrednost tudi pri spremenljivki `BloodPressure`. Iz tega bi lahko sklepali, da bo  t-test, ki ga uporabljamo za MAR testiranje(_missing at random_), pokazal, da odsotnost podatkov pri spremenljivkah `SkinThickness`, `Insulin`, `BloodPressure` in `BMI` ni naključno, saj vidimo, da je odsotnost podatkov pri določenih spremenljivkah povezano.

```{r fig.cap="Korelacije med mankajočimi vrednostmi.", fig.height=3, fig.width=5, results=T}
# Korelacije med mankajočimi vrednostmi
isMiss = is.na(data[,2:6])
missCor = cor(isMiss)
rownames(missCor) = colnames(missCor) = colnames(data[,2:6])
missCor[is.na(missCor)] = 0
corrplot::corrplot(missCor, method = 'number', number.cex=0.75) 
```

Poglejmo si še vzorce mankajočih vrednosti. \
Najprej si poglejmo glede razvrstitev spremenljivk, kjer imamo največ mankajočih vrednosti, torej spremenljivki `SkinThickness` in `Insulin`. Iz vzorev na spodnjih grafih bi lahko rekli, da če imamo vrednost pri spremenljivki `Insulin`, jo imamo tudi pri drugih spremenljivkah(le dve izjemi), če pa nimamo vrednosti pri spremenljivi `SkinThickness`, jo nimamo tudi pri spremenljivki `Insulin` in obstaja velika verjetnost, da je ne bomo imeli tudi pri spremenljivki `BloodPressure`.

```{r, results=T, fig.caption="Razvrstitev mankajočih vrednosti glede na spremenljivko SkinThickness(levo) in Insulin(desno).", fig.height =4, fig.width = 8}
par(mfrow=c(1,2))
matrixplot(data, sortby="SkinThickness", cex.axis = 0.6) # ce manka SkinThickness pol manka tud Insulin 
matrixplot(data, sortby="Insulin", cex.axis = 0.6) # Ce je insulin potem mamo vse podatke, razn dveh izjem
```

Ker je večina mankajočih vrednostih pri spremenljivkah `SkinThickness` in `Insulin`, nas sicer zanimajo predvsem razvrstitve glede na druge spremenljivke, zato so to tudi oglejmo. 

Iz spodnjega grafa imamo občutek, da obstaja večja verjetnost mankajočega podatka pri spremenljvkah `Insuline` in `SkinThickness` ob določenem številu nosečnostih pri ženskah. Pri razvrstitvi glede na spremenljivko `Glucose` ne zaznamo nekega vzorca.
<!-- Tom01: jst bi tle mogoce rekel da ni zaznat nekega vzorca tako ce uredimo po nosecnosti kot tudi po Glucose...ker se mi zdi da so pri nosecnosti tud dost nakljucno razporejene ostale vrednosti..ceprav s kasnejsimi testi se je pa izkazalo kot da je neka povezanost, tko da sploh nevem-->

```{r, results=T, fig.caption="Razvrstitev mankajočih vrednosti glede na spremenljivko Pregnant(levo) in Glucose(desno).", fig.height =4, fig.width = 8}
par(mfrow=c(1,2))
matrixplot(data, sortby="Pregnant", cex.axis = 0.6) # Večje število nosečnosti, večja verjetnost mankajočega podatka pri Insuline oziroma pri nekaterih vrednostih Pregnant tudi mankajoča vrednost Insulin(imava kr neki rdečih "kvadratkov"), mogoce tudi SkinThickness 
matrixplot(data, sortby="Glucose", cex.axis = 0.6)
```

Iz spodnjega grafa se nam zdi, da če imamo mankajočo vrednost pri spremenljivki `BloodPressure`, potem obstaja velika verjetnost, da bomo imeli mankajoče vrednosti tudi pri spremenljivkah `SkinThickness` in `Insulin`. Prav tako obstaja večja verjetnost mankajoče vrednosti pri teh dveh spremenljivkah in še pri spremenljivki `BlodPressure`, če imamo mankajočo vrednost pri spremenljivki `BMI`.

```{r, results=T, fig.caption="Razvrstitev mankajočih vrednosti glede na spremenljivko BloodPressure(levo) in BMI(desno).", fig.height =4, fig.width = 8}
par(mfrow=c(1,2))
matrixplot(data, sortby="BloodPressure", cex.axis = 0.6) # aha neki vidm, ce manka BloodPressure, pol manka tud SkinThickness pa Insulin(mogoce to mer ena oseba pa je en dan ni blo v sluzbo :))
matrixplot(data, sortby="BMI", cex.axis = 0.6) # ce ni BMI potem obstaja velika verjetnost, da imamo mankajočo vrednost tudi pri spremenljivkah Insulin, SkinThickness, BloodPressure
```

Na spodnjih treh grafih pa lahko vidimo, da je pri manjših vrednostih spremenljivke `DiabetesPedigree` in višji starosti več mankajočih vrednosti spremenljivke `Insulin`.

```{r, results=T, fig.caption="Razvrstitev mankajočih vrednosti glede na spremenljivko DiabetesPedigree(levo), Age(sredina) in Class(desno).", fig.height =4, fig.width = 8}
par(mfrow=c(1,3))
matrixplot(data, sortby="DiabetesPedigree", cex.axis = 0.6) # mogoče se mi zdi: pri manjših vrednostih spremenljivke DiabetesPedigree več mankajočih vrednosti pri spremenljivki Insulin
matrixplot(data, sortby="Age") # Pri visoki starosti večja verjetnost mankajočih vrednosti pri spremenljivkah Insulin in SkinThickness
matrixplot(data, sortby="Class", cex.axis = 0.6)# ni vzorca
```

V nadaljevanju sva izvedla več t-testov za preverjanje ali je odsotnost podatkov pri določenih spremenljivkah MAR(_missing at random_) ali ne. S testom sva testirala ali je povprečje posamezne spremenljivke v obeh skupinah(1. skupina so podatki, ki imajo vrednost druge spremenljivke, 2. skupina pa podatki, ki nimajo vrednost neke druge spremenljivke) enako, primer ničelne hipoteze, ki sva jo testirala

$H_0$ : Povprečji sprem. BMI v obeh skupinah (tistih, ki imajo podatke za Insulin in tistih, ki nimajo podatkov za Insulin) sta enaki.

S pomočjo testov sva ugotovila, da mankajoči podatki pri spremenljivki `Insulin` niso naključni, saj rezultati testov nakazujejo, da so mankajoče vrednosti povezane s številom nosečnosti, da obstaja večja verjetnost mankajočega podatka pri starejših ženskah, pri tistih z višjim krvnim tlakom(`BloodPressure`) in nižjimi vrednostmi spremenljivke `DiabetesPedigree`.  Mankajoči podatki pri spremenljivki so verjetno MAR(_missing at random_) ali celo NMAR(_not missing at random_), ker so torej odvisne od drugih spremenljivk(ki načeloma ne manjkajo) in od mankajočih vrednosti. \
Prav tako je odsotnost podatkov pri spremenljivki `SkinThickness` povezana z vrednostmi pri spremenljivki `Pregnant` in višjim krvnim tlakom(sprem. `BloodPressure`) - povprečne vrednosti krvnega tlaka so v skupini z manjkajočimi podatki `SkinThickness` višje. Poleg tega so mankajoči podatki `SkinThickness` povezani še z višjo povprečno starostjo(`Age`) in nižjimi vrednostmi `DiabetesPedigree`. Torej odsotnos podatkov v spremenljivki morda je MAR(_missing at random_) ali celo NMAR(_not missing at random_), ker so torej odvisne od drugih spremenljivk(ki načeloma ne manjkajo) in od mankajočih vrednosti. \
Pri mankajočih vrednostih spremenljivke smo testirali, ali na mankajoče vrednosti kaj vpliva prisotnost/odsotnost podatko spremenljivk `BMI` in `SkinThickness` - glede na zgornjo korelacijski matriko. Ugotovila sva, da so manjkajoči podatki za sprem. `BloodPressure` verjetno MCAR(Missing Completely At Random), saj prisotnost manjkajočih podatkov ni povezana z vrednostmi `BMI` ali `SkinThickness`.\
Prav tako sva pri mankajočih vrednostih spremenljivke `Glucose` ugotovila, da so verjetno MCAR(Missing Completely At Random), saj prisotnost manjkajočih podatkov ni povezana z vrednostmi nobene druge spremenljivke.

Poleg tega sva prišla do zaključka, da je verjetnost za mankajočo vrednost pri posamezni spremenljivki(z izjemo sprem. `BMI`) večja pri ženskah, ki imajo diabetes, kot pri tistih, ki ga nimajo.

S pomočjo $\chi^2$-testa, ki preučuje ali obstaja statistično značilna povezava med manjkajočimi vrednostmi v posamezni spremenljivki in razredi v spremenljivki `Class`, sva ugotovila, da mankajoče vrednosti pri spremenljivkah niso statistično povezane z razredom `Class`. Razred, ki označujej prisotnost ali odsotnost sladkorne bolezni, torej ne vpliva na to, ali manjkajo podatki za spremenljivke.

# Logistična regresija in imputacija mankajočih vrednosti

S pomočjo logistične regresije (`glm()`) bova na podlagi različnih medicinskih spremenljivk (meritev) poskusila napovedati, ali ima posameznica diabetes. Pri tem bova uporabila različne metode za obravnavo mankajočih vrednosti. Najprej bova preverila kakšne vrednosti koeficientov dobimo v primeru, da uporabimo podatke takše kakršni so (originalne). Nato bova s pomočjo metode `listwise deletion` ohranila le tiste statistične enote, ki imajo zabeležene podatke vseh spremenljivk. Manjkajoče vrednosti (`NA`) bova z metodo *odločitvenih dreves* (`random forest`) izračunala oz. "zapolnila" ter naredila logistično regresijo. Za konec pa bova preverila kakšne rezultate dobimo v primeru uporabe metode *multiple(stohastične) imputacije preko verižnih enačb* (`MICE`).

```{r "formula za logisticno regresijo"}
 f <- formula(Class ~ .)
```


## Originalni (prvotni podatki)

Najprej preverimo kakšne vrednosti koeficientov in pripadajočih 95% intervalov zaupanja dobimo v primeru, da za modeliranje uporabimo originalne (nespremenjene podatke). Pri izvajanju tega sva ugotovila, da funkcija za logistično regresijo `glm()` ne sprejema mankajočih vrednosti in že sama po sebi izvaja metodo `listwise deletion`. 

```{r "logisticna regresija org podatki", results="hold"}
model_org <- glm(f, data=data, family = binomial(link="logit"))
# funkcija glm sama po sebi izbrise vrstice z mankajočimi podatki (376 vrstic)

# podatki uporabljeni za izracun koef in IZ
podatki_model = model_org$model

selected_stats = describe(podatki_model) %>% 
  dplyr::select(-vars, -kurtosis, -skew, -trimmed, -mad, -range, -median, -min, -max)
selected_stats_org = selected_stats_org %>% dplyr::select(-median, -min, -max)
selected_stats_org <- rbind(selected_stats_org[nrow(selected_stats_org), ], selected_stats_org[-nrow(selected_stats_org), ])
opisne_statistik = cbind(selected_stats, selected_stats_org) 
kable(opisne_statistik,
      align = "c", digits = 2,
      caption = "Osnovne opisne statistike podatkov.") %>%
kable_styling(full_width = F, 
                position = "center", latex_options = "H") %>%
  add_header_above(c(" " = 1, "listwise deletion" = 4, "izvirni podatki" = 4))
```

Če natančneje pogledamo zgornjo tabelo opisnih statistik lahko opazimo, da so razlike med statistikami, ki smo jih naredili na začetku. Funkcija `glm()` sama po sebi odstrani vse vrstice, ki vsebujejo vsaj eno `NA` vrednost. To je enako kot bi naredili _listwise deletion_. To lahko opazimi tudi iz stolpca, ki prikazuje število enot, na katerih so izračunane opisne statistike (vse vrednosti so enake $392$).

Ker bi, ne glede na to katero preprosto metodo bi uporabila za obravnavo mankajočih vrednosti (*listwise deletion* ali *pairwise deletion*), bili rezultati identični zgornjim, tema dvema metodama ne bova posvečala velike pozornosti, bova pa prikazala rezultate metode kot eno izmed možnosti.

```{r "logisticna regresija podatki brez NA (listwise deletion)"}
brez_na <- complete.cases(data)
model_brez_na <- glm(f, data=data[brez_na,], family = binomial(link="logit"))
```

## Odločitvena drevesa

Kot naslednjo metodo, s katero bova nadomestila manjkajoče vrednosti v podatkih, sva si izbrala metodo odločitvenih dreves. Gre za metodo, ki dobro deluje na velikih podatkih, je robustna za nelinearnost, dobro deluje tudi v primeru osamelcev in jo lahko uporabimo tako na številskih kot tudi kategoričnih spremenljivkah. Občutek imava, glede na najine podatke, da bo to dobra metoda, ker imava velik nabor podatkov, večino številske spremenljivke in nekaj ekstremnih vrednosti, ki so osamelci(lahko vidimo v tabeli opisnih statistik podatkov na začetku). Odločila sva se za deterministični pristop vstavjanja mankajočih vrednosti, torej, da vstavljava le napovedi(brez slučajne napake modela).

Metoda deluje iterativno - pri vsakem koraku izboljša imputirane vrednosti na osnovi modela, ki ga gradi z uporabo predhodno imputiranih podatkov. Z večanjem števila iteracij običajno dobimo boljše rezultate. Izvedla sva imputacije na podlagi 1 iteracije, petih in desetih. Ker najin nabor podatkov ni tako zelo ogromno velik, kot so ponavadi podatki pri strojnem učenju(kamor spadajo odločitvena drevesa), se nama zdi, da bo 10 iteracij več kot dovolj, pri dveh iteracijah pa se verjetno imputirane vrednosti še ne bodo stabilizirale.

V spodnjih tabelah lahko vidimo primerjavo med osnovnimi statistikami pri originalnih podatkih in podatkih z imputiranimi mankajočimi vrednostmi.

```{r "priprava podatkov random forest"}
# dve iteraciji
dataRF_dve <- rfImpute(f, data, iter=2)
model_RF_dve <- glm(f, data=dataRF_dve, family = binomial(link="logit"))

# pet iteracij
dataRF_pet <- rfImpute(f, data, iter=5)
model_RF_pet <- glm(f, data=dataRF_pet, family = binomial(link="logit"))

# deset iteracij
dataRF_deset <- rfImpute(f, data, iter=10)
model_RF_deset <- glm(f, data=dataRF_deset, family = binomial(link="logit"))
```

```{r "logisticna regresija random forest", results="hold"}
# dve iteraciji
selected_stats_dve = describe(dataRF_dve) %>% 
  dplyr::select(-vars, -kurtosis, -skew, -trimmed, -mad, -range, -median, -min, -max)
opisne_statistik_dve = cbind(selected_stats_dve, selected_stats_org) 
kable(opisne_statistik_dve,
      align = "c", digits = 2,
      caption = "Opisne statistike podatkov pri dveh iteracijah.") %>%
kable_styling( full_width = F, 
                position = "center", latex_options = "H") %>%
  add_header_above(c(" " = 1, "odločitvena drevesa" = 4, "izvirni podatki" = 4))

# pet iteracij
selected_stats_pet = describe(dataRF_pet) %>% 
  dplyr::select(-vars, -kurtosis, -skew, -trimmed, -mad, -range, -median, -min, -max)
opisne_statistik_pet = cbind(selected_stats_pet, selected_stats_org) 
kable(opisne_statistik_pet,
      align = "c", digits = 2,
      caption = "Opisne statistike podatkov pri petih iteracijah.") %>%
kable_styling(full_width = F, 
                position = "center", latex_options = "H") %>%
  add_header_above(c(" " = 1, "odločitvena drevesa" = 4, "izvirni podatki" = 4))

# deset iteracij
selected_stats_deset = describe(dataRF_deset) %>% 
  dplyr::select(-vars, -kurtosis, -skew, -trimmed, -mad, -range, -median, -min, -max)
opisne_statistik_deset = cbind(selected_stats_deset, selected_stats_org) 
kable(opisne_statistik_deset,
      align = "c", digits = 2,
      caption = "Opisne statistike podatkov pri desetih iteracijah.") %>%
kable_styling( full_width = F, 
                position = "center", latex_options = "H") %>%
  add_header_above(c(" " = 1, "odločitvena drevesa" = 4, "izvirni podatki" = 4))
```

Tokrat lahko vidimo, da smo z izračunom nadomestili manjkajoče vrednosti (število vrednosti v vsakem stolpcu (spremenljivki) je enako 768, tako kot na izvirnih podatkih) pri vseh iteracijah seveda. Pričakovano so se spremenile vrednosti opisnih spremenljivk, predvsem pa opazimo razliko oz. zmanjšanje standardnega odklona (`sd`) pri vseh spremenljivkah, opaziva tudi, da so zmanjšanja/večanja opisnih statistik bolj izrazita pri spremenljivkah, ki so imele v izvirnih podatkih več mankajočih vrednosti(npr. `Insulin`), kar je seveda logično, saj moramo vstaviti več mankajočih vrednosti. Večjih razlik med številom iteracij pa ni, kar lahko vidimo tudi na spodnjih dveh grafih, zato je morda privzeta vrednost(deset iteracij) najboljša izbira.

```{r "primerjava graficno iteracije", fig.cap="Prikaz ocen regresijskih koeficientov in intervalov zaupanja za metodo odločitvenih dreves imputacij mankajočih vrednosti za različne iteracije(brez spremenljivke DiabetesPedigree levo in z desno).", fig.width=14, fig.height=8}
df_errorbar = data.frame(koef = rep(colnames(data)[1:(ncol(data)-1)], 3),
                     metoda = rep(c("Dve iteraiciji", "Pet iteracij", "Deset iteracij"), each=8),
                     vred = c(model_RF_dve$coefficients[2:9],
                              model_RF_pet$coefficients[2:9],
                              model_RF_deset$coefficients[2:9]),
                     lower = c(confint(model_RF_dve)[2:9,1],
                              confint(model_RF_pet)[2:9,1],
                              confint(model_RF_deset)[2:9,1]),
                     upper = c(confint(model_RF_dve)[2:9,2],
                              confint(model_RF_pet)[2:9,2],
                              confint(model_RF_deset)[2:9,2]))

vrstni_red = c("Dve iteraiciji", "Pet iteracij", "Deset iteracij")

df_errorbar$koef = factor(df_errorbar$koef)
df_errorbar$metoda = factor(df_errorbar$metoda, levels=vrstni_red)
indeks = which(df_errorbar$koef=="DiabetesPedigree")
df_errorbar_brez = df_errorbar[-indeks,]

g1 = ggplot(df_errorbar_brez, aes(x=vred, y=koef,colour = metoda)) +
  geom_point(position = position_dodge2(reverse = TRUE, 0.9), size=0.8) +
  geom_errorbarh(aes(xmin=lower, xmax=upper),
                 position = position_dodge2(reverse = TRUE, 0.8),
                 height=0.9, size=0.5) +
  theme_minimal() + theme(legend.position = "none")

g2 = ggplot(df_errorbar, aes(x=vred, y=koef, colour = metoda)) +
  geom_point(position = position_dodge2(reverse = TRUE, 0.9), size=0.8) +
  geom_errorbarh(aes(xmin=lower, xmax=upper),
                 position = position_dodge2(reverse = TRUE, 0.8),
                 height=0.9, size=0.5) +
  theme_minimal() + theme(legend.position = "right") +
  labs(y = " ")

library(patchwork)
combined_plot = g1 + g2 + plot_layout(guides = "collect")
combined_plot
```

## Multiple(stohastične) imputacije preko verižnih enačb

Najprej si oglejmo tabelo manjkajočih vrednosti. Desna stran predstavlja število spremenljivk z manjkajočimi vrednostmi, leva stran pomeni število enot, ter spodaj imamo število enot z manjkajočimi vrednostmi.

```{r "priprava podatkov MICE", fig.height=5, fig.width=7, fig.cap="Tabela mankajočih vrednosti."}
md.pattern(data, rotate.names=TRUE)

if(file.exists("data_mice.RDS")){
  data_mice <- readRDS("data_mice.RDS")
  } else {
    data_mice <- mice(data, m=50, maxit=55)
    saveRDS(data_mice, "data_mice.RDS")
  }
```

Enotam z manjkajočimi vrednostmi najpogosteje manjkajo vrednosti spremenljivk `Insulin`(1), `SkinThickness`(2) ali `BloodPressure`(3), kar smo ugotovili že pri mehanizmu mankajočih vrednosti in analizi podatkov. Prav tako skoraj v vseh primerih je vrednost spremenljivke `Insulin` manjkajoča vrednost (le dve enoti v podatkih imata manjkajoče vrednosti in ta ni pri spremenljivki `Insulin`, ampak pri sprem. `BMI` in `Glucose`).

```{r}
odstotek = nrow(na.omit(data))/nrow(data) * 100
```


Za izračun manjkajočih vrednosti sva uporabila funkcijo `mice()`, kjer sva za vrednosti prametrov izbrala `m` = 50 (pravilo palca pravi da izberemo `m` glede na % manjkajočih vrednosti - imamo `r round(odstotek,2)`\% mankajočih enot) in `maxit` = 55 (nekoliko višja vrednost, da vrednosti zagotovo skonvergirajo).
<!--Neza02: ma kaj se ti ne bi zdel bols mogoce m = 45 in maxit=55? glede na to, da je nekih 50% mankajocih?-->

Poglejmo si grafe povprečja in standarednega odklona za spremenljivke z manjkajočimi vrednostmi, da se prepričamo ali vrednosti res skonvergirajo.

```{r "konvergenca MICE", fig.height=6, fig.width=6, fig.cap="Grafi povprečja in standardnega odklona spremenljivk z mankajočimi vrednostmi."}
plot(data_mice, layout=c(2, 5))
```

Glede na zgornje grafe, bi lahko rekli, da smo izbrali prave vrednosti parametrov (vrednosti pri vseh spremenljivkah z iteracijami ustalijo - gledamo grafe od leve proti desni).

```{r "logisticna regresija MICE"}
# izracun vrednosti za vse izračunane podatkovne okvirje
model_mice = with(data=data_mice, expr=glm(Class ~ Pregnant + Glucose + BloodPressure + SkinThickness +
                                              Insulin + BMI + DiabetesPedigree + Age,
                                            family = binomial(link="logit")))
mice_zdruzeno = pool(model_mice)
mice_summary = summary(mice_zdruzeno)
```

# Primerjava regresijskih koeficientov in intervalov zaupanja

Poglejmo si sedaj katera metoda imputacije mankajočih vrednosti se je odrezala najbolje glede na ocene regresijskih koeficientov in njihovih intervalov zaupanja. Na enem grafu bomo prikazali spremenljivko `DiabetesPedigree`, na drugem pa ostale spremenljivke zaradi boljšega pregleda.

Takoj opazimo, da sta original in listwise metodi enaki, kar se tiče intervalov zaupanja in ocen koeficientov, kar je logično, saj funkcija linearne regresije deluje po principu listwise metode. Opazno je tudi, da je širina intervalov pri vseh spremenljivkah ožja pri metodi imputacije z odločitvenimi drevesi in MICE. Vse tri metode so si sicer dokaj podobne, še posebaj pri spremenljivki Insulin, kjer smo imeli največ mankajočih vrednosti, pri spremenljivki SkinThickness je vseeno razlika med metodo listwise in odločitvenimi drevesi ali metodo MICE.\
Pri spremenljivkah, ki so imele največ mankajočih vrednosti, npr `Insulin` ali `SkinThickness` torej ne vidimo večjih razlik v ocenah regresijskih koeficientov, tudi intervali zaupanja so dokaj ozki glede na metode imputacije mankajočih vrednosti. S tem ko pri spremenljivkah, ki pa niso imele mankajoče vrednosti, pa dobimo ožje intervale zaupanja če v linearni regresiji uporabimo podatke, kjer smo imputirali mankajoče vrednosti pri drugih spremenljivkah s pomočjo metode odločitvenih dreves in MICE. Torej metodi pozitivno prispevata k ocenjevanju koeficientov pri linearni regresiji in njihovim intervalom zaupanja.

```{r "primerjava graficno brez CV", fig.cap="Prikaz ocen regresijskih koeficientov in intervalov zaupanja za vse metode imputacij mankajočih vrednosti(brez spremenljivke DiabetesPedigree levo in z desno).", fig.width=14, fig.height=8}
df_errorbar = data.frame(koef = rep(colnames(data)[1:(ncol(data)-1)], 4),
                     metoda = rep(c("Originalni", "Listwise", "Odlocitvena drevesa","MICE"), each=8),
                     vred = c(model_org$coefficients[2:9],
                              model_brez_na$coefficients[2:9],
                              model_RF_deset$coefficients[2:9],
                              #model_CVI$coefficients[2:9],
                              mice_summary[-1, "estimate"]),
                     lower = c(confint(model_org)[2:9,1],
                              confint(model_brez_na)[2:9,1],
                              confint(model_RF_deset)[2:9,1],
                              #confint(model_CVI)[2:9,1],
                              mice_summary[-1,"estimate"]-1.96*mice_summary[-1, "std.error"]),
                     upper = c(confint(model_org)[2:9,2],
                              confint(model_brez_na)[2:9,2],
                              confint(model_RF_deset)[2:9,2],
                              #confint(model_CVI)[2:9,2],
                              mice_summary[-1,"estimate"]+1.96*mice_summary[-1, "std.error"])
                     )

vrstni_red = c("Originalni", "Listwise", "Odlocitvena drevesa","MICE")

df_errorbar$koef = factor(df_errorbar$koef)
df_errorbar$metoda = factor(df_errorbar$metoda, levels=vrstni_red)
indeks = which(df_errorbar$koef=="DiabetesPedigree")
df_errorbar_brez = df_errorbar[-indeks,]

g1 = ggplot(df_errorbar_brez, aes(x=vred, y=koef,colour = metoda)) +
  geom_point(position = position_dodge2(reverse = TRUE, 0.9), size=0.8) +
  geom_errorbarh(aes(xmin=lower, xmax=upper),
                 position = position_dodge2(reverse = TRUE, 0.8),
                 height=0.9, size=0.5) +
  theme_minimal() + theme(legend.position = "none")

g2 = ggplot(df_errorbar, aes(x=vred, y=koef, colour = metoda)) +
  geom_point(position = position_dodge2(reverse = TRUE, 0.9), size=0.8) +
  geom_errorbarh(aes(xmin=lower, xmax=upper),
                 position = position_dodge2(reverse = TRUE, 0.8),
                 height=0.9, size=0.5) +
  theme_minimal() + theme(legend.position = "right") +
  labs(y = " ")

library(patchwork)
combined_plot = g1 + g2 + plot_layout(guides = "collect")
combined_plot
```

# Vstavljanje srednje vrednosti

Med tem, da odstranimo vse enote z mankajočimi vrednostmi v katerem koli stolpcu in tem, da jih imputiramo s pomočjo dveh ustreznih metod sicer obstaja razlika. Ampak zgolj iz radovednosti pa naju zanima ali sta metodi odločitvenih dreves in MICE res dobri oziroma boljši od npr. vstavljanja srednje vrednosti(povprečja), ki sicer ni primerna metoda praktično nikoli, saj podcenjuje variabilnost in korelacijo med podatki. Je pa sicer metoda, ki je dokaj preprosta, ni računsko zahtevna in manjkajoče vrednosti nadomestimo na dokaj lahek način. 

Pri tej metodi na mesto manjkajočih vrednosti (`NA`) vstavimo srednjo vrednost spremenljivke (povprečje) izračunano na podatkih, ki jih imamo na voljo. Za metodo *vstavljanje srednje vrednosti* sva se odločila, saj zaradi vstavitve le ene vrednosti na vsa manjkajoča mesta v spremneljivki, pričakujeva da bo delovala najslabše, vendar naju vseeno zanima koliko se bo zares razlikovala od preostalih metod. 

```{r "Central value imputation"}
dataCVI = data
for (i in colnames(data)) {
  dataCVI[is.na(data[, i]), i] <- mean(data[, i], na.rm=TRUE)
}

model_CVI = glm(f, data=dataCVI, family = binomial(link="logit"))
```

```{r "tabela Central value imputation", results="hold"}
selected_stats = describe(dataCVI) %>% 
  dplyr::select(-vars, -kurtosis, -skew, -trimmed, -mad, -range, -median, -min, -max)
selected_stats = rbind(selected_stats[nrow(selected_stats),],
                       selected_stats[-nrow(selected_stats),])
opisne_statistik = cbind(selected_stats, selected_stats_org) 
kable(opisne_statistik,
      align = "c", digits = 2,
      caption = "Opisne statistike podatkov.") %>%
kable_styling( full_width = F, 
                position = "center", latex_options = "H") %>%
  add_header_above(c(" " = 1, "vstavljanje srednje vrednosti" = 4, "izvirni podatki" = 4))
```

Iz tabela lahko razberemo, da smo res nadomestili vse manjkajoče vrednosti (število vrednosti v vsaki spremenljivki je enako 768). Prav tako se povprečja na novih in originalnih podatkih ujemata, kar je pričakovano, saj smo ravno povprečje vrednosti spremenljivke uporabili za nadomestitev manjkajočih vrednosti. Poleg spremembe števila vrednosti v spremenljivki, opazimo tudi veliko spremembo standardnega odklona pri spremenljivkah z veliko manjkajočimi vrednostmi kot sta `SkinThickness`, `Insulin`, pri ostalih pa sprememba ni tako zelo velika. 

Na spodnjem grafu(ponovno je prikaz ločen najprej za izbrane spremenljivke in potem še za vse, da je bolj pregledno) pa se na prvi pogled zdi, da metoda ni tako zelo slaba, ker ima dokaj ozke intervale zaupanja(tudi ožje kot ostale metode), ampak to pričakujemo, predvsem pri spremenljivkah z veliko mankajočimi vrednostmi, ker bo potem veliko enot imelo enako vrednost in s tem odstranimo variabilnost; enako sicer lahko opazimo tudi pri spremenljivkah z malo mankajočimi vrednostmi. Torej to, kljub ozkim intervalom zaupanja, ni najboljša metoda imputacije mankajočih vrednosti.

```{r "primerjava graficno se CVI", fig.cap="Prikaz ocen regresijskih koeficientov in intervalov zaupanja za vse metode imputacij mankajočih vrednosti(brez spremenljivke DiabetesPedigree levo in z desno).", fig.width=14, fig.height=8}
df_errorbar = data.frame(koef = rep(colnames(data)[1:(ncol(data)-1)], 5),
                     metoda = rep(c("Originalni", "Listwise", "Odlocitvena drevesa",
                                    "Vstavljanje srednje vrednosti","MICE"), each=8),
                     vred = c(model_org$coefficients[2:9],
                              model_brez_na$coefficients[2:9],
                              model_RF_deset$coefficients[2:9],
                              model_CVI$coefficients[2:9],
                              mice_summary[-1, "estimate"]),
                     lower = c(confint(model_org)[2:9,1],
                              confint(model_brez_na)[2:9,1],
                              confint(model_RF_deset)[2:9,1],
                              confint(model_CVI)[2:9,1],
                              mice_summary[-1,"estimate"]-1.96*mice_summary[-1, "std.error"]),
                     upper = c(confint(model_org)[2:9,2],
                              confint(model_brez_na)[2:9,2],
                              confint(model_RF_deset)[2:9,2],
                              confint(model_CVI)[2:9,2],
                              mice_summary[-1,"estimate"]+1.96*mice_summary[-1, "std.error"])
                     )

vrstni_red = c("Originalni", "Listwise", "Odlocitvena drevesa", "Vstavljanje srednje vrednosti","MICE")

df_errorbar$koef = factor(df_errorbar$koef)
df_errorbar$metoda = factor(df_errorbar$metoda, levels=vrstni_red)
indeks = which(df_errorbar$koef=="DiabetesPedigree")
df_errorbar_brez = df_errorbar[-indeks,]

g1 = ggplot(df_errorbar_brez, aes(x=vred, y=koef,colour = metoda)) +
  geom_point(position = position_dodge2(reverse = TRUE, 0.9), size=0.8) +
  geom_errorbarh(aes(xmin=lower, xmax=upper),
                 position = position_dodge2(reverse = TRUE, 0.8),
                 height=0.9, size=0.5) +
  theme_minimal() + theme(legend.position = "none")

g2 = ggplot(df_errorbar, aes(x=vred, y=koef, colour = metoda)) +
  geom_point(position = position_dodge2(reverse = TRUE, 0.9), size=0.8) +
  geom_errorbarh(aes(xmin=lower, xmax=upper),
                 position = position_dodge2(reverse = TRUE, 0.8),
                 height=0.9, size=0.5) +
  theme_minimal() + theme(legend.position = "right") +
  labs(y = " ")

library(patchwork)
combined_plot = g1 + g2 + plot_layout(guides = "collect")
combined_plot
```

# Zaključek

Glede na rezultate najne analize bi lahko metode razdelila v dve skupini. V prvi skupini je uporaba funckije `glm()` na originalnih podatkih in uporaba *listwise* oziroma *pairwise* metode. Za naštete primere sva pričakovala nekoliko slabše rezultate, saj pri oblikovanju logističnega modela uporabijo le podatke, ki so na voljo. S tem lahko pričakujemo drugačne vrednosti mer središčnosti in nekoliko višje mere razpršenosti, kar pa vpliva tudi na oceno koeficientov z logistično regresijo. To se je izkazalo res tudi v najnem primeru, saj so se ocene koeficientov in 95% intervalov zaupanja znotraj skupine popolnoma ujemali. To pa tudi posledica delovanja funkcije `glm()`, saj pred modeliranje odstrani vse vrstice z manjkajočimi vrednostmi, torej sta to torej enaki metodi. \
V drugo skupino pa bi lahko uvrstila vse preostale metode, ki sva jih še analizirala. To so *Odlocitvena drevesa*, *Vstavljanje srednje vrednosti* in *Multiple(stohastične) imputacije preko verižnih enačb*. Vse tri metode za obravnavo manjkajočih vrednosti so pri modeliranju dala podobne ocene koeficientov in njihovih 95% intervalov zaupanja(predvsem odločitvena drevesa in MICE). Res imamo ožje intervale zaupanji pri metodi vstavljanja srednje vrednosti, vendar se to ne izkaže za dobro, saj pri spremenljivkah z veliko mankajočimi vrednostmi vstavimo veliko enakih vrednosti, kar zmanjša variabilnost oz. jo s tem podcenimo.

Po zgornji analizi bi, na podlagi grafov in rezultatov, za nadomestitev manjkajočih vrednosti uporabila metodo *Odlocitvena drevesa* ali *Multiple(stohastične) imputacije preko verižnih enačb*. Obe metodi se nama zdita primerni za najine podatke. 









