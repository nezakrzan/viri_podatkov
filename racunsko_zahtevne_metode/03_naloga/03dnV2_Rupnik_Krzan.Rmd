---
title: "Domača naloga 3"
author: "Neža Kržan, Tom Rupnik Medjedovič"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
header-includes:
- \usepackage[slovene]{babel}
- \usepackage{float}
- \usepackage[T1]{fontenc}
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", fig.pos = "H", message = FALSE, warning = FALSE, results = F, fig.height =4, fig.width = 6.5)

# potrebne knjižnice
library(ggplot2)
library(car)
library(tidyr)
library(dplyr)
library(ADGofTest)
library(lmerTest)
library(knitr)
library(kableExtra)
library(glue)

# seme
set.seed(2024)
```

# Cilji naloge

<!-- Jst nevem če tole čist razumem... midva morva primerjat dve resampling methods? 
Delava linearno regresijo, kjer mava krseni dve predpostavki, torej iz tega dobiva original rezultate, pol bova pa delala bootstrap pa se eno?
Kaj pa potem spreminjava da vplivava na primernost in uspesnot metod? Mogoce velikost vzorca? Ce mas majhen vzorec pa velik bootrtrap vzorcev najbr ne bo ok al kaj?

Aa okej dojamem zdej, najina klasična metoda je linearna regresija, najina druga metoda je pa bootstrap?

In simulations, vary at least two factors that could influence the suitability or success of the methods. - 
Torej modva bova za to spreminjala linearnost pa heteroskedasticnost?
Sam, ne razumem cist dobr, al morva spreminjat tud neki kar bi vplival na bootstrap?

Tom16: ja jst sm tako razumel, da je najna osnovna metoda lin. reg. ampak ker zaradi krsenja predpostavk ni dobra metoda primerjava še z bootstrap metodo. 
Zdej se mi zdi da spreminjava dovolj faktorjev k imava še velikost vzorca...sicer pa ja heteroskedastičnost se lepo vidi, ta nelinernost je pa bolj boga haha-->

Želiva preučiti uporabo metode ponovnega vzorčenja _bootstrap_, v primeru ko klasičnimi testom ne moremo popolno zaupati zaradi kršenja predpostavk. Analizirati želiva primer, kjer klasična statistična metoda, v najinem primeru je to linearna regresija, ni popolnoma primerna za ocenjevanje koeficientov napovednih spremenljivk in njihovih intervalov zaupanja, zaradi kršitve predpostavk statističnega modela(tj. linearna regresija). 

Generirala bova podatke, na katerih bova izračunala intervale zaupanja koeficientov linearne regresije. 

Za uporabno linearne regresije je potrebno izpolniti določene predpostavke, da imamo veljaven model. Te so:

- linearna odvisnost: _obstoj linearne povezanosti med napovednimi (pojasnjevalnimi) spremenljivkami in odzivno (ciljno) spremenljivko_,
- normalna porazdeljenost napak in neodvisnost napak,
- homoskedastičnost: _varianca napak mora biti konstantna_,
- brez popolne multikolinearnosti: _neodvisne spremenljivke ne smejo biti preveč povezane med seboj_,
- zadostno število podatkov.

Podatke bova generirala tako, da bodo nekatere izmed teh predpostavk kršene(opisano v naslednjem poglavju) ter bova med seboj primerjala intervale zaupanja dobljene z linearno regresijo (`lm`) in metodo ponovnega vzorčenja(_bootstrap_).<!--Tom16: bova tudi permutacijski test baredila?--> 

# Generiranje podatkov

Podatke sva generirala tako, da je v linearnem regresiji kršena predpostavka homoskedastičnost (konstantna varianca napak). Enačba, ki sva jo uporabila za generiranje odzivne spremenljivke je enaka:

$$y_i = \beta_0 + \beta_1 \cdot x_{1i} + \beta_2 \cdot x_{2i} + \epsilon_i$$
pri čemer:

* $\beta_0$-konstanta enaka $100$,
* $\beta_1$-koeficient spremenljivke $x_1$ enak $3$,
* $\beta_2$-koeficient spremenljivke $x_2$ enak $2$,
* $\epsilon$-napaka, ki generirana iz porazdelitve $N(0,x_1\cdot\alpha)$ ($\alpha$ določa povezanost s spremenljivko $x_1$),

torej

$$
y_i = 100 + 3 \cdot x_{1i} + 2 \cdot x_{2i} + \epsilon_i.
$$

Kot sva že omenila bova spreminjala faktor $\alpha$ in s tem kršila predpostavko konstantne variance napak, saj se ta z večanjem vrednosti $x_1$ povečuje ali pa je konstantna. Ta zavzame vrednosti $\alpha\in\{0.6, 1, 1.2\}$. 

Velikost vzorca pa enak  $n = (20, 200, 500)$, ker naju zanima kako se bo bootstrap metoda obnesla tudi na zelo majhnem vzorcu - s tem je tudi kršena predpostavka o dovolj velikem vzorcu pri linearni regresiji.

Pri generiranju posameznih vrednosti v enačbi linearne regresije($x_{1i}, x_{2i}$) sva se odločila za generiranje iz enakomerne porazdelitve, in sicer $x_{1i} \sim Unif(20, 60)$ ter $x_{2i} \sim Unif(2, 10)$, torej, da imamo v podatkih majhne vrednosti in nekoliko večje.

```{r generiranje podatkov}
set.seed(2024)
n = 500 # velikost vzorca

generiranje_podatkov <- function(beta0, beta1, beta2, alpha, n) {
  # generiranje vrednosti za x1 in x2
  x1 <- runif(n, 20, 60)
  x2 <- runif(n, 2, 10)
  
  # generiranje napake
  epsilon <- rnorm(n, 0,x1^alpha) # dodava heteroskedasticnost
  
  # izračun napovedne spremenljivke za model (parametri = vhodni argumenti) 
  y <- beta0 + beta1 * x1 + beta2 * x2 + epsilon # z ^gamma dodava nelinearni del
  
  # podatke spravimo v podatkovni okvir in vrnemo kot rezultat funkcije
  data.frame(x1 = x1, x2 = x2, y = y) 
}

# izracun vrednosti vzorca
vzorec06 = generiranje_podatkov(100, 3, 2, 0.6, n)
vzorec1 = generiranje_podatkov(100, 3, 2, 1,  n)
vzorec12 = generiranje_podatkov(100, 3, 2, 1.2, n)

# modeli (brez transformacije)
model06 = lm(y ~ x1 + x2, vzorec06)
model1 = lm(y ~ x1 + x2, vzorec1)
model12 = lm(y ~ x1 + x2, vzorec12)

```

Narišimo grafe ostankov za nekaj kombinacij faktorjev, da se prepričamo o kršenju predpostavk, velikost vzorca je v *vseh* primerih nastavljena na $500$.

```{r "graf ostankov 0.6 in 0.8", fig.dim=c(5,3), fig.cap="Grafi ostankov pri paramatrih alpha=0,6."}
par(mfrow=c(1,2))
plot(model06, which = c(1,3))
```

```{r "graf ostankov 1.2 in 1.4", fig.dim=c(5,3), fig.cap="Grafi ostankov pri paramatrih alpha=1,2."}
par(mfrow=c(1,2))
plot(model12, which = c(1,3))
```

V obeh primerih lahko na desnem grafu opazimo, da se z večanjem vrednosti povečuje tudi variabilnost napak (naraščajoč trend). To lahko opazimo, tudi iz levega grafa, saj se od leve proti desni s povečevanjem vrednosti, povečuje tudi variabilnost ostankov. Prav tako je vidna razlika, ko povečamo vrednost parametra $\alpha$, saj se vrednosti ostankov povečajo (variabilnost se poveča).  

# Klasični test in metoda ponovnega vzorčenja

Pri ponovnem vzorčenju bova uporabila metodo bootstrap, pri kateri bo število bootstrap vzorcev enako $m=1000$. 

Za vsako kombinacijo faktorjev( _alpha_ in _velikost vzorca_) sva generirala podatke, na katerih sva za vsako kombinacijo faktorjev izvedla linearno regresijo in poračunala intervale zaupanja za vse tri koeficiente(`Intercept`, `x1`, `x2`). \
Enak postopek sva ponovila z metodo ponovnega vzorčenja bootstrap - naključno sva iz generiranih podatkov za vse kombinacije faktorjev izbrala podatke, na katerih sva potem izvedla linearno regresijo in izračunala intervale zaupanja za vse tri koeficiente (`Intercept`, `x1`, `x2`). Tak postopek ponovnega vzorčenja sva ponovila $m = 1000$, zato smo torej imeli $1000$ bootstrap vzorcev. \
Ves ta postopek sva ponovila $10000$-krat in zaradi (predvsem) počasnosti _bootstrap_ metode uporabila in uporabila t.i. paralelno računanje(angl. *parallel computing*).

## Analiza rezultatov podatkov

Jasno nam torej je, da se na rezultate, pridobljene s klasično metodo ne moremo ravno zanesti, saj kršenje predpostavk pri linearni regresiji močno vpliva na intervale zaupanja(tudi na ocene koeficientov). Pri obeh metodah pa seveda pri majhnem vzorcu($n = 20$) pričakujemo najširše intervale zaupanja, ki pa se potem z večanjem vzorca ožajo. Verjetno pa bodo intervali zaupanja pri obeh metodah(klasični test in bootstrap) približno enako široki.

Na spodnjih grafih vidimo, da se intervali z večanjem vzorca res manjšajo, razlike med intervali s klasično analizo in bootstrapom pa so minimalne, največja razlika v širini intervala se opazi pri majhnem vzorcu($n=20$). Težko pa rečemo, da faktor heteroskedastičnost($\alpha$) glede na metodo kako značilno vpliva na širino intervala.

```{r "zdruzeni rezultati"}
source("03dnV2_Rupnik_Krzan.R")

# zdruziva rezultate
podatki_skupaj = rbind(rezultati_klasicna, rezultati_bootstrap)
# dodava metodo
podatki_skupaj = cbind(podatki_skupaj, rep(c("klasična analiza(LR)", "bootstrap"), each=nrow(rezultati_klasicna)))
colnames(podatki_skupaj)[ncol(podatki_skupaj)] = "metoda"

IZ_skupaj = podatki_skupaj %>% group_by(alpha, velikost.vzorca, metoda) %>%
  summarise(int.coef = mean(int.coef), x1.coef = mean(x1.coef), x2.coef = mean(x2.coef),
            int.lower = mean(int.lower), int.upper = mean(int.upper),
            x1.lower = mean(x1.lower), x1.upper = mean(x1.upper),
            x2.lower = mean(x2.lower), x2.upper = mean(x2.upper))

IZ_skupaj$alpha = factor(IZ_skupaj$alpha)
IZ_skupaj$velikost.vzorca = factor(IZ_skupaj$velikost.vzorca)

# sirine intervalov
sirine_intervalov = IZ_skupaj %>%
  mutate(SI_int = abs(int.upper) - abs(int.lower), SI_x1 = abs(x1.upper) - abs(x1.lower), SI_x2 = abs(x2.upper) - x2.lower) %>%
  select(alpha, velikost.vzorca, SI_int, SI_x1, SI_x2, metoda)
sirine_intervalov = cbind(sirine_intervalov, podatki = rep(c("klasična analiza(LR)", "bootstrap"), each=9))
sirine_intervalov$velikost.vzorca = factor(sirine_intervalov$velikost.vzorca)

```

<!--Prikaz presecisce-->

```{r "graf int", fig.cap="Grafi intervalov zaupanja(levo) in širine intervalov zaupanja(desno) za prosti koeficient(Intercept).", fig.width = 8}
custom_labeller <- labeller(
  alpha = function(x) paste("\u03b1 =", x)
)

tabela_risanje = IZ_skupaj %>%
  inner_join(sirine_intervalov, by = c("alpha", "velikost.vzorca", "metoda"))
tabela_risanje$metoda <- factor(tabela_risanje$metoda)

g1 = ggplot(tabela_risanje, aes(x=velikost.vzorca, col=metoda, group=metoda)) +
  geom_errorbar(aes(ymin = int.lower, ymax = int.upper), width=0.5, position = position_dodge2(reverse = TRUE, 0.3)) + 
  geom_point(aes(y = int.coef), position = position_dodge2(reverse = TRUE, 0.5), shape = 16, size = 1) +
  facet_grid(glue('alpha*" = {alpha}"') ~., labeller = label_parsed, scales="free") +
  labs(x = "velikost vzorca (n)", y = " ") +
  theme_minimal() + theme(legend.position = "none") +
  labs(color = "metoda")

g2 = ggplot(tabela_risanje, aes(x=velikost.vzorca, col=metoda, group=metoda)) +
  geom_point(aes(y = SI_int), shape = 16, size = 1.2) +
  geom_line(aes(y = SI_int)) +
  facet_grid(glue('alpha*" = {alpha}"') ~., labeller = label_parsed, scales="free") +
  labs(x = "velikost vzorca (n)", y = " ") +
  theme_minimal() + theme(legend.position = "right") +
  labs(color = "metoda")
library(patchwork)
combined_plot = g1 + g2 + plot_layout(guides = "collect")
combined_plot
```

<!--Prikaz x1-->

```{r "graf x1", fig.cap="Grafi intervalov zaupanja(levo) in širine intervalov zaupanja(desno) za koeficient pri x1(beta1).", fig.width = 8}
g1 = ggplot(tabela_risanje, aes(x=velikost.vzorca, col=metoda, group=metoda)) +
  geom_errorbar(aes(ymin = x1.lower, ymax = x1.upper), width=0.5, position = position_dodge2(reverse = TRUE, 0.3)) + 
  geom_point(aes(y = x1.coef), position = position_dodge2(reverse = TRUE, 0.5), shape = 16, size = 1) +
  facet_grid(glue('alpha*" = {alpha}"') ~., labeller = label_parsed, scales="free") +
  labs(x = "velikost vzorca (n)", y = " ") +
  theme_minimal() + theme(legend.position = "none") +
  labs(color = "metoda")

g2 = ggplot(tabela_risanje, aes(x=velikost.vzorca, col=metoda, group=metoda)) +
  geom_point(aes(y = SI_x1), shape = 16, size = 1.2) +
  geom_line(aes(y = SI_x1)) +
  facet_grid(glue('alpha*" = {alpha}"') ~., labeller = label_parsed, scales="free") +
  labs(x = "velikost vzorca (n)", y = " ") +
  theme_minimal() + theme(legend.position = "right") +
  labs(color = "metoda")
library(patchwork)
combined_plot = g1 + g2 + plot_layout(guides = "collect")
combined_plot
```

<!--Prikaz x2-->

```{r "graf x2", fig.cap="Grafi intervalov zaupanja(levo) in širine intervalov zaupanja(desno) za koeficient pri x2(beta2).", fig.width = 8}
g1 = ggplot(tabela_risanje, aes(x=velikost.vzorca, col=metoda, group=metoda)) +
  geom_errorbar(aes(ymin = x2.lower, ymax = x2.upper), width=0.5, position = position_dodge2(reverse = TRUE, 0.3)) + 
  geom_point(aes(y = x2.coef), position = position_dodge2(reverse = TRUE, 0.5), shape = 16, size = 1) +
  facet_grid(glue('alpha*" = {alpha}"') ~., labeller = label_parsed, scales="free") +
  labs(x = "velikost vzorca (n)", y = " ") +
  theme_minimal() + theme(legend.position = "none") +
  labs(color = "metoda")

g2 = ggplot(tabela_risanje, aes(x=velikost.vzorca, col=metoda, group=metoda)) +
  geom_point(aes(y = SI_x2), shape = 16, size = 1.2) +
  geom_line(aes(y = SI_x2)) +
  facet_grid(glue('alpha*" = {alpha}"') ~., labeller = label_parsed, scales="free") +
  labs(x = "velikost vzorca (n)", y = " ") +
  theme_minimal() + theme(legend.position = "right") +
  labs(color = "metoda")
library(patchwork)
combined_plot = g1 + g2 + plot_layout(guides = "collect")
combined_plot
```

### Pokritost

Pokritost se nanaša na odstotek primerov, ko interval zaupanja dejansko zajame resnično vrednost parametra. Mi imamo 95\% interval zaupanja, torej pričakujemo, da interval zajame resnično vrednost v 95\% ponovljenih vzorčenj. Rezultate si lahko ogledamo v spodni tabeli in grafu.

```{r "pokritost izracun"}
pokritost = podatki_skupaj %>% group_by(alpha, velikost.vzorca, metoda) %>%
  summarise(pokritost_int = mean(int.lower <= 100 & 100 <= int.upper),
            pokritost_x1 = mean(x1.lower <= 3 & 3 <= x1.upper),
            pokritost_x2 = mean(x2.lower <= 2 & 2 <= x2.upper))

pokritost_bootstrap = pokritost %>% filter(metoda == "bootstrap")
pokritost_klasicna = pokritost %>% filter(metoda == "klasična analiza(LR)")
```


```{r "prikaz pokritost", results=T}
df_pokritost = data.frame("alpha" = pokritost_bootstrap$alpha, 
                          "n" = pokritost_bootstrap$velikost.vzorca,
                          "int_klasicna" = pokritost_klasicna$pokritost_int,
                          "int_bootstrap" = pokritost_bootstrap$pokritost_int,
                          "x1_klasicna" = pokritost_klasicna$pokritost_x1,
                          "x1_bootstrap" = pokritost_bootstrap$pokritost_x1,
                          "x2_klasicna" = pokritost_klasicna$pokritost_x2,
                          "x2_bootstrap" = pokritost_bootstrap$pokritost_x2)

kable(df_pokritost, 
      col.names = c("alpha", "velikost vzorca", rep(c("klasicna", "bootstrap"),3)),
      align = "c", digits = 4, caption = "Pokritos pri posameznih koeficientih in kombinacijah alphe in velikosti vzorca(n).") %>%
  add_header_above(c(" " = 2, "intercept" = 2, "beta1" = 2, "beta2" = 2))
```

Vidimo, da se pokritost razlikuje glede na metodo, velikost vzorca in faktor $\alpha$. Vidimo, da je v večini primerov pokritost pri klasičnem testu(linearna regresija) boljše, ampak težko ocenimo, če je to res bolje, sam so kršene predpostavke in ocene koeficientov in intervali zaupanja takrat niso zanesljivi. Največje razlike v pokritosti so pri prosterm členu(Intercept) in pri majhnem vzorcu $n = 20$. 

```{r, fig.cap="Graf pokritosti za vse tri koeficiente."}
pokritostLong = pivot_longer(pokritost, cols =matches("^(pokritost)."),
                       values_to = "value",
                       names_to = c("metric"),
                       names_pattern = ".(int|x1|x2)") 

pokritostLong$metric = factor(pokritostLong$metric, levels = c("int", "x1", "x2"),
                              labels = c("Int", "beta1", "beta2"))

ggplot(pokritostLong, aes(x = factor(velikost.vzorca), y = value, col=metoda, group=metoda)) +
  geom_line() + geom_hline(yintercept = 0.95, size = 0.15) +
  geom_point() +
  facet_grid(alpha~metric, scales="free", labeller = custom_labeller) +
  labs(x = "velikost vzorca (n)", y = " ") +
  theme(legend.position = "bottom") +
  theme_minimal()
```

# Zaključek

Pri primerjavi intervalov zaupanja "klasične" metode (*linearne regresije*), ko so predpostavke te kršene, in metode ponovnega vzorčenja (*bootstrap*), nisva opazila drastičnih razlik. Intervali zaupanja so bili pri metodi ponovnega vzorčenja nekoliko ožji, največja razlika v širini intervala pa se opazi pri majhnem vzorcu ($n=20$). Pri pokritosti se iskaže, da ima klasična nalaiza boljšo pokritost že pri majhnem vzorcu, _bootstrap_ metoda pa se približa 95\% pokritosti šele pri zelo velikem vzorcu $n=500$. 

Glede na analizo bi težko rekla, da je ena metoda veliko boljša od druge. Vendar pa bi vseeno ob kršenju predpostavk uporabila metodo ponovnega vzorčenja, saj se je ta izkazala za malenkost boljšo in z velikim številom vzorev (vzorečenja) odstranimo ekstremne robne vrednosti. 






