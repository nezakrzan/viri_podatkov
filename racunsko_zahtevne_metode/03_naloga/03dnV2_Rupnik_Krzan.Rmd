---
title: "Domača naloga 3"
author: "Neža Kržan, Tom Rupnik Medjedovič"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
header-includes:
- \usepackage[slovene]{babel}
- \usepackage{float}
- \usepackage[T1]{fontenc}
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", fig.pos = "H", message = FALSE, warning = FALSE, results = F, fig.height =4, fig.width = 6.5)

# potrebne knjižnice
library(ggplot2)
library(car)
library(tidyr)
library(dplyr)
library(ADGofTest)
library(lmerTest)
library(knitr)
library(kableExtra)
library(glue)

# seme
set.seed(2024)
```

# Cilji naloge

<!-- Jst nevem če tole čist razumem... midva morva primerjat dve resampling methods? 
Delava linearno regresijo, kjer mava krseni dve predpostavki, torej iz tega dobiva original rezultate, pol bova pa delala bootstrap pa se eno?
Kaj pa potem spreminjava da vplivava na primernost in uspesnot metod? Mogoce velikost vzorca? Ce mas majhen vzorec pa velik bootrtrap vzorcev najbr ne bo ok al kaj?

Aa okej dojamem zdej, najina klasična metoda je linearna regresija, najina druga metoda je pa bootstrap?

In simulations, vary at least two factors that could influence the suitability or success of the methods. - 
Torej modva bova za to spreminjala linearnost pa heteroskedasticnost?
Sam, ne razumem cist dobr, al morva spreminjat tud neki kar bi vplival na bootstrap?

Tom16: ja jst sm tako razumel, da je najna osnovna metoda lin. reg. ampak ker zaradi krsenja predpostavk ni dobra metoda primerjava še z bootstrap metodo. 
Zdej se mi zdi da spreminjava dovolj faktorjev k imava še velikost vzorca...sicer pa ja heteroskedastičnost se lepo vidi, ta nelinernost je pa bolj boga haha-->

Želiva preučiti uporabo metode ponovnega vzorčenja _bootstrap_, v primeru ko klasičnimi testom ne moremo popolno zaupati zaradi kršenja predpostavk. Analizirati želiva primer, kjer klasična statistična metoda, v najinem primeru je to linearna regresija, ni popolnoma primerna za ocenjevanje koeficientov napovednih spremenljivk in njihovih intervalov zaupanja, zaradi kršitve predpostavk statističnega modela(tj. linearna regresija). 

Generirala bova podatke, na katerih bova izračunala intervale zaupanja koeficientov linearne regresije. 

Za uporabno linearne regresije je potrebno izpolniti določene predpostavke, da imamo veljaven model. Te so:

- linearna odvisnost: _obstoj linearne povezanosti med napovednimi (pojasnjevalnimi) spremenljivkami in odzivno (ciljno) spremenljivko_,
- normalna porazdeljenost napak in neodvisnost napak,
- homoskedastičnost: _varianca napak mora biti konstantna_,
- brez popolne multikolinearnosti: _neodvisne spremenljivke ne smejo biti preveč povezane med seboj_,
- zadostno število podatkov.

Podatke bova generirala tako, da bodo nekatere izmed teh predpostavk kršene(opisano v naslednjem poglavju) ter bova med seboj primerjala intervale zaupanja dobljene z linearno regresijo (`lm`) in metodo ponovnega vzorčenja(_bootstrap_).<!--Tom16: bova tudi permutacijski test baredila?--> 

# Generiranje podatkov

Podatke sva generirala tako, da je v linearnem regresiji kršena predpostavka homoskedastičnost (konstantna varianca napak). Enačba, ki sva jo uporabila za generiranje odzivne spremenljivke je enaka:

$$y_i = \beta_0 + \beta_1 \cdot x_{1i} + \beta_2 \cdot x_{2i} + \epsilon_i$$
pri čemer:

* $\beta_0$-konstanta enaka $100$,
* $\beta_1$-koeficient spremenljivke $x_1$ enak $3$,
* $\beta_2$-koeficient spremenljivke $x_2$ enak $2$,
* $\epsilon$-napaka, ki generirana iz porazdelitve $N(0,x_1\cdot\alpha)$ ($\alpha$ določa povezanost s spremenljivko $x_1$),

torej

$$
y_i = 100 + 3 \cdot x_{1i} + 2 \cdot x_{2i} + \epsilon_i.
$$

Kot sva že omenila bova spreminjala faktor $\alpha$ in s tem kršila predpostavko konstantne variance napak, saj se ta z večanjem vrednosti $x_1$ povečuje ali pa je konstantna. Ta zavzame vrednosti $\alpha\in\{0.6, 1, 1.2\}$. 

Velikost vzorca pa enak  $n = (20, 200, 500)$, ker naju zanima kako se bo bootstrap metoda obnesla tudi na zelo majhnem vzorcu - s tem je tudi kršena predpostavka o dovolj velikem vzorcu pri linearni regresiji.

Pri generiranju posameznih vrednosti v enačbi linearne regresije($x_{1i}, x_{2i}$) sva se odločila za generiranje iz enakomerne porazdelitve, in sicer $x_{1i} \sim Unif(20, 60)$ ter $x_{2i} \sim Unif(2, 10)$, torej, da imamo v podatkih majhne vrednosti in nekoliko večje.

```{r generiranje podatkov}
set.seed(2024)
n = 500 # velikost vzorca

generiranje_podatkov <- function(beta0, beta1, beta2, alpha, n) {
  # generiranje vrednosti za x1 in x2
  x1 <- runif(n, 20, 60)
  x2 <- runif(n, 2, 10)
  
  # generiranje napake
  epsilon <- rnorm(n, 0,x1^alpha) # dodava heteroskedasticnost
  
  # izračun napovedne spremenljivke za model (parametri = vhodni argumenti) 
  y <- beta0 + beta1 * x1 + beta2 * x2 + epsilon # z ^gamma dodava nelinearni del
  
  # podatke spravimo v podatkovni okvir in vrnemo kot rezultat funkcije
  data.frame(x1 = x1, x2 = x2, y = y) 
}

# izracun vrednosti vzorca
vzorec06 = generiranje_podatkov(100, 3, 2, 0.6, n)
vzorec1 = generiranje_podatkov(100, 3, 2, 1,  n)
vzorec12 = generiranje_podatkov(100, 3, 2, 1.2, n)

# modeli (brez transformacije)
model06 = lm(y ~ x1 + x2, vzorec06)
model1 = lm(y ~ x1 + x2, vzorec1)
model12 = lm(y ~ x1 + x2, vzorec12)

```

Narišimo grafe ostankov za nekaj kombinacij faktorjev, da se prepričamo o kršenju predpostavk, velikost vzorca je v *vseh* primerih nastavljena na $500$.

```{r "graf ostankov 0.6 in 0.8", fig.dim=c(5,3), fig.cap="Grafi ostankov pri paramatrih alpha=0,6."}
par(mfrow=c(1,2))
plot(model06, which = c(1,3))
```

```{r "graf ostankov 1.2 in 1.4", fig.dim=c(5,3), fig.cap="Grafi ostankov pri paramatrih alpha=1,2."}
par(mfrow=c(1,2))
plot(model12, which = c(1,3))
```

V obeh primerih lahko na desnem grafu opazimo, da se z večanjem vrednosti povečuje tudi variabilnost napak (naraščajoč trend). To lahko opazimo, tudi iz levega grafa, saj se od leve proti desni s povečevanjem vrednosti, povečuje tudi variabilnost ostankov. Prav tako je vidna razlika, ko povečamo vrednost parametra $\alpha$, saj se vrednosti ostankov povečajo (variabilnost se poveča).  

# Klasični test in metoda ponovnega vzorčenja

Pri ponovnem vzorčenju bova uporabila metodo bootstrap, pri kateri bo število bootstrap vzorcev enako $m=1000$. 

Za vsako kombinacijo faktorjev( _alpha_ in _velikost vzorca_) sva generirala podatke, na katerih sva za vsako kombinacijo faktorjev izvedla linearno regresijo in poračunala intervale zaupanja za vse tri koeficiente(`Intercept`, `x1`, `x2`). \
Enak postopek sva ponovila z metodo ponovnega vzorčenja bootstrap - naključno sva iz generiranih podatkov za vse kombinacije faktorjev izbrala podatke, na katerih sva potem izvedla linearno regresijo in izračunala intervale zaupanja za vse tri koeficiente (`Intercept`, `x1`, `x2`). Tak postopek ponovnega vzorčenja sva ponovila $m = 1000$, zato smo torej imeli $1000$ bootstrap vzorcev. \
Ves ta postopek sva ponovila $1000$-krat in zaradi (predvsem) počasnosti _bootstrap_ metode uporabila in uporabila t.i. paralelno računanje(angl. *parallel computing*).

## Analiza rezultatov podatkov

Jasno nam torej je, da se na rezultate, pridobljene s podatki pred transformacijo ne moremo ravno zanesti, saj kršenje predpostavk pri linearni regresiji močno vpliva na intervale zaupanja(tudi na ocene koeficientov). Pri majhnem vzorcu($n = 20$) seveda pričakujemo najširše intervale zaupanja, ki pa se potem z večanjem vzorca ožajo. Verjetno bodo intervali zaupanja pri obeh metodah približno enako široki.

Na spodnjih grafih vidimo, da se intervazli z večanjem vzorca res manjšajo, razlike med intervali s klasično analizo in bootstrapom pa so minimalne, največja razlika v širini intervala se opazi pri majhnem vzorcu($n=20$).

```{r "zdruzeni rezultati"}
source("03dnV2_Rupnik_Krzan.R")

# zdruziva rezultate
podatki_skupaj = rbind(rezultati_klasicna, rezultati_bootstrap)
# dodava metodo
podatki_skupaj = cbind(podatki_skupaj, rep(c("klasicna", "bootstrap"), each=nrow(rezultati_klasicna)))
colnames(podatki_skupaj)[ncol(podatki_skupaj)] = "metoda"

podatki_skupaj$alpha = factor(podatki_skupaj$alpha)
podatki_skupaj$velikost.vzorca = factor(podatki_skupaj$velikost.vzorca)
```

<!--Prikaz presecisce-->

```{r "podatki za prikaz int"}
pod_int = podatki_skupaj %>% 
  select(c("alpha", "velikost.vzorca", "int.coef", "int.lower", "int.upper", "metoda"))

agr_int_coef = aggregate(int.coef ~ alpha + velikost.vzorca + metoda, 
                   data = pod_int, FUN = mean)
agr_int_lower = aggregate(int.lower ~ alpha + velikost.vzorca + metoda, 
                   data = pod_int, FUN = mean)
agr_int_upper = aggregate(int.upper ~ alpha + velikost.vzorca + metoda, 
                   data = pod_int, FUN = mean)

int_skupaj = full_join(agr_int_coef, agr_int_lower)
int_skupaj = full_join(int_skupaj, agr_int_upper)
```

```{r "graf int", fig.cap="Grafi intervalov zaupanja za prosti koeficient(Intercept)."}
ggplot(int_skupaj, aes(x=velikost.vzorca, col=metoda, group=metoda)) +
  geom_errorbar(aes(ymin = int.lower, ymax = int.upper), width=0.5, position = position_dodge2(reverse = TRUE, 0.3)) + 
  geom_point(aes(y = int.coef), position = position_dodge2(reverse = TRUE, 0.5), shape = 16, size = 1) +
  # facet_grid(alpha~gamma, scales="free", labeller = custom_labeller) +
  facet_grid(factor(alpha, c("1.2", "1", "0.6"))~., 
             labeller = label_parsed, scales = "free")  +
  labs(x = "velikost vzorca (n)", y = " ") +
  theme(legend.position = "bottom") +
  theme_minimal()
```

<!--Prikaz x1-->

```{r "podatki za prikaz x1"}
pod_x1 = podatki_skupaj %>% 
  select(c("alpha", "velikost.vzorca", "x1.coef", "x1.lower", "x1.upper", "metoda"))

agr_x1_coef = aggregate(x1.coef ~ alpha + velikost.vzorca + metoda, 
                   data = pod_x1, FUN = mean)
agr_x1_lower = aggregate(x1.lower ~ alpha + velikost.vzorca + metoda, 
                   data = pod_x1, FUN = mean)
agr_x1_upper = aggregate(x1.upper ~ alpha + velikost.vzorca + metoda, 
                   data = pod_x1, FUN = mean)

x1_skupaj = full_join(agr_x1_coef, agr_x1_lower)
x1_skupaj = full_join(x1_skupaj, agr_x1_upper)
```


```{r "graf x1", fig.cap="Grafi intervalov zaupanja za koeficient pri x1(beta1)."}
ggplot(x1_skupaj, aes(x=velikost.vzorca, col=metoda, group=metoda)) +
  geom_errorbar(aes(ymin = x1.lower, ymax = x1.upper), width=0.5, position = position_dodge2(reverse = TRUE, 0.3)) + 
  geom_point(aes(y = x1.coef), position = position_dodge2(reverse = TRUE, 0.5), shape = 16, size = 1) +
  # facet_grid(alpha~gamma, scales="free", labeller = custom_labeller) +
  facet_grid(factor(alpha, c("1.2", "1", "0.6"))~., 
             labeller = label_parsed, scales = "free")  +
  labs(x = "velikost vzorca (n)", y = " ") +
  theme(legend.position = "bottom") +
  theme_minimal()
```

<!--Prikaz x2-->

```{r "podatki za prikaz x2"}
pod_x2 = podatki_skupaj %>% 
  select(c("alpha", "velikost.vzorca", "x2.coef", "x2.lower", "x2.upper", "metoda"))

agr_x2_coef = aggregate(x2.coef ~ alpha + velikost.vzorca + metoda, 
                   data = pod_x2, FUN = mean)
agr_x2_lower = aggregate(x2.lower ~ alpha + velikost.vzorca + metoda, 
                   data = pod_x2, FUN = mean)
agr_x2_upper = aggregate(x2.upper ~ alpha + velikost.vzorca + metoda, 
                   data = pod_x2, FUN = mean)

x2_skupaj = full_join(agr_x2_coef, agr_x2_lower)
x2_skupaj = full_join(x2_skupaj, agr_x2_upper)
```


```{r "graf x2", fig.cap="Grafi intervalov zaupanja za koeficient pri x2(beta2)."}
ggplot(x2_skupaj, aes(x=velikost.vzorca, col=metoda, group=metoda)) +
  geom_errorbar(aes(ymin = x2.lower, ymax = x2.upper), width=0.5, position = position_dodge2(reverse = TRUE, 0.3)) + 
  geom_point(aes(y = x2.coef), position = position_dodge2(reverse = TRUE, 0.5), shape = 16, size = 1) +
  # facet_grid(alpha~gamma, scales="free", labeller = custom_labeller) +
  facet_grid(factor(alpha, c("1.2", "1", "0.6"))~., 
             labeller = label_parsed, scales = "free") +
  labs(x = "velikost vzorca (n)", y = " ") +
  theme(legend.position = "bottom") +
  theme_minimal()
```

<!-- Pokritost -->

```{r pokritost int}
# stolpci v matriki: alpha, n, klasicna, bootstrap
pokritost_int = matrix(NA, nrow = 9, ncol = 4)
ind = 1
for(alpha in c(0.6, 1, 1.2)){
  for(n in c(20, 200, 500)){
    pod_klasicna = podatki_skupaj %>%
      filter(alpha==alpha, velikost.vzorca == n, metoda == "klasicna") %>%
      select(c("int.lower", "int.upper"))
    
    pod_bootstrap = podatki_skupaj %>%
      filter(alpha==alpha, velikost.vzorca == n, metoda == "bootstrap") %>%
      select(c("int.lower", "int.upper"))
    
    pokritost_int[ind,] = c(alpha, n,
                          mean(pod_klasicna$int.lower <= 100 & 100 <= pod_klasicna$int.upper),
                          mean(pod_bootstrap$int.lower <= 100 & 100 <= pod_bootstrap$int.upper))
    ind = ind + 1
  }
}
```


```{r pokritost x1}
# stolpci v matriki: alpha, n, klasicna, bootstrap
pokritost_x1 = matrix(NA, nrow = 9, ncol = 4)
ind = 1
for(alpha in c(0.6, 1, 1.2)){
  for(n in c(20, 200, 500)){
    pod_klasicna = podatki_skupaj %>%
      filter(alpha==alpha, velikost.vzorca == n, metoda == "klasicna") %>%
      select(c("x1.lower", "x1.upper"))
    
    pod_bootstrap = podatki_skupaj %>%
      filter(alpha==alpha, velikost.vzorca == n, metoda == "bootstrap") %>%
      select(c("x1.lower", "x1.upper"))
    
    pokritost_x1[ind,] = c(alpha, n,
                          mean(pod_klasicna$x1.lower <= 3 & 3 <= pod_klasicna$x1.upper),
                          mean(pod_bootstrap$x1.lower <= 3 & 3 <= pod_bootstrap$x1.upper))
    ind = ind + 1
  }
}
```


```{r pokritost x2}
# stolpci v matriki: alpha, n, klasicna, bootstrap
pokritost_x2 = matrix(NA, nrow = 9, ncol = 4)
ind = 1
for(alpha in c(0.6, 1, 1.2)){
  for(n in c(20, 200, 500)){
    pod_klasicna = podatki_skupaj %>%
      filter(alpha==alpha, velikost.vzorca == n, metoda == "klasicna") %>%
      select(c("x2.lower", "x2.upper"))
    
    pod_bootstrap = podatki_skupaj %>%
      filter(alpha==alpha, velikost.vzorca == n, metoda == "bootstrap") %>%
      select(c("x2.lower", "x2.upper"))
    
    pokritost_x2[ind,] = c(alpha, n,
                          mean(pod_klasicna$x2.lower <= 2 & 2 <= pod_klasicna$x2.upper),
                          mean(pod_bootstrap$x2.lower <= 2 & 2 <= pod_bootstrap$x2.upper))
    ind = ind + 1
  }
}
```


```{r "prikaz pokritost", results=T}

df_pokritost = data.frame("alpha" = pokritost_int[,1], 
                          "n" = pokritost_int[,2],
                          "int_klasicna" = pokritost_int[,3],
                          "int_bootstrap" = pokritost_int[,4],
                          "x1_klasicna" = pokritost_x1[,3],
                          "x1_bootstrap" = pokritost_x1[,4],
                          "x2_klasicna" = pokritost_x2[,3],
                          "x2_bootstrap" = pokritost_x2[,4])

kable(df_pokritost, 
      col.names = c("alpha", "velikost vzorca", rep(c("klasicna", "bootstrap"),3)),
      align = "c", digits = 4) %>%
  add_header_above(c(" " = 2, "intercept" = 2, "beta1" = 2, "beta2" = 2))
```

