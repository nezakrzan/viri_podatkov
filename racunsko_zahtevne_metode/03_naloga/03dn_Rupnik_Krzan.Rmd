---
title: "Domača naloga 3"
author: "Neža Kržan, Tom Rupnik Medjedovič"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
header-includes:
- \usepackage[slovene]{babel}
- \usepackage{float}
- \usepackage[T1]{fontenc}
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", fig.pos = "H", message = FALSE, warning = FALSE, results = F, fig.height =3, fig.width = 6.5)

# potrebne knjižnice
library(ggplot2)
library(car)
library(tidyr)
library(dplyr)
library(ADGofTest)
library(lmerTest)
library(knitr)
library(kableExtra)

# seme
set.seed(2024)
```

# Cilji naloge

Želiva preučiti uporabo metode ponovnega vzorčenja, v primeru ko klasičnimi testom ne moremo popolno zaupati zaradi kršenja predpostavk. Generirala bova podatke, na katerih bova izračunala intervale zaupanja koeficientov linearne regresije. Zaradi kršenja predpostavk  bova s pomočjo testa `boxCox` izvedla primerno transformacijo odzivne spremenljivke (ta bo v vseh primerih `log` transformacija). Na koncu bova med seboj primerjala intervale zaupanja dobljene z linearno regresijo (`lm`) in metodo ponovnega vzorčenja. Primerjavo bova naredila tako na rezultatih pred in po transformaciji, vendar pa moramo paziti, saj rezultati pred in po transformaciji med seboj niso primerljivi. 

Pričakujeva, da bomo z metodo ponovnega vzorčenja dobili boljše rezultate.

# Generiranje podatkov

Podatke sva generirala tako, da je v linearnem regresiji kršena predpostavka linearne odvisnosti odzivne spremenljivke od napovednih in kršena homoskedastičnost (konstantna varianca napak). Enačba, ki sva jo uporabila za generiranje odzivne spremenljivke se glasi:
$$y_i = \beta_0 + \beta_1 \cdot x_{1i} + \beta_2 \cdot x_{2i}^\gamma + \epsilon_i$$
pri čemer:

* $\beta_0$-konstanta enaka 100
* $\beta_1$-koeficient spremenljivke $x_1$ enak $3$ 
* $\beta_2$-koeficient spremenljivke $x_2$ enak $2$ 
* $\gamma$-eksponent, ki ga bova spreminjala (določa nelinearno zvezo)
* $\epsilon$-napaka, ki generirana iz porazdelitve $N(0,x_1\cdot\alpha)$ ($\alpha$ določa povezanost s spremenljivko $x_1$)

Kot sva že omenila bova spreminjala faktorja $\gamma$ in $\alpha$. S faktorjem $\gamma$ bomo kršili prespostavko o linearni zvezi, saj bo ta zavzel vrednosti $0.8$ in $1.4$. S faktorjem $\alpha$ pa bomo kršili predpostavko konstantne variance napak, saj se ta z večanjem vrednosti $x_1$ povečuje. Ta zavzame vrednosti $\alpha\in\{0.6, 1, 1.2\}$

```{r generiranje podatkov}
n = 150 # velikost vzorca

generiranje_podatkov <- function(beta0, beta1, beta2, hetero, eksp) {
  # generiranje vrednosti za x1 in x2 # x1 <- rnorm(n, 50, 3)
  # x2 <- rnorm(n, 200, 8)
  x1 <- runif(n, 20, 60)
  x2 <- runif(n, 2, 10)
  epsilon <- rnorm(n, 0,x1*hetero) # dodava heteroskedasticnost
  # izračun napovedne spremenljivke za model (parametri = vhodni argumenti) 
  # z ^eksp dodava nelinearni del
  y <- beta0 + beta1 * x1 + beta2 * x2^eksp + epsilon
  # podatke spravimo v podatkovni okvir in vrnemo kot rezultat funkcije
  data.frame(x1 = x1, x2 = x2, y = y) 
}

vzorec06_08 = generiranje_podatkov(100, 3, 2, 0.6, 0.8)
vzorec06_14 = generiranje_podatkov(100, 3, 2, 0.6, 1.4)
vzorec1_08 = generiranje_podatkov(100, 3, 2, 1, 0.8)
vzorec1_14 = generiranje_podatkov(100, 3, 2, 1, 1.4)
vzorec12_08 = generiranje_podatkov(100, 3, 2, 1.2, 0.8)
vzorec12_14 = generiranje_podatkov(100, 3, 2, 1.2, 1.4)

# modeli (brez transformacije)
model06_08 = lm(y ~ x1 + x2, vzorec06_08)
model06_14 = lm(y ~ x1 + x2, vzorec06_14)
model1_08 = lm(y ~ x1 + x2, vzorec1_08)
model1_14 = lm(y ~ x1 + x2, vzorec1_14)
model12_08 = lm(y ~ x1 + x2, vzorec12_08)
model12_14 = lm(y ~ x1 + x2, vzorec12_14)
```

Narišimo grafe ostankov za nekaj kombinacij faktorjev, da se prepričamo o kršenju predpostavk.

```{r "graf ostankov 0.6 in 0.8", fig.dim=c(5,3), fig.cap="Grafi ostankov pri paramatrih alpha=0.6 in gamma=0.8"}
par(mfrow=c(1,2))
plot(model06_08, which = c(1,3))
```

```{r "graf ostankov 1.2 in 1.4", fig.dim=c(5,3), fig.cap="Grafi ostankov pri paramatrih alpha=1.2 in gamma=1.4"}
par(mfrow=c(1,2))
plot(model12_14, which = c(1,3))
```

V obeh primerih lahko na desnem grafu opazimo, da se z večanjem vrednosti povečuje tudi variabilnost napak (naraščajoč trend). Na levem grafu lahko sorazmerno s faktorjem $\gamma$ pričakujemo odstopanje vrednosti na robovih. V primeru $\gamma=0.8$ opazimo, da so na robovih nekoliko nižje vrednosti, v primeru $\gamma=1.4$ pa nekoliko višje vrednosti.

Za vsako kombinacijo parametrov preverimo ali se vrednost $\lambda=0$ (`log` transformacija) nahaja znotraj 95% intervala optimalnega parametra $\lambda$, ki ga vrne funkija `powerTransform`.

```{r lambda vrednsoti, results=T}
spodnja = c(summary(powerTransform(model06_08))$result[3],
            summary(powerTransform(model06_14))$result[3],
            summary(powerTransform(model1_08))$result[3],
            summary(powerTransform(model1_14))$result[3],
            summary(powerTransform(model12_08))$result[3],
            summary(powerTransform(model12_14))$result[3])

zgornja = c(summary(powerTransform(model06_08))$result[4],
            summary(powerTransform(model06_14))$result[4],
            summary(powerTransform(model1_08))$result[4],
            summary(powerTransform(model1_14))$result[4],
            summary(powerTransform(model12_08))$result[4],
            summary(powerTransform(model12_14))$result[4])

opt_lambda = data.frame("alpha" = c(0.6, 0.6, 1, 1, 1.2, 1.2),
                        "lambda" = c(rep(c(0.8, 1.4), 3)),
                        "spodnji" = round(spodnja, 3),
                        "zgornji" = round(zgornja,3))

kable(opt_lambda, align = "c")
```

Res je $\lambda=0$ vsebovana v vseh 95% intervalih zaupanja.


# Primerjava vrednosti (brez transformacije)



