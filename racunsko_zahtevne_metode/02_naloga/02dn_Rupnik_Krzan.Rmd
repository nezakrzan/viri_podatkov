---
title: "Domača naloga 2"
author: "Neža Kržan, Tom Rupnik Medjedovič"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
header-includes:
- \usepackage[slovene]{babel}
- \usepackage{float}
- \usepackage[T1]{fontenc}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", fig.pos = "H", message = FALSE, warning = FALSE, results = F, fig.height =3, fig.width = 6.5)

# potrebne knjižnice
library(ggplot2)
library(car)
library(tidyr)
library(dplyr)
library(ADGofTest)

# seme
set.seed(2024)
```

<!-- 
Navodilo:

Clustering

Compare at least 2 methods and find out which one is the best. Generate data for at least 4 groups from a bivariate multivariate normal distribution.  Among other things, examine the effect of adding nonsignificant variables (variables that have the same distribution across all groups).

Primerjaj vsaj dve metodi in ugotovi, katera je najboljša. 
Ustvari podatke za vsaj 4 skupine iz bivariatne multivariatne normalne porazdelitve. 
Med drugim preuči učinek dodajanja nepomembnih spremenljivk (spremenljivk, ki imajo enako porazdelitev v vseh skupinah).
--> 

# Cilj naloge

Želiva preučiti 2 različni metodi razvrščanja v skupine. Primerjaval bova metodo voditeljev(*k-means*) in razvrščanje na podlagi modelov. Zanima nas katera bo najboljša na podatkih, generiranih iz bivariatne multivariatne normalne porazdelitve. 

Zanima naju tudi, kako na metodi vpliva dodajanje nepomembnih spremenljivk, torej tistih, ki imajo enako porazdelitev v vseh skupinah.

Za metodi sva se odločila na podlagi njunih predpostavk, ker so nekatere dokaj podobne, npr. predpostavljajata, da so skupine dovolj ločene oz. ni prekomernega prekirvanja med njimi, homogenosti variance znotraj skupine oz. podatki so v skupinah razmeroma homogeno razporejeni in zahtevata vnaprejšnjo določitev števila skupin, poleg tega pri razvrščanju na podlagi modelov zahtevamo v predpostavkah, da so podatki generirani iz multivariatnih normalnih porazdelitev.

# Generiranje podatkov

Podatke sva generirala tako, da je njihova porazdelitev bivariatna multivariatna normalna. Zanima naju kako se bodo metode obnesle glede na to kako so si skupine med seboj različne. V ta namen sva si izbrala parameter, ki prilagaja povprečja v skupini, tj. $diff = (1, 2, 4, 10)$. Želiva si, da imava primere, ko so si skupine zelo različne med seboj in ne tako zelo različne. Torej bo pri porazdelitvi povprečja generirana s pomočjo faktorja _diff_ in število skupin, kovariančna matrika pa bo po diagonali vsebovala število spremenljivk.

Faktorji, ki jih bova še spreminjala so:

- število skupin, $k = (4, 8, 10)$,
- velikosti skupin, $n = (20, 100, 200)$, pri čemer bodo imele vse skupine vedno enako velikost in
- število spremenljivk, $v = (12, 24, 36)$.
<!--- vnaprejšna določitev števila skupin, $k.2 = (1, 4, 10, 100)$.-->
<!-- Tom28: ne spomnim se tocno zakaj smo na vajah tko naredil da sta bila
stevilo skupin in stevilo spremenljivk povezana, da je stevilo spremenljivk veckratnik stevila skupin...-->

Faktorji so bili izbrani na podlagi tega, da si želiva rezultate, ki bodo dobri in slabi oziroma da bodo za nekatere metode dobri za druge pa slabi.

Pri generiranju podatkov bo število <!--Tom28: informativnih--> spremenljivk enako številu skupin, vse ostale spremenljivke bodo neinformativne, ker nas zanima tudi kako vpliva dodajanje nepomembnih oz. neinformativnih spremenljivk. 

```{r generiranje podatkov, fig.cap="Primer generiranih podatkov za 4 skupine, velikosti n = 100, 12 spremenljivk in diff = 2.", return_all = TRUE, fig.height=4, fig.width=5}
generiranje.podatkov = function(stevilo.spremenljivk, velikost.skupin, stevilo.skupin, diff){
  # generiranje povprečij
  M = diag(stevilo.skupin)*diff 
  
  # neinformativne spremenljivke - same 0
  M = cbind(M, matrix(0, nrow=stevilo.skupin, ncol=stevilo.spremenljivk-stevilo.skupin)) 
  S = diag(stevilo.spremenljivk)
  
  X = NULL 
  # generamo podatke za vsako skupino posebaj
  for(i in 1:stevilo.skupin){
    iX = MASS::mvrnorm(n=velikost.skupin, mu = M[i,], Sigma = S)
    X = rbind(X,iX)
  }
  
  # dodamo se skupino
  X = cbind(X, skupina=rep(1:stevilo.skupin,each=velikost.skupin)) # clu = skupina
  return(X)
}

data.primer1 = generiranje.podatkov(stevilo.spremenljivk = 12, velikost.skupin = 100, stevilo.skupin = 4, diff = 2)
pairs(data.primer1[,1:4], col=data.primer1[,13])
```

```{r generiranje podatkov 2, fig.cap="Primer generiranih podatkov za 4 skupine, velikosti n = 100, 12 spremenljivk in diff = 4.", return_all = TRUE, fig.height=4, fig.width=5}

data.primer2 = generiranje.podatkov(stevilo.spremenljivk = 12, velikost.skupin = 100, stevilo.skupin = 4, diff = 4)
pairs(data.primer2[,1:4], col=data.primer2[,13])
```

# Simulacija

Izvedla sva simulacijo s $100$ ponovitvami in uporabila t.i. paralelno računanje(angl. *parallel computing*). V simulaciji sva generirala podatke in potem izvedla obe metodi razvrščanja v skupine(*metodo voditeljev* in *razvrščanje na podlagi modelov*).

Za obe metodi sva izračunala 3 različne mere, in sicer prilagojeni Randov indeks(*ARI*), vsoto kvadratov znotraj skupine(*WSS*) in proporcija vsote kvadratov znotraj skupine(*PWSS*). \
Prilagojeni Randovi indeksi zavzemajo vrednosti na intervalu $[-1,1]$ in želimo si, da so čim bližje 1, torej da gre za dobro ujemanje med razvrstitvami, kar je boljše od naključnega. Pri meri *WSS* si želimo majhne vrednosti, saj to pomeni, da so skupine bolj kompaktne in s tem so si točke znotraj skupine bolj podobne. Gre sicer za mero, ki je pristranska in jo nekatere metode optimizirajo(ravno metoda *kmeans*). Mera *PWSS* pa oceni delež variabilnosti v podatkih, ki ga pojasnjujejo skupine, v primerjavi z celotno variabilnostjo podatkov in višji kot je, bolje je, saj to pomeni, da so skupine dobro definirane in točke znotraj skupin tesno sledijo svojim centroidom.

Pri primerjavi metod se bova na začetku osredotočala predvsem na prilagojeni Randov indeks(*ARI*), saj je mera *WSS* pristranska in jo nekatere metode optimizirajo(ravno metoda *kmeans*). Meri *WSS* in *PWSS* bosta služili zgolj kot dodaten vpogled.

```{r branje in sprememba podatkov za izris grafov}
res = readRDS("simulacija.RDS")

resLong = pivot_longer(res, cols =matches("^(ari|wss|pwss)\\."),
                       values_to = "value",
                       names_to = c("metric", "method"),
                       names_pattern = "^(ari|wss|pwss)\\.(kmeans|mclust)") 
resWide <- resLong %>% pivot_wider(names_from = metric, values_from = value) # da so ari, wss in pwss vsaka svoj column

resAgg = aggregate(cbind(ari, wss, pwss) ~ stevilo.spremenljivk + velikost.skupin 
                   + stevilo.skupin + method, 
                   data = resWide, FUN = mean)

resAggFac = resAgg
resAggFac$stevilo.spremenljivk = as.factor(resAggFac$stevilo.spremenljivk)
resAggFac$velikost.skupin = as.factor(resAggFac$velikost.skupin)
resAggFac$stevilo.skupin = as.factor(resAggFac$stevilo.skupin)

resAgg_diff = aggregate(cbind(ari, wss, pwss) ~ stevilo.spremenljivk +
                          velikost.skupin + stevilo.skupin + method + diff, 
                        data = resWide, FUN = mean)

resAggFac_diff = resAgg_diff
resAggFac_diff$stevilo.spremenljivk = as.factor(resAggFac_diff$stevilo.spremenljivk)
resAggFac_diff$velikost.skupin = as.factor(resAggFac_diff$velikost.skupin)
resAggFac_diff$stevilo.skupin = as.factor(resAggFac_diff$stevilo.skupin)
resAggFac_diff$diff = as.factor(resAggFac_diff$diff)
```

## Popravljen Randov indeks (ARI)

Poglejmo si kako se spreminja ARI vrednost v primeru, ko spreminjamo število skupin, število spremenljik in velikost skupin, pri tem pa ne upoštevamo kako so si skupine med seboj različne (`diff`). Vrstice predstavljajo spremembo števila skupin, stolpci pa spremembo velikosti skupin.

```{r risanje ARI, fig.cap="Prikaz ARI vrednosti razdeljen glede na velikost skupin in število skupin", fig.height=4, fig.width=5}
ggplot(resAggFac, aes(y = ari, x = stevilo.spremenljivk,
                      col=method, group=method)) + 
  geom_point() + geom_line() +
  facet_grid(stevilo.skupin ~ velikost.skupin, scales="free")
```

Vidimo, da je v vseh kombinacijah števila skupin in velikosti skupin trend ARI vrednosti podajoč, ko povečujemo število spremenljivk. Tudi znotraj posamezne velikosti skupin se vrednost manjša z večanjem števila skupin, čeprav je ta razlika dokaj majhna. Vseeno pa lahko opazimo, da ima metoda `k-means` v vseh primerih večjo ali enako ARI vrednost kot metoda `mclust`. 

Prikažimo vrednosti še nekoliko tako da tokrat vrstice predstavljajo spremembo števila skupin, stolpci pa spremembo števila spremenljivk. 

```{r risanje ARI 2, fig.cap="Prikaz ARI vrednosti razdeljen glede na velikost skupin in število skupin", fig.height=4, fig.width=5}
ggplot(resAggFac, aes(y = ari, x = velikost.skupin,
                      col=method, group=method)) + 
  geom_point() + geom_line() +
  facet_grid(stevilo.skupin ~ stevilo.spremenljivk, scales="free")
```

Najverjetneje bi pričakovali da metodi nekoliko bolje razporedita vrednosti v prave skupine, zato si oglejmo kako se vrednosti razlikujejo če upoštevamo še spremenljivko `diff`.

<!-- Tom30: kateri izmed spodjih ti je lepši? tist k ti ni ga lahko kr pobrises-->

```{r}
ggplot(resAggFac_diff, aes(y = ari, x = stevilo.spremenljivk,
                      col=method, group=interaction(method, diff), linetype=diff)) + 
  geom_point() + geom_line() +
  scale_linetype_manual(values=c("dotted", "dotdash", "dashed", "solid"))+
  facet_grid(stevilo.skupin ~ velikost.skupin, scales="free")
```


```{r}
ggplot(resAggFac_diff, aes(y = ari, x = stevilo.spremenljivk,
                      col=diff, group=interaction(method, diff), linetype=method)) + 
  geom_point() + geom_line() +
  scale_linetype_manual(values=c("solid", "dashed")) +
  scale_color_manual(values = c("darkviolet", "darkgreen", "blue", "red"))+
  facet_grid(stevilo.skupin ~ velikost.skupin, scales="free")
```










