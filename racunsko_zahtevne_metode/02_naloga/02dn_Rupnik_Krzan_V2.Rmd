---
title: "Domača naloga 2"
author: "Neža Kržan, Tom Rupnik Medjedovič"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
header-includes:
- \usepackage[slovene]{babel}
- \usepackage{float}
- \usepackage[T1]{fontenc}
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", fig.pos = "H", message = FALSE, warning = FALSE, results = F, fig.height =3, fig.width = 6.5)

# potrebne knjižnice
library(ggplot2)
library(car)
library(tidyr)
library(dplyr)
library(ADGofTest)
library(lmerTest)
library(knitr)
library(kableExtra)

# seme
set.seed(2024)
```

<!-- 
Navodilo:

Clustering

Compare at least 2 methods and find out which one is the best. Generate data for at least 4 groups from a bivariate multivariate normal distribution.  Among other things, examine the effect of adding nonsignificant variables (variables that have the same distribution across all groups).

Primerjaj vsaj dve metodi in ugotovi, katera je najboljša. 
Ustvari podatke za vsaj 4 skupine iz bivariatne multivariatne normalne porazdelitve. 
Med drugim preuči učinek dodajanja nepomembnih spremenljivk (spremenljivk, ki imajo enako porazdelitev v vseh skupinah).
--> 

# Cilj naloge

Želiva preučiti 2 različni metodi razvrščanja v skupine. Primerjala bova metodo voditeljev(*k-means*) in razvrščanje na podlagi modelov. Za metodo razvrščanje na podlagi modelov sva pustila, da izbere najboljši model na podlagi BIC vrednosti. Število skupin pri kateri se računa BIC vrednost sva določila glede na trenutne nastavitve (`settings`) v iteraciji. Zanima nas katera bo najboljša na podatkih, generiranih iz bivariatne multivariatne normalne porazdelitve. 

Zanima naju tudi, kako na metodi vpliva dodajanje nepomembnih spremenljivk, torej tistih, ki imajo enako porazdelitev v vseh skupinah.

<!-- Tom14: Tukej se nevem kako bi popravil-->
Za metodi sva se odločila na podlagi njunih predpostavk, ker so nekatere dokaj podobne, npr. predpostavljajata, da so skupine dovolj ločene oz. ni prekomernega prekrivanja med njimi, homogenosti variance znotraj skupine oz. podatki so v skupinah razmeroma homogeno razporejeni in zahtevata vnaprejšnjo določitev števila skupin, poleg tega pri razvrščanju na podlagi modelov zahtevamo v predpostavkah, da so podatki generirani iz multivariatnih normalnih porazdelitev.

# Generiranje podatkov

Podatke sva generirala tako, da je njihova porazdelitev bivariatna multivariatna normalna. Zanima naju kako se bodo metode obnesle glede na to kako so si skupine med seboj različne. V ta namen sva si izbrala parameter, ki prilagaja povprečja v skupini, tj. $diff = (1, 2, 4, 10)$. Želiva si, da imava primere, ko so si skupine zelo različne med seboj in ne tako zelo različne. <!--Torej bo pri porazdelitvi povprečja generirana s pomočjo faktorja _diff_ in število skupin, kovariančna matrika pa bo po diagonali vsebovala število spremenljivk.--> Ker si želiva rezultate, kjer bo ena metoda delovala bolje od druge, bova spreminjala tudi korelacije med spremenljivkami <!--skupinami-->, $cor = c(0, 0.2, 0.9)$.

<!--
Za lažje razumevanje si poglejmo primer, kjer je število skupin enako $8$, število informativnih spremenljivk $5$, ter velikost skupin $100$.\
Elemente želimo razporediti v $8$ skupin, zato bo imela vsaka spremenljivka $8*100$ vrednosti. Ker je število skupin enako $8$, bomo imeli $8$ informativnih spremenljivk in $4$ neinformativne.\
Vrednosti neinformativnih spremenljivk generiramo iz porazdelitve tako da imajo povprečje 0 (torej na podlagi njih ne moremo elemente razvrstiti v skupine). 

Vrednosti informativnih spremenljivk pa generiramo iz porazdlitve tako da ima $100$ vrednosti povprečje enako `diff`, preostale $(8-1)*100$ vrednosti pa so generirane iz porazdlitve s povprečjem $0$. Na primer spremenljivka, ki bo v 2. skupini ima vrednost med $101$ in $200$ iz porazdlitve s povprečjem `diff`, vse ostale vrednosti pa iz porazdelitve s povprečjem 0. <!-- Neza17: bi kle mogoče dopisala da je ta porazdelitev bivariatna multivariatna?-->

Faktorji, ki jih bova še spreminjala so:

- število skupin, $k = (4, 8, 14)$,
- velikosti skupin, $n = (20, 100, 200)$, pri čemer bodo imele vse skupine vedno enako velikost in
- število neinformativnih spremenljivk, $v = (1, 4, 10)$.

Faktorji so bili izbrani na podlagi tega, da si želiva rezultate, ki bodo dobri in slabi oziroma da bodo za nekatere metode dobri za druge pa slabi.

<!--Neza17: To sm zdej mal bolj splošno napisala, misls da je okej, al je treba kej bolj podrobno opisat?
Tom19: ne se mi zdi da je tko cist ok-->
Torej če opišemo postopek generiranja podatkov. Število informativnih spremenljivk sva nastavila na število skupin, število neinformativnih spremenljivk pa bova tekom simulacije spreminjala, saj naju tudi zanima vpliv dodajanja le-teh. Vse spremenljivke generirava torej iz bivariatne multivariatne normalne porazdelitve, kjer imajo informativne spremenljivke povprečje enako parametru `diff`, neinformativne pa enako $0$. Standardni odklon pa določiva s pomočjo parametra `cor`, za vse spremenljivke enako(informativne in neinformativne). Število elementov oziroma velikost vzorca, ki ga generirava za spremenljivko pa je določen s pomočjo velikosti skupin. 

<!--
Pri generiranju podatkov bo število spremenljivk enako številu skupin, vse ostale spremenljivke bodo neinformativne, ker nas zanima tudi kako vpliva dodajanje nepomembnih oz. neinformativnih spremenljivk. 
-->

V naslednjih dveh primerih je število **vseh** spremenljivk enako $5$, kjer je $1$ spremenljivka **neinformativna**, torej je število skupin enako 4. Na grafu so vidne le 4 spremenljivke, ker ena od vseh ni informativna.

```{r generiranje podatkov, fig.cap="Primer generiranih podatkov za 4 skupine, velikosti n = 100, 5 spremenljivk ter diff = 2 in cor = 0.", return_all = TRUE, fig.height=4, fig.width=5}
source("generiranje_podatkov.R")

set.seed(2024)
stevilo.neinformativnih.sprem = 1
velikost.skupin = 100
stevilo.skupin = 4
diff = 2
cor = 0
data.primer1 = generiranje.podatkov(velikost.skupin, stevilo.skupin, 
                     stevilo.neinformativnih.sprem, diff, cor)
pairs(data.primer1[,1:5], col=data.primer1[,6])
```

# Simulacija

Izvedla sva simulacijo s $100$ ponovitvami (za večje število ponovitev se nisva odločila zaradi časovne zahtevnosti) in uporabila t.i. paralelno računanje(angl. *parallel computing*). V simulaciji sva generirala podatke in potem izvedla obe metodi razvrščanja v skupine(*metodo voditeljev* in *razvrščanje na podlagi modelov*).

Za obe metodi sva izračunala mero prilagojeni Randov indeks(*ARI*), ki sva jo uporabila za analizo in primerjavo metod med seboj.

<!--
Za obe metodi sva izračunala 3 različne mere, in sicer prilagojeni Randov indeks(*ARI*), vsoto kvadratov znotraj skupine(*WSS*) in proporcija vsote kvadratov znotraj skupine(*PWSS*). (Zadnji dve meri sva zaradi "neprimernosti" kasneje opustila in ju tudi nisva obravnavala) \ -->
<!-- Tom04: tole v oklepaju sm dodal tko da nisi za bv vse tole spodi pisala ce si se ze potrudla-->

Prilagojeni Randovi indeksi zavzemajo vrednosti na intervalu $[-1,1]$ in želimo si, da so čim bližje 1, torej da gre za dobro ujemanje med razvrstitvami, kar je boljše od naključnega (vrednosti blizu 0). <!--Pri meri *WSS* si želimo majhne vrednosti, saj to pomeni, da so skupine bolj kompaktne in s tem so si točke znotraj skupine bolj podobne. Gre sicer za mero, ki je pristranska in jo nekatere metode optimizirajo(ravno metoda *kmeans*). Mera *PWSS* pa oceni delež variabilnosti v podatkih, ki ga pojasnjujejo skupine, v primerjavi z celotno variabilnostjo podatkov in višji kot je, bolje je, saj to pomeni, da so skupine dobro definirane in točke znotraj skupin tesno sledijo svojim centroidom.-->

<!-- Tom04: Za PWSS bi jst reku da more bit tud cim manjši ker je v stevcu WSS torej razdalje tock od centrov skupin, v imenovalcu pa WSS ce bi ble vse tocke v eni skupini...in blizje 1 kot bo vrednost ulomka, vecje bojo mogle bit WSS znotraj posamezne skupine oz zelo podobna razporeditev v skupine (slaba razporeditev) kot bi bila ce bi bile vse tocke v eni skupini-->

<!--Pri primerjavi metod se bova na začetku osredotočala predvsem na prilagojeni Randov indeks(*ARI*), saj je mera *WSS* pristranska in jo nekatere metode optimizirajo(ravno metoda *kmeans*).-->

Pri primerjavi metod sva se osredotočala predvsem na prilagojeni Randov indeks(*ARI*), saj so nekatere druge mere kot naprimer *WSS* pristranske in jo nekatere metode optimizirajo(ravno metoda *kmeans*).


# Analiza

Analizo rezultatov bova razdelila v več delov, saj pri simulaciji spreminjava veliko število faktorjev (*število skupin*, *število neinformativnih spremenljivk*, *velikost skupin*, razliko med skupinami (*diff*) in korelacijo (*cor*)). Odločila sva se za delitev glede na vrednost povprečja v skupini (razlike povprečja skupin).

Pričakujeva, da bosta metodi pri večjih vrednostih `diff` nekoliko boljše delovali, saj so skupine med seboj dobro ločene oz. je med njimi manj prekrivanja. V nasprotju pa je s spreminjanjem korelacije med spremenljivkami, saj pričakujeva, da bo bo pri niži korelaciji oziroma brez korelacije metoda voditeljev delovala bolje kot razvrščanje na podlagi modelov in ravno nasportno, ko bo korelacija visoka.

```{r "branje podatkov"}
# prebereva in urediva podatke
res = readRDS("simulacijaV3.RDS")

resLong = pivot_longer(res, cols =matches("^(ari)\\."),
                       values_to = "value",
                       names_to = c("metric", "method"),
                       names_pattern = "^(ari)\\.(kmeans|mclust)") 
resLong$method[resLong$method == "kmeans"] = "metoda voditeljev"
resLong$method[resLong$method == "mclust"] = "razvrscanje na podlagi modelov"

resAgg = aggregate(value ~ stevilo.neinformativnih.sprem +
                          velikost.skupin + stevilo.skupin + method + diff + cor, 
                        data = resLong, FUN = mean)
# ce bova rabila se skupno stevilo spremneljivk
resAgg$skupaj_sprem = resAgg$stevilo.neinformativnih.sprem + resAgg$stevilo.skupin

resAgg_factor = resAgg
resAgg_factor$stevilo.neinformativnih.sprem = factor(resAgg_factor$stevilo.neinformativnih.sprem)
resAgg_factor$velikost.skupin = factor(resAgg_factor$velikost.skupin)
resAgg_factor$stevilo.skupin = factor(resAgg_factor$stevilo.skupin)
resAgg_factor$diff = factor(resAgg_factor$diff)
resAgg_factor$cor = factor(resAgg_factor$cor)
resAgg_factor$skupaj_sprem = factor(resAgg$skupaj_sprem)
```


## `diff` = 1

Graf prikazuje spreminjanje ARI vrednosti v odvisnosti od števila skupin, pri čemer vrstice predstavljajo korelacijo med spremenljivkami, stolpci pa število neinformativnih spremenljivk.

```{r "risanje diff 1", fig.cap="Prikaz ARI vrednosti, ko je razlika povprečja skupin enaka 1."}
# iz podatkov izbereva le diff=1
pod_diff1 = resAgg_factor %>% filter(diff == 1)

custom_labeller <- labeller(
  cor = function(x) paste("cor =", x),
  stevilo.neinformativnih.sprem = function(x) paste("st. neinfo. sprem. =", x)
)

ggplot(pod_diff1, aes(y = value, x = stevilo.skupin,
                      col=method, group=interaction(method, velikost.skupin), linetype=velikost.skupin)) + 
  geom_point() + geom_line() +
  scale_linetype_manual(values=c("dotted", "dashed", "solid"))+
  facet_grid(cor~stevilo.neinformativnih.sprem, scales="free", labeller = custom_labeller)+
  xlab("stevilo skupin") + 
  ylab("ARI") + 
  theme_minimal() + 
  labs(color = "Metoda:") 
```

Najbolj očitna razlika med metodama je vidna s spreminjanjem korelacije med spremenljivkami. \
Ko korelacija ni prisotna bi lahko rekli da metoda voditeljev nekoliko bolje razporedi enote v skupine, čeprav je razlika med njima minimalna. Prav tako bi lahko enako trdili v primeru `cor`=2, kjer so razlike majhne in se zmanjšujejo, ko se število neinformativnih spremenljivk povečuje. Ko pa je korelacija med spremenljivkami enaka $0.9$, metoda razvrščanja na podlagi modelov veliko bolje razlikuje med skupinami. \
V vseh kombinacijah faktorjev je možno videti, da vrednost ARI z naraščanje števila skupin pada. Prav tako vrednost pada, ko število neinformativnih spremenljivk narašča. 


## `diff` = 2

Graf prikazuje spreminjanje ARI vrednosti v odvisnosti od števila skupin, pri čemer vrstice predstavljajo korelacijo med spremenljivkami, stolpci pa število neinformativnih spremenljivk.

```{r "risanje diff 2", fig.cap="Prikaz ARI vrednosti, ko je razlika povprečja skupin enaka 2."}
# iz podatkov izbereva le diff=1
pod_diff2 = resAgg_factor %>% filter(diff == 2)

ggplot(pod_diff2, aes(y = value, x = stevilo.skupin,
                      col=method, group=interaction(method, velikost.skupin), linetype=velikost.skupin)) + 
  geom_point() + geom_line() +
  scale_linetype_manual(values=c("dotted", "dashed", "solid"))+
  facet_grid(cor~stevilo.neinformativnih.sprem, scales="free", labeller = custom_labeller)+
  xlab("stevilo skupin") + 
  ylab("ARI") + 
  theme_minimal() + 
  labs(color = "Metoda:") 
```

Tokrat je očitna razlika med metodam vidna le v primeru, ko je korelacija enaka $0.9$. V preostalih dveh primerih pa se vrednosti izračunane po metodi voditeljev in razvrščanja na podlagi modelov med seboj prepletajo. Nekoliko večja razlika je le desnem grafu `cor`=0.2, ko metoda voditeljev v vseh primerih vrne boljše rezultate.

Tako kot v predhodnem razdelku je v vseh kombinacijah faktorjev možno videti, da vrednost ARI z naraščanje števila skupin pada. Prav tako vrednost pada, ko število neinformativnih spremenljivk narašča, kar lahko bolj natančno vidimo tudi na spodnjem grafu


```{r "risanje diff 2 neinf sprem", fig.cap="Prikaz ARI vrednosti, ko je razlika povprečja skupin enaka 2 glede na število neinfomrativnih spremenljivk."}
# iz podatkov izbereva le diff=1
pod_diff2 = resAgg_factor %>% filter(diff == 2)

custom_labeller <- labeller(
  cor = function(x) paste("cor =", x),
  stevilo.skupin = function(x) paste("st. skupin =", x)
)

ggplot(pod_diff2, aes(y = value, x = stevilo.neinformativnih.sprem,
                      col=method, group=interaction(method, velikost.skupin), linetype=velikost.skupin)) + 
  geom_point() + geom_line() +
  scale_linetype_manual(values=c("dotted", "dashed", "solid"))+
  facet_grid(cor~stevilo.skupin, scales="free", labeller = custom_labeller)+
  xlab("stevilo neinformativnih spremenljivk") + 
  ylab("ARI") + 
  theme_minimal() + 
  labs(color = "Metoda:") 
```

## `diff` = 4

Graf prikazuje spreminjanje ARI vrednosti v odvisnosti od števila skupin, pri čemer vrstice predstavljajo korelacijo med spremenljivkami, stolpci pa število neinformativnih spremenljivk.

```{r "risanje diff 4", fig.cap="Prikaz ARI vrednosti, ko je razlika povprečja skupin enaka 4."}
# iz podatkov izbereva le diff=1
pod_diff4 = resAgg_factor %>% filter(diff == 4)

ggplot(pod_diff4, aes(y = value, x = stevilo.skupin,
                      col=method, group=interaction(method, velikost.skupin), linetype=velikost.skupin)) + 
  geom_point() + geom_line() +
  scale_linetype_manual(values=c("dotted", "dashed", "solid"))+
  facet_grid(cor~stevilo.neinformativnih.sprem, scales="free", labeller = custom_labeller)+
  xlab("stevilo skupin") + 
  ylab("ARI") + 
  theme_minimal() + 
  labs(color = "Metoda:") 
```

Kot lahko opazimo se z večanjem razlike povprečja skupin, razlike v ARI vrednosti med metodama manjšajo. Izjema je le `cor` = 0.9, kjer z metodo voditeljev ne dobimo dobrih rezultatov. 

Če si ogledamo 3. stolpec (*število neinformativnih sprmeneljivk* = 10) opazimo, da metoda *razvrščanja na podlagi modelov* vrne nekoliko slabše rezultate v primeru, ko imamo majhno velikost skupin. 

Izpostavimo lahko še zadnjo vrstico (`cor` = 0.9), kjer opazimo, da *metoda voditeljev* vrne dober rezultat, le v primeru, ko je število skupin in število neinformativnih spremenljivk majhno. Ko pa se te dve vrednosti povečata, ARI vrednost dosti pade. 

## `diff` = 10

Graf prikazuje spreminjanje ARI vrednosti v odvisnosti od števila skupin, pri čemer vrstice predstavljajo korelacijo med spremenljivkami, stolpci pa število neinformativnih spremenljivk.

```{r "risanje diff 10", fig.cap="Prikaz ARI vrednosti, ko je razlika povprečja skupin enaka 10."}
# iz podatkov izbereva le diff=1
pod_diff10 = resAgg_factor %>% filter(diff == 10)

ggplot(pod_diff10, aes(y = value, x = stevilo.skupin,
                      col=method, group=interaction(method, velikost.skupin), linetype=velikost.skupin)) + 
  geom_point() + geom_line() +
  scale_linetype_manual(values=c("dotted", "dashed", "solid"))+
  facet_grid(cor~stevilo.neinformativnih.sprem, scales="free", labeller = custom_labeller)+
  xlab("stevilo skupin") + 
  ylab("ARI") + 
  theme_minimal() + 
  labs(color = "Metoda:") 
```

Tokrat dobimo dokaj nezanimive rezultate, saj so vse vrednosti blizu 1, kar naj bi pomenilo smo enote popolnoma pravilno razporedili v skupine. Zaključimo lahko le, da če imamo dovolj ločene skupine (povprečja) je vseeno katero metodo uporabimo, saj obe dobro ločujeta med skupinami.

## Analiza

Iz zgornjih grafov je torej očitno, da spreminjanje faktorja `diff` in `cor` znatno vplivata na to, katera metoda je boljša za razvrščanje v skupine. \ Pri manjši korelaciji oz. kjer korelacije ni in je ločljivost med skupinami majhna(`diff` = 1), bolje deluje metoda voditeljev, pri večji pa metoda razvršanja na podlagi modelov. Ko pa se ločljivost med skupinami poveča(torej bolje ločimo med skupinami, `diff` = 2, 4, 10), pa je razlika med metodama pri majhnih korelacijah minimalna oz. je skoraj da ni, pokaže se šele pri večji korelaciji, ko je metoda razvrščanja na podlagi modelov vidno boljša. \
Faktor `diff` tudi močno vpliva na koeficient ARI, ki je pri večjih ločljivostih med skupinami (skoraj) enak 1, kar kaže na preprleganje modelov oz. predobro razvršanje v skupine i je tud vseeno, ne glede na ostale fakotre, katero metodo vzamemo.

Na mero ARI vpliva tudi večanje števila skupin v katere razvršačmo enote - ta se z večanjem skupin vidno manjša, torej bi lahko rekla, da razvrščanje v (pre)več skupin ne deluje dobro z obe matodama. \
Prav tako se kakovost razvrščanja v skupine pri obeh metodah manjša(nobena ni boljša) z dodajanjem neinformativnih spremenljivk.

# Primerjava metod za razvrščanje v skupine 

Metodi bova primerjala s pomočjo ANOVA testa in linearnih mešanih modelov, kjer pričakujeva podobne rezultate. Na podlagi zgornjih grafov predvidevava, da bodo vrednosti fakoraj `diff` in `cor` nekoliko bolj statistično pomembno vplivala na rezultate analize, kot vrednosti drugih faktorjev.

## ANOVA

V spodnji tabeli lahko vidimo količina variabilnosti glede na faktorje, ki jih testiramo in informacijo o statistični značilnosti posameznih spremenljivk in njihovih kombinacij. Razvidno je, da so nekateri faktorji in kombinacije le teh statistično pomembi in razlike med različnimi vrednostmi faktorjev vplivajo na rezultate. Izrazito tako odstopata faktorji `diff` in `cor` ter njuna interakcija, kar bi lahko rekla, da vsa ugotovila že pri zgornji analizi. Prav tako nekoliko bolj na rezultate analize vplivajo interakcije z drugimi faktorji, kjer sta `diff` in `cor` tudi zraven(npr. interakcija `velikost.skupin:diff:cor`). Prav tako so vrednosti faktorja `stevilo.skupin` tud statistično pomembni in vplivajo bolj na rezultate analize, katera metoda za razvrščanje v skupine je boljša.

```{r "anova"}
resLongF = resLong
# spremeniva v faktor
for(sprem in c("i", "stevilo.neinformativnih.sprem", "velikost.skupin", 
               "stevilo.skupin", "diff", "cor")){
  resLongF[[sprem]] = as.factor(resLongF[[sprem]])
}
# stolpec 'value' preimneujeva v 'ari'
names(resLongF) = sub('value', 'ari', names(resLongF))

useOld_aov = T # uporabi ze izracunane podatke
if(useOld_aov == F){
  aov_vred = aov(ari ~ stevilo.neinformativnih.sprem*velikost.skupin*stevilo.skupin*diff*cor,
                   data = resLongF)
  anova_vred_aov = anova(aov_vred) 
  saveRDS(object = anova_vred_aov, file="aov_vrednosti.RDS")
}
anova_vred_aov = readRDS("aov_vrednosti.RDS")
```

```{r "prikaz anova", results=T}
kable((anova_vred_aov[1:(nrow(anova_vred_aov)-1),] %>%
  arrange(desc(`Sum Sq`))), align = "c",
  caption = "Prikaz rezultatov ANOVA testa.") %>%
  kable_styling(font_size = 7, latex_options = "HOLD_position")
```


## Linearni mešani modeli

Primerjajmo metodi še s pomočjo linearnih mešanih modelov, kjer je iz spodnje tabele razvidno, da res dobimo, glede na razvrstitev statistične pomembnosti, enake faktorje kot pri zgornjem testu. 

```{r "lmer"}
useOld_lmer = T # uporabi ze izracunane podatke
if(useOld_lmer == F){
  lmer_vred = lmer(ari ~ stevilo.neinformativnih.sprem*velikost.skupin*stevilo.skupin*diff*cor+(1|i),
                   data = resLongF)
  anova_vred_lmer = anova(lmer_vred) 
  saveRDS(object = anova_vred_lmer, file="lmer_vrednosti.RDS")
}
anova_vred_lmer = readRDS("lmer_vrednosti.RDS")
```

```{r "prikaz lmer", results=T}
kable((anova_vred_lmer[1:(nrow(anova_vred_lmer)-1),] %>%
  arrange(desc(`Sum Sq`))), align = "c",
  caption = "Prikaz rezultatov linearnih mešanih modelov.") %>%
  kable_styling(font_size = 7, latex_options = "HOLD_position")
```


# Zaključek

Pri primerjavi dveh metod za razvrščanje v skupine, *metodo voditeljev* ter *razvrščanje na podlagi modelov*, na podlagi mere prilagojeni Randov indeks (ARI) sva ugotovila, da na vrednost ARI pa ne vpliva negativno samo število nepomembnih spremenljivk(tistih, ki imajo enako porazdelitev v vseh skupinah), ampak tudi število skupin v katere želimo razporediti posamezne točke. S tem sva potrdila tudi najno predvidevanje, da se bo z večanjem števila skupin indeks ARI manjšal, ker postane razvrščanje težje, saj pri več skupinah obstaja več kombinacij za razvrščanje, zato je večja verjetnost napačnih ujemanj. V primeru, da je število skupin veliko in so te blizu skupaj, je verjetnost za napačno razporeditev velika. 

Na 'kvaliteto' razporeditve v skupine pa najbolj vpliva ločljivost med skupinami (`diff`) in korelacija(`cor`)(glede na ANOVA test in linearne mešane modele), tudi razlika v metodah je očitna. Če imamo dokaj normalno ločljivost med skupinami(npr. `diff` = 2) in nimamo korelacije je nekoliko boljša metoda voditeljev, ampak že opri majhnih korelacijah, pa je razvrščanje na podlagi modelov boljše. Torej, če imamo med spremenljivkami korelacijo je bolje za razvrščanje v skupine uporabiti metodo razvršanja na podlagi modelov, v nasprotnem primeru pa metodo voditeljev. 






