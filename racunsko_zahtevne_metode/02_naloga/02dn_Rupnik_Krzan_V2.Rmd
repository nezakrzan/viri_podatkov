---
title: "Domača naloga 2"
author: "Neža Kržan, Tom Rupnik Medjedovič"
output:
  pdf_document:
    fig_caption: true
    number_sections: true
header-includes:
- \usepackage[slovene]{babel}
- \usepackage{float}
- \usepackage[T1]{fontenc}
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", fig.pos = "H", message = FALSE, warning = FALSE, results = F, fig.height =3, fig.width = 6.5)

# potrebne knjižnice
library(ggplot2)
library(car)
library(tidyr)
library(dplyr)
library(ADGofTest)
library(lmerTest)
library(knitr)
library(kableExtra)

# seme
set.seed(2024)
```

<!-- 
Navodilo:

Clustering

Compare at least 2 methods and find out which one is the best. Generate data for at least 4 groups from a bivariate multivariate normal distribution.  Among other things, examine the effect of adding nonsignificant variables (variables that have the same distribution across all groups).

Primerjaj vsaj dve metodi in ugotovi, katera je najboljša. 
Ustvari podatke za vsaj 4 skupine iz bivariatne multivariatne normalne porazdelitve. 
Med drugim preuči učinek dodajanja nepomembnih spremenljivk (spremenljivk, ki imajo enako porazdelitev v vseh skupinah).
--> 

# Cilj naloge

Želiva preučiti 2 različni metodi razvrščanja v skupine. Primerjala bova metodo voditeljev(*k-means*) in razvrščanje na podlagi modelov. Za metodo razvrščanje na podlagi modelov sva pustila, da izbere najboljši model na podlagi BIC vrednosti. Število skupin pri kateri se računa BIC vrednost sva določila glede na trenutne nastavitve (`settings`) v iteraciji. Zanima nas katera bo najboljša na podatkih, generiranih iz bivariatne multivariatne normalne porazdelitve. 

Zanima naju tudi, kako na metodi vpliva dodajanje nepomembnih spremenljivk, torej tistih, ki imajo enako porazdelitev v vseh skupinah.

<!-- Tom14: Tukej se nevem kako bi popravil-->
Za metodi sva se odločila na podlagi njunih predpostavk, ker so nekatere dokaj podobne, npr. predpostavljajata, da so skupine dovolj ločene oz. ni prekomernega prekrivanja med njimi, homogenosti variance znotraj skupine oz. podatki so v skupinah razmeroma homogeno razporejeni in zahtevata vnaprejšnjo določitev števila skupin, poleg tega pri razvrščanju na podlagi modelov zahtevamo v predpostavkah, da so podatki generirani iz multivariatnih normalnih porazdelitev.

# Generiranje podatkov

Podatke sva generirala tako, da je njihova porazdelitev bivariatna multivariatna normalna. Zanima naju kako se bodo metode obnesle glede na to kako so si skupine med seboj različne. V ta namen sva si izbrala parameter, ki prilagaja povprečja v skupini, tj. $diff = (1, 2, 4, 10)$. Želiva si, da imava primere, ko so si skupine zelo različne med seboj in ne tako zelo različne. <!--Torej bo pri porazdelitvi povprečja generirana s pomočjo faktorja _diff_ in število skupin, kovariančna matrika pa bo po diagonali vsebovala število spremenljivk.--> Ker si želiva rezultate, kjer bo ena metoda delovala bolje od druge, bova spreminjala tudi korelacije med skupinami, $cor = c(0, 0.2, 0.9)$.

<!--
Za lažje razumevanje si poglejmo primer, kjer je število skupin enako $8$, število informativnih spremenljivk $5$, ter velikost skupin $100$.\
Elemente želimo razporediti v $8$ skupin, zato bo imela vsaka spremenljivka $8*100$ vrednosti. Ker je število skupin enako $8$, bomo imeli $8$ informativnih spremenljivk in $4$ neinformativne.\
Vrednosti neinformativnih spremenljivk generiramo iz porazdelitve tako da imajo povprečje 0 (torej na podlagi njih ne moremo elemente razvrstiti v skupine). 

Vrednosti informativnih spremenljivk pa generiramo iz porazdlitve tako da ima $100$ vrednosti povprečje enako `diff`, preostale $(8-1)*100$ vrednosti pa so generirane iz porazdlitve s povprečjem $0$. Na primer spremenljivka, ki bo v 2. skupini ima vrednost med $101$ in $200$ iz porazdlitve s povprečjem `diff`, vse ostale vrednosti pa iz porazdelitve s povprečjem 0. <!-- Neza17: bi kle mogoče dopisala da je ta porazdelitev bivariatna multivariatna?-->

Faktorji, ki jih bova še spreminjala so:

- število skupin, $k = (4, 8, 14)$,
- velikosti skupin, $n = (20, 100, 200)$, pri čemer bodo imele vse skupine vedno enako velikost in
- število neinformativnih spremenljivk, $v = (1, 4, 10)$.

Faktorji so bili izbrani na podlagi tega, da si želiva rezultate, ki bodo dobri in slabi oziroma da bodo za nekatere metode dobri za druge pa slabi.

<!--Neza17: To sm zdej mal bolj splošno napisala, misls da je okej, al je treba kej bolj podrobno opisat?-->
Torej če opišemo postopek generiranja podatkov. Število informativnih spremenljivk sva nastavila na število skupin, število neinformativnih spremenljivk pa bova tekom simulacije spreminjala, saj naju tudi zanima vpliv dodajanja le-teh. Vse spremenljivke generirava torej iz bivariatne multivariatne normalne porazdelitve, kjer imajo informativne spremenljivke povprečje enako parametru `diff`, neinformativne pa enako $0$. Standardni odklon pa določiva s pomočjo parametra `cor`, za vse spremenljivke enako(informativne in neinformativne). Število elementov oziroma velikost vzorca, ki ga generirava za spremenljivko pa je določen s pomočjo velikosti skupin. 

<!--
Pri generiranju podatkov bo število spremenljivk enako številu skupin, vse ostale spremenljivke bodo neinformativne, ker nas zanima tudi kako vpliva dodajanje nepomembnih oz. neinformativnih spremenljivk. 
-->

V naslednjih dveh primerih je število **vseh** spremenljivk enako $5$, kjer je $1$ spremenljivka **neinformativna**, torej je število skupin enako 4. Na grafu so vidne le 4 spremenljivke, ker ena od vseh ni informativna.

```{r generiranje podatkov, fig.cap="Primer generiranih podatkov za 4 skupine, velikosti n = 100, 5 spremenljivk ter diff = 2 in cor = 0.", return_all = TRUE, fig.height=4, fig.width=5}
source("generiranje_podatkov.R")

set.seed(2024)
stevilo.neinformativnih.sprem = 1
velikost.skupin = 100
stevilo.skupin = 4
diff = 2
cor = 0
data.primer1 = generiranje.podatkov(velikost.skupin, stevilo.skupin, 
                     stevilo.neinformativnih.sprem, diff, cor)
pairs(data.primer1[,1:5], col=data.primer1[,6])
```

# Simulacija

Izvedla sva simulacijo s $100$ ponovitvami (za večje število ponovitev se nisva odločila zaradi časovne zahtevnosti) in uporabila t.i. paralelno računanje(angl. *parallel computing*). V simulaciji sva generirala podatke in potem izvedla obe metodi razvrščanja v skupine(*metodo voditeljev* in *razvrščanje na podlagi modelov*).

Za obe metodi sva izračunala mero prilagojeni Randov indeks(*ARI*), ki sva jo uporabila za analizo in primerjavo metod med seboj.

<!--
Za obe metodi sva izračunala 3 različne mere, in sicer prilagojeni Randov indeks(*ARI*), vsoto kvadratov znotraj skupine(*WSS*) in proporcija vsote kvadratov znotraj skupine(*PWSS*). (Zadnji dve meri sva zaradi "neprimernosti" kasneje opustila in ju tudi nisva obravnavala) \ -->
<!-- Tom04: tole v oklepaju sm dodal tko da nisi za bv vse tole spodi pisala ce si se ze potrudla-->

Prilagojeni Randovi indeksi zavzemajo vrednosti na intervalu $[-1,1]$ in želimo si, da so čim bližje 1, torej da gre za dobro ujemanje med razvrstitvami, kar je boljše od naključnega (vrednosti blizu 0). <!--Pri meri *WSS* si želimo majhne vrednosti, saj to pomeni, da so skupine bolj kompaktne in s tem so si točke znotraj skupine bolj podobne. Gre sicer za mero, ki je pristranska in jo nekatere metode optimizirajo(ravno metoda *kmeans*). Mera *PWSS* pa oceni delež variabilnosti v podatkih, ki ga pojasnjujejo skupine, v primerjavi z celotno variabilnostjo podatkov in višji kot je, bolje je, saj to pomeni, da so skupine dobro definirane in točke znotraj skupin tesno sledijo svojim centroidom.-->

<!-- Tom04: Za PWSS bi jst reku da more bit tud cim manjši ker je v stevcu WSS torej razdalje tock od centrov skupin, v imenovalcu pa WSS ce bi ble vse tocke v eni skupini...in blizje 1 kot bo vrednost ulomka, vecje bojo mogle bit WSS znotraj posamezne skupine oz zelo podobna razporeditev v skupine (slaba razporeditev) kot bi bila ce bi bile vse tocke v eni skupini-->

<!--Pri primerjavi metod se bova na začetku osredotočala predvsem na prilagojeni Randov indeks(*ARI*), saj je mera *WSS* pristranska in jo nekatere metode optimizirajo(ravno metoda *kmeans*).-->

Pri primerjavi metod sva se osredotočala predvsem na prilagojeni Randov indeks(*ARI*), saj so nekatere druge mere kot naprimer *WSS* pristranske in jo nekatere metode optimizirajo(ravno metoda *kmeans*).
