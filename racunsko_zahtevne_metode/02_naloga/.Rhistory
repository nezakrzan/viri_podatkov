suppressMessages({ # v konzoli se ne izpisuje fitting
model = capture.output({
mclust.res = mclust::Mclust(data.scale, G = stevilo.skupin) # kle nevem cist tocn, k zgori je za nstart kao zacetno stevilo skupin ane in pol sm mal googlala sam kle pa nevem cit tocn kaj nastavt...
})
})
res$ari.mclust[row] = blockmodeling::crand(data$skupina, mclust.res$classification) #ari
# kje se nahaja zanka
if(row%%10==0) cat("Iteration ", row, "/", nrow(settings), "complete! \n")
}
saveRDS(res, "simulacija.RDS")
stopCluster(cl)
}
res
# na enem slajdu v predavanjih pise: Why is "sum of squares within clusters" not a good measure?
# in moj zapisek na to je: Cilj clusteringa najti skupine ki so si čim manj podobne ampak elemnti v skupini pa čim bolj skupi. Nekatere metode optimize to mero(k-means) in nekatere ne, zato ni najboljša mera...
# sm sla gledat v lansko kar smo delala, ampak te dve metodi nimata nobene skupne mere...
# zdej pa nevem al dodava se wss al ne? mal sm googlala je se nek Silhuetni koeficient
# meri pa, kako podobne so si točke znotraj gruče v primerjavi z najbližjo sosednjo gručo. Giblje se od -1 do 1, kjer večja vrednost pomeni boljše grupiranje.
################################# grafični prikaz ##############################
resLong = pivot_longer(res, cols=matches("^p[AM]"), values_to = "ariVal",
names_to = "method", names_prefix = "ari.")
# na enem slajdu v predavanjih pise: Why is "sum of squares within clusters" not a good measure?
# in moj zapisek na to je: Cilj clusteringa najti skupine ki so si čim manj podobne ampak elemnti v skupini pa čim bolj skupi. Nekatere metode optimize to mero(k-means) in nekatere ne, zato ni najboljša mera...
# sm sla gledat v lansko kar smo delala, ampak te dve metodi nimata nobene skupne mere...
# zdej pa nevem al dodava se wss al ne? mal sm googlala je se nek Silhuetni koeficient
# meri pa, kako podobne so si točke znotraj gruče v primerjavi z najbližjo sosednjo gručo. Giblje se od -1 do 1, kjer večja vrednost pomeni boljše grupiranje.
################################# grafični prikaz ##############################
library(dplyr)
resLong = pivot_longer(res, cols=matches("^p[AM]"), values_to = "ariVal",
names_to = "method", names_prefix = "ari.")
# na enem slajdu v predavanjih pise: Why is "sum of squares within clusters" not a good measure?
# in moj zapisek na to je: Cilj clusteringa najti skupine ki so si čim manj podobne ampak elemnti v skupini pa čim bolj skupi. Nekatere metode optimize to mero(k-means) in nekatere ne, zato ni najboljša mera...
# sm sla gledat v lansko kar smo delala, ampak te dve metodi nimata nobene skupne mere...
# zdej pa nevem al dodava se wss al ne? mal sm googlala je se nek Silhuetni koeficient
# meri pa, kako podobne so si točke znotraj gruče v primerjavi z najbližjo sosednjo gručo. Giblje se od -1 do 1, kjer večja vrednost pomeni boljše grupiranje.
################################# grafični prikaz ##############################
library(tidyverse)
resLong = pivot_longer(res, cols=matches("^p[AM]"), values_to = "ariVal",
names_to = "method", names_prefix = "ari.")
library(dplyr)
resLong = pivot_longer(res, values_to = "ariVal",
names_to = "method", names_prefix = "ari.") # cols=matches("^p[AM]")
res
set.seed(2024)
library(tidyr)
# na enem slajdu v predavanjih pise: Why is "sum of squares within clusters" not a good measure?
# in moj zapisek na to je: Cilj clusteringa najti skupine ki so si čim manj podobne ampak elemnti v skupini pa čim bolj skupi. Nekatere metode optimize to mero(k-means) in nekatere ne, zato ni najboljša mera...
# sm sla gledat v lansko kar smo delala, ampak te dve metodi nimata nobene skupne mere...
# zdej pa nevem al dodava se wss al ne? mal sm googlala je se nek Silhuetni koeficient
# meri pa, kako podobne so si točke znotraj gruče v primerjavi z najbližjo sosednjo gručo. Giblje se od -1 do 1, kjer večja vrednost pomeni boljše grupiranje.
################################# grafični prikaz ##############################
library(tidyr)
setwd("~/Documents/viri_podatkov/racunsko_zahtevne_metode/01_naloga")
st_ponovitev = 5000
velikost = c(15, 40, 60, 100, 200, 1000)
############################### p - vrednost ##################################
settings = expand.grid(i=1:st_ponovitev, n = velikost,
var = c("1,10,1", "1,5,10", "1,1,1"))
if(file.exists("p_vrednost.RDS")){
res<-readRDS("p_vrednost.RDS")
} else {
res<-cbind(settings, pANOVA=NA, pANOVA_2=NA, pMETHOD3=NA)
for(row in 1:nrow(settings)){
# dolocitev velikosti skupin in varianc
velikost = settings$n[row]
var_skupaj = as.numeric(strsplit(as.character(settings$var[row]),",")[[1]])
sd1 = sqrt(var_skupaj[1])
sd2 = sqrt(var_skupaj[2])
sd3 = sqrt(var_skupaj[3])
# generiranje skupin
x<-c(rnorm(velikost, 0, sd1),
rnorm(velikost, 0, sd2),
rnorm(velikost, 0, sd3))
gr<-factor(rep(1:3, times=c(velikost,velikost,velikost)))
# classic ANOVA
res$pANOVA[row] = summary(aov(x~gr))[[1]][["Pr(>F)"]][1]
# Welch's ANOVA
res$pANOVA_2[row] = oneway.test(x~gr, var.equal = FALSE)$p.value
# Levenejev test
p_test_enak_V = leveneTest(x~gr)$`Pr(>F)`[1]
if(p_test_enak_V > 0.05){
res$pMETHOD3[row] = summary(aov(x~gr))[[1]][["Pr(>F)"]][1]
} else {
res$pMETHOD3[row] = oneway.test(x~gr, var.equal = FALSE)$p.value
}
}
# shranjevanje
saveRDS(object = res, file="p_vrednost.RDS")
}
res
# risanje p-vrednost: Prikaz p-vrednosti Anderson-Darling testa.
resLong = pivot_longer(res, cols=matches("^p[AM]"), values_to = "pVal",
names_to = "method", names_prefix = "p")
resLong
setwd("~/Documents/viri_podatkov/racunsko_zahtevne_metode/02_naloga")
resLong = pivot_longer(res, cols =matches("^p[AM]"),  values_to = "ariVal",
names_to = "method", names_prefix = "ari.")
useOld = TRUE # ne uporabljal starega rezultata
if(useOld&&file.exists("simulacija.RDS")){
res = readRDS("simulacija.RDS")
}else{
# potrebne knjiznice
# neke tezave z mclust zato je tkole zdej
# potrebne.knjiznice <- c("foreach", "doParallel", "doRNG", "mclust", "blockmodeling")
# nove.knjiznice <- potrebne.knjiznice[!(potrebne.knjiznice %in% installed.packages()[,"Package"])]
# if (length(nove.knjiznice)) install.packages(nove.knjiznice)
# lapply(potrebne.knjiznice, library, character.only = TRUE)
library(foreach)
library(doParallel)
library(doRNG)
library(mclust)
# parallel computing
nc = detectCores()-1
cl = makeCluster(nc, outfile="logSimulacija") # shranjujemo konzolo
# nalozimo ustrezne pakete za vsak cluster worker
clusterEvalQ(cl, {
library(mclust)})
registerDoParallel(cl)
set.seed(2024)
res = cbind(settings,
ari.kmeans=NA, wss.kmeans=NA, pwss.kmeans=NA,
ari.mclust=NA, wss.mclust=NA, pwss.mclust=NA)
for(row in 1:nrow(settings)){
# row = 1
# izberemo faktorje
stevilo.spremenljivk = settings$stevilo.spremenljivk[row]
stevilo.skupin = settings$stevilo.skupin[row]
velikost.skupin = settings$velikost.skupin[row]
diff = settings$diff[row]
# generiramo podatke
data = generiranje.podatkov(stevilo.spremenljivk= stevilo.spremenljivk,
velikost.skupin = velikost.skupin,
stevilo.skupin = stevilo.skupin,
diff = diff)
# transformacija v data.frame
data = as.data.frame(data)
# skaliramo podatke za metodo razvrscanje na polagi modelov
data.scale = scale(data[,1:stevilo.spremenljivk])
# metoda kmeans
kmeans.res = kmeans(data[,1:stevilo.spremenljivk], centers=stevilo.skupin, nstart = 100) #, nstart=nRep)
res$ari.kmeans[row] = blockmodeling::crand(data$skupina, kmeans.res$cluster) #ari
res$wss.kmeans[row] = kmeans.res$tot.withinss #wss
res$pwss.kmeans[row] = kmeans.res$tot.withinss/kmeans.res$totss #pwss
# razvrscanje na polagi modelov
suppressMessages({ # v konzoli se ne izpisuje fitting
model = capture.output({
mclust.res = mclust::Mclust(data.scale, G = stevilo.skupin) # kle nevem cist tocn, k zgori je za nstart kao zacetno stevilo skupin ane in pol sm mal googlala sam kle pa nevem cit tocn kaj nastavt...
})
})
# ari
res$ari.mclust[row] = blockmodeling::crand(data$skupina, mclust.res$classification) #ari
# wss
wss.mclust = sum(sapply(1:stevilo_gruc, function(k) {
sum(rowSums((data.scale[Mclust_res$classification == k, ] - colMeans(data.scale[Mclust_res$classification == k, ]))^2))
}))
res$wss.mclust[row] = wss.mclust
# pwss
res$pwss.mclust[row] = wss.mclust / sum((data.scale - colMeans(data.scale))^2)
# kje se nahaja zanka
if(row%%10==0) cat("Iteration ", row, "/", nrow(settings), "complete! \n")
}
saveRDS(res, "simulacija.RDS")
stopCluster(cl)
}
resLong = pivot_longer(res, cols =matches("^p[AM]"),  values_to = "ariVal",
names_to = "method", names_prefix = "ari.")
resLong = pivot_longer(res, cols =matches("^ari\\"),  values_to = "ariVal",
names_to = "method", names_prefix = "ari.")
resLong = pivot_longer(res, cols =matches("^ari\\."),  values_to = "ariVal",
names_to = "method", names_prefix = "ari.")
resLong
res
################################## simulacija ##################################
m = 100 # st. ponovitev
stevilo.skupin.v = c(4, 8, 10)
velikost.skupin.v = c(20, 100, 200)
stevilo.spremenljivk.v = c(12, 24, 36)
diff.v = c(1, 2, 4, 10)
# parametri za test
m = 2
settings = expand.grid(i=1:m, stevilo.spremenljivk = rev(stevilo.spremenljivk.v),
velikost.skupin = rev(velikost.skupin.v),
stevilo.skupin=rev(stevilo.skupin.v),
diff = rev(diff.v))
useOld = TRUE # ne uporabljal starega rezultata
if(useOld&&file.exists("simulacija.RDS")){
res = readRDS("simulacija.RDS")
}else{
# potrebne knjiznice
# neke tezave z mclust zato je tkole zdej
# potrebne.knjiznice <- c("foreach", "doParallel", "doRNG", "mclust", "blockmodeling")
# nove.knjiznice <- potrebne.knjiznice[!(potrebne.knjiznice %in% installed.packages()[,"Package"])]
# if (length(nove.knjiznice)) install.packages(nove.knjiznice)
# lapply(potrebne.knjiznice, library, character.only = TRUE)
library(foreach)
library(doParallel)
library(doRNG)
library(mclust)
# parallel computing
nc = detectCores()-1
cl = makeCluster(nc, outfile="logSimulacija") # shranjujemo konzolo
# nalozimo ustrezne pakete za vsak cluster worker
clusterEvalQ(cl, {
library(mclust)})
registerDoParallel(cl)
set.seed(2024)
res = cbind(settings,
ari.kmeans=NA, wss.kmeans=NA, pwss.kmeans=NA,
ari.mclust=NA, wss.mclust=NA, pwss.mclust=NA)
for(row in 1:nrow(settings)){
# row = 1
# izberemo faktorje
stevilo.spremenljivk = settings$stevilo.spremenljivk[row]
stevilo.skupin = settings$stevilo.skupin[row]
velikost.skupin = settings$velikost.skupin[row]
diff = settings$diff[row]
# generiramo podatke
data = generiranje.podatkov(stevilo.spremenljivk= stevilo.spremenljivk,
velikost.skupin = velikost.skupin,
stevilo.skupin = stevilo.skupin,
diff = diff)
# transformacija v data.frame
data = as.data.frame(data)
# skaliramo podatke za metodo razvrscanje na polagi modelov
data.scale = scale(data[,1:stevilo.spremenljivk])
# metoda kmeans
kmeans.res = kmeans(data[,1:stevilo.spremenljivk], centers=stevilo.skupin, nstart = 100) #, nstart=nRep)
res$ari.kmeans[row] = blockmodeling::crand(data$skupina, kmeans.res$cluster) #ari
res$wss.kmeans[row] = kmeans.res$tot.withinss #wss
res$pwss.kmeans[row] = kmeans.res$tot.withinss/kmeans.res$totss #pwss
# razvrscanje na polagi modelov
suppressMessages({ # v konzoli se ne izpisuje fitting
model = capture.output({
mclust.res = mclust::Mclust(data.scale, G = stevilo.skupin) # kle nevem cist tocn, k zgori je za nstart kao zacetno stevilo skupin ane in pol sm mal googlala sam kle pa nevem cit tocn kaj nastavt...
})
})
# ari
res$ari.mclust[row] = blockmodeling::crand(data$skupina, mclust.res$classification) #ari
# wss
wss.mclust = sum(sapply(1:stevilo_gruc, function(k) {
sum(rowSums((data.scale[Mclust_res$classification == k, ] - colMeans(data.scale[Mclust_res$classification == k, ]))^2))
}))
res$wss.mclust[row] = wss.mclust
# pwss
res$pwss.mclust[row] = wss.mclust / sum((data.scale - colMeans(data.scale))^2)
# kje se nahaja zanka
if(row%%10==0) cat("Iteration ", row, "/", nrow(settings), "complete! \n")
}
saveRDS(res, "simulacija.RDS")
stopCluster(cl)
}
useOld = FALSE # ne uporabljal starega rezultata
# parametri za test
m = 2
stevilo.spremenljivk.v = 12
velikost.skupin.v = 100
stevilo.skupin.v = 8
diff.v = 2
settings = expand.grid(i=1:m, stevilo.spremenljivk = rev(stevilo.spremenljivk.v),
velikost.skupin = rev(velikost.skupin.v),
stevilo.skupin=rev(stevilo.skupin.v),
diff = rev(diff.v))
settings
useOld = FALSE # ne uporabljal starega rezultata
if(useOld&&file.exists("simulacija.RDS")){
res = readRDS("simulacija.RDS")
}else{
# potrebne knjiznice
# neke tezave z mclust zato je tkole zdej
# potrebne.knjiznice <- c("foreach", "doParallel", "doRNG", "mclust", "blockmodeling")
# nove.knjiznice <- potrebne.knjiznice[!(potrebne.knjiznice %in% installed.packages()[,"Package"])]
# if (length(nove.knjiznice)) install.packages(nove.knjiznice)
# lapply(potrebne.knjiznice, library, character.only = TRUE)
library(foreach)
library(doParallel)
library(doRNG)
library(mclust)
# parallel computing
nc = detectCores()-1
cl = makeCluster(nc, outfile="logSimulacija") # shranjujemo konzolo
# nalozimo ustrezne pakete za vsak cluster worker
clusterEvalQ(cl, {
library(mclust)})
registerDoParallel(cl)
set.seed(2024)
res = cbind(settings,
ari.kmeans=NA, wss.kmeans=NA, pwss.kmeans=NA,
ari.mclust=NA, wss.mclust=NA, pwss.mclust=NA)
for(row in 1:nrow(settings)){
# row = 1
# izberemo faktorje
stevilo.spremenljivk = settings$stevilo.spremenljivk[row]
stevilo.skupin = settings$stevilo.skupin[row]
velikost.skupin = settings$velikost.skupin[row]
diff = settings$diff[row]
# generiramo podatke
data = generiranje.podatkov(stevilo.spremenljivk= stevilo.spremenljivk,
velikost.skupin = velikost.skupin,
stevilo.skupin = stevilo.skupin,
diff = diff)
# transformacija v data.frame
data = as.data.frame(data)
# skaliramo podatke za metodo razvrscanje na polagi modelov
data.scale = scale(data[,1:stevilo.spremenljivk])
# metoda kmeans
kmeans.res = kmeans(data[,1:stevilo.spremenljivk], centers=stevilo.skupin, nstart = 100) #, nstart=nRep)
res$ari.kmeans[row] = blockmodeling::crand(data$skupina, kmeans.res$cluster) #ari
res$wss.kmeans[row] = kmeans.res$tot.withinss #wss
res$pwss.kmeans[row] = kmeans.res$tot.withinss/kmeans.res$totss #pwss
# razvrscanje na polagi modelov
suppressMessages({ # v konzoli se ne izpisuje fitting
model = capture.output({
mclust.res = mclust::Mclust(data.scale, G = stevilo.skupin) # kle nevem cist tocn, k zgori je za nstart kao zacetno stevilo skupin ane in pol sm mal googlala sam kle pa nevem cit tocn kaj nastavt...
})
})
# ari
res$ari.mclust[row] = blockmodeling::crand(data$skupina, mclust.res$classification) #ari
# wss
wss.mclust = sum(sapply(1:stevilo_gruc, function(k) {
sum(rowSums((data.scale[Mclust_res$classification == k, ] - colMeans(data.scale[Mclust_res$classification == k, ]))^2))
}))
res$wss.mclust[row] = wss.mclust
# pwss
res$pwss.mclust[row] = wss.mclust / sum((data.scale - colMeans(data.scale))^2)
# kje se nahaja zanka
if(row%%10==0) cat("Iteration ", row, "/", nrow(settings), "complete! \n")
}
saveRDS(object = res, file="simulacija.RDS")
stopCluster(cl)
}
if(useOld&&file.exists("simulacija.RDS")){
res = readRDS("simulacija.RDS")
}else{
# potrebne knjiznice
# neke tezave z mclust zato je tkole zdej
# potrebne.knjiznice <- c("foreach", "doParallel", "doRNG", "mclust", "blockmodeling")
# nove.knjiznice <- potrebne.knjiznice[!(potrebne.knjiznice %in% installed.packages()[,"Package"])]
# if (length(nove.knjiznice)) install.packages(nove.knjiznice)
# lapply(potrebne.knjiznice, library, character.only = TRUE)
library(foreach)
library(doParallel)
library(doRNG)
library(mclust)
# parallel computing
nc = detectCores()-1
cl = makeCluster(nc, outfile="logSimulacija") # shranjujemo konzolo
# nalozimo ustrezne pakete za vsak cluster worker
clusterEvalQ(cl, {
library(mclust)})
registerDoParallel(cl)
set.seed(2024)
res = cbind(settings,
ari.kmeans=NA, wss.kmeans=NA, pwss.kmeans=NA,
ari.mclust=NA, wss.mclust=NA, pwss.mclust=NA)
for(row in 1:nrow(settings)){
# row = 1
# izberemo faktorje
stevilo.spremenljivk = settings$stevilo.spremenljivk[row]
stevilo.skupin = settings$stevilo.skupin[row]
velikost.skupin = settings$velikost.skupin[row]
diff = settings$diff[row]
# generiramo podatke
data = generiranje.podatkov(stevilo.spremenljivk= stevilo.spremenljivk,
velikost.skupin = velikost.skupin,
stevilo.skupin = stevilo.skupin,
diff = diff)
# transformacija v data.frame
data = as.data.frame(data)
# skaliramo podatke za metodo razvrscanje na polagi modelov
data.scale = scale(data[,1:stevilo.spremenljivk])
# metoda kmeans
kmeans.res = kmeans(data[,1:stevilo.spremenljivk], centers=stevilo.skupin, nstart = 100) #, nstart=nRep)
res$ari.kmeans[row] = blockmodeling::crand(data$skupina, kmeans.res$cluster) #ari
res$wss.kmeans[row] = kmeans.res$tot.withinss #wss
res$pwss.kmeans[row] = kmeans.res$tot.withinss/kmeans.res$totss #pwss
# razvrscanje na polagi modelov
suppressMessages({ # v konzoli se ne izpisuje fitting
model = capture.output({
mclust.res = mclust::Mclust(data.scale, G = stevilo.skupin) # kle nevem cist tocn, k zgori je za nstart kao zacetno stevilo skupin ane in pol sm mal googlala sam kle pa nevem cit tocn kaj nastavt...
})
})
# ari
res$ari.mclust[row] = blockmodeling::crand(data$skupina, mclust.res$classification) #ari
# wss
wss.mclust = sum(sapply(1:stevilo.skupin, function(k) {
sum(rowSums((data.scale[Mclust_res$classification == k, ] - colMeans(data.scale[Mclust_res$classification == k, ]))^2))
}))
res$wss.mclust[row] = wss.mclust
# pwss
res$pwss.mclust[row] = wss.mclust / sum((data.scale - colMeans(data.scale))^2)
# kje se nahaja zanka
if(row%%10==0) cat("Iteration ", row, "/", nrow(settings), "complete! \n")
}
saveRDS(object = res, file="simulacija.RDS")
stopCluster(cl)
}
if(useOld&&file.exists("simulacija.RDS")){
res = readRDS("simulacija.RDS")
}else{
# potrebne knjiznice
# neke tezave z mclust zato je tkole zdej
# potrebne.knjiznice <- c("foreach", "doParallel", "doRNG", "mclust", "blockmodeling")
# nove.knjiznice <- potrebne.knjiznice[!(potrebne.knjiznice %in% installed.packages()[,"Package"])]
# if (length(nove.knjiznice)) install.packages(nove.knjiznice)
# lapply(potrebne.knjiznice, library, character.only = TRUE)
library(foreach)
library(doParallel)
library(doRNG)
library(mclust)
# parallel computing
nc = detectCores()-1
cl = makeCluster(nc, outfile="logSimulacija") # shranjujemo konzolo
# nalozimo ustrezne pakete za vsak cluster worker
clusterEvalQ(cl, {
library(mclust)})
registerDoParallel(cl)
set.seed(2024)
res = cbind(settings,
ari.kmeans=NA, wss.kmeans=NA, pwss.kmeans=NA,
ari.mclust=NA, wss.mclust=NA, pwss.mclust=NA)
for(row in 1:nrow(settings)){
# row = 1
# izberemo faktorje
stevilo.spremenljivk = settings$stevilo.spremenljivk[row]
stevilo.skupin = settings$stevilo.skupin[row]
velikost.skupin = settings$velikost.skupin[row]
diff = settings$diff[row]
# generiramo podatke
data = generiranje.podatkov(stevilo.spremenljivk= stevilo.spremenljivk,
velikost.skupin = velikost.skupin,
stevilo.skupin = stevilo.skupin,
diff = diff)
# transformacija v data.frame
data = as.data.frame(data)
# skaliramo podatke za metodo razvrscanje na polagi modelov
data.scale = scale(data[,1:stevilo.spremenljivk])
# metoda kmeans
kmeans.res = kmeans(data[,1:stevilo.spremenljivk], centers=stevilo.skupin, nstart = 100) #, nstart=nRep)
res$ari.kmeans[row] = blockmodeling::crand(data$skupina, kmeans.res$cluster) #ari
res$wss.kmeans[row] = kmeans.res$tot.withinss #wss
res$pwss.kmeans[row] = kmeans.res$tot.withinss/kmeans.res$totss #pwss
# razvrscanje na polagi modelov
suppressMessages({ # v konzoli se ne izpisuje fitting
model = capture.output({
mclust.res = mclust::Mclust(data.scale, G = stevilo.skupin) # kle nevem cist tocn, k zgori je za nstart kao zacetno stevilo skupin ane in pol sm mal googlala sam kle pa nevem cit tocn kaj nastavt...
})
})
# ari
res$ari.mclust[row] = blockmodeling::crand(data$skupina, mclust.res$classification) #ari
# wss
wss.mclust = sum(sapply(1:stevilo.skupin, function(k) {
sum(rowSums((data.scale[mclust.res$classification == k, ] - colMeans(data.scale[mclust.res$classification == k, ]))^2))
}))
res$wss.mclust[row] = wss.mclust
# pwss
res$pwss.mclust[row] = wss.mclust / sum((data.scale - colMeans(data.scale))^2)
# kje se nahaja zanka
if(row%%10==0) cat("Iteration ", row, "/", nrow(settings), "complete! \n")
}
saveRDS(object = res, file="simulacija.RDS")
stopCluster(cl)
}
res
# na enem slajdu v predavanjih pise: Why is "sum of squares within clusters" not a good measure?
# in moj zapisek na to je: Cilj clusteringa najti skupine ki so si čim manj podobne ampak elemnti v skupini pa čim bolj skupi. Nekatere metode optimize to mero(k-means) in nekatere ne, zato ni najboljša mera...
# sm sla gledat v lansko kar smo delala, ampak te dve metodi nimata nobene skupne mere...
# zdej pa nevem al dodava se wss al ne? mal sm googlala je se nek Silhuetni koeficient
# meri pa, kako podobne so si točke znotraj gruče v primerjavi z najbližjo sosednjo gručo. Giblje se od -1 do 1, kjer večja vrednost pomeni boljše grupiranje.
################################# grafični prikaz ##############################
library(tidyr)
library(dplyr)
resLong = pivot_longer(res, cols =matches("^ari\\."),  values_to = "ariVal",
names_to = "method", names_prefix = "ari.")
resLong
resAgg = aggregate(cbind(ari.kmeans, wss.kmeans, pwss.kmeans, ari.mclust, wss.mclust, pwss.mclust) ~
stevilo.spremenljivk + velikost.skupin + stevilo.skupin, data = resLong, FUN = mean)
resLong = pivot_longer(res, cols =matches("^(ari|wss|pwss)\\."),  values_to = "value",
names_to = c("metric", "method"), names_pattern = "^(ari|wss|pwss)\\.(kmeans|mclust)")
resLong
res
resWide <- resLong %>% pivot_wider(names_from = metric, values_from = value)
resWide
resAgg = aggregate(cbind(ari, wss, pwss) ~ stevilo.spremenljivk + velikost.skupin + stevilo.skupin + method,
data = res, FUN = mean)
resAgg = aggregate(cbind(ari, wss, pwss) ~ stevilo.spremenljivk + velikost.skupin + stevilo.skupin + method,
data = resWide, FUN = mean)
resAgg
library(ggplot2)
# risemo adjR2
ggplot(resAgg, aes(y = ari, x = as.factor(stevilo.spremenljivk, col=method, group=method))) + # za x ponavadi dobro neki kar nima preveč vpliva
geom_point() + geom_line() +
facet_grid(stevilo.skupin ~ velikost.skupin, scales="free")
# risemo adjR2
ggplot(resAgg, aes(y = ari, x = as.factor(stevilo.spremenljivk), col=method, group=method)) + # za x ponavadi dobro neki kar nima preveč vpliva
geom_point() + geom_line() +
facet_grid(stevilo.skupin ~ velikost.skupin, scales="free")
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", fig.pos = "H", message = FALSE, warning = FALSE, results = F, fig.height =3, fig.width = 6.5)
# potrebne knjižnice
library(ggplot2)
library(car)
library(tidyr)
library(ADGofTest)
# seme
set.seed(2024)
data.primer2 = generiranje.podatkov(stevilo.spremenljivk = 12, velikost.skupin = 100, stevilo.skupin = 8, diff = 4)
pairs(data.primer1[,1:4], col=data.primer1[,13])
data.primer2 = generiranje.podatkov(stevilo.spremenljivk = 12, velikost.skupin = 100, stevilo.skupin = 8, diff = 4)
pairs(data.primer2[,1:4], col=data.primer1[,13])
data.primer2 = generiranje.podatkov(stevilo.spremenljivk = 12, velikost.skupin = 100, stevilo.skupin = 8, diff = 4)
pairs(data.primer2[,1:4], col=data.primer2[,13])
data.primer2 = generiranje.podatkov(stevilo.spremenljivk = 12, velikost.skupin = 100, stevilo.skupin = 4, diff = 4)
pairs(data.primer2[,1:4], col=data.primer2[,13])
